[2024-10-23 18:02:36 mlla_tiny] (main.py 110): INFO Full config saved to work_dir/mlla_tiny/default/config.json
[2024-10-23 18:02:36 mlla_tiny] (main.py 113): INFO AMP: true
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MESA: 1.0
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /home/zq/pycode/MLLA/ImageNet-1000
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 8
  PIN_MEMORY: true
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  MLLA:
    APE: false
    DEPTHS:
    - 2
    - 4
    - 8
    - 4
    EMBED_DIM: 64
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 2
    - 4
    - 8
    - 16
    PATCH_SIZE: 4
    QKV_BIAS: true
  NAME: mlla_tiny
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mlla
OUTPUT: work_dir/mlla_tiny/default
PRINT_FREQ: 100
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
THROUGHPUT_MODE: false
TRAIN:
  AUTO_RESUME: true
  BASE_LR: 0.000125
  CLIP_GRAD: 5.0
  COOLDOWN_EPOCHS: 0
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 1.25e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.25e-07
  WEIGHT_DECAY: 0.05

[2024-10-23 19:32:41 mlla_tiny] (main.py 110): INFO Full config saved to work_dir/mlla_tiny/default/config.json
[2024-10-23 19:32:41 mlla_tiny] (main.py 113): INFO AMP: true
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MESA: 1.0
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /home/zq/pycode/MLLA/ImageNet-1000
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 8
  PIN_MEMORY: true
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  MLLA:
    APE: false
    DEPTHS:
    - 2
    - 4
    - 8
    - 4
    EMBED_DIM: 64
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 2
    - 4
    - 8
    - 16
    PATCH_SIZE: 4
    QKV_BIAS: true
  NAME: mlla_tiny
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mlla
OUTPUT: work_dir/mlla_tiny/default
PRINT_FREQ: 100
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
THROUGHPUT_MODE: false
TRAIN:
  AUTO_RESUME: true
  BASE_LR: 0.000125
  CLIP_GRAD: 5.0
  COOLDOWN_EPOCHS: 0
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 1.25e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.25e-07
  WEIGHT_DECAY: 0.05

[2024-10-23 19:32:41 mlla_tiny] (main.py 117): INFO Creating model:mlla/mlla_tiny
[2024-10-23 19:33:19 mlla_tiny] (main.py 120): INFO MLLA(
  (patch_embed): Stem(
    (conv1): ConvLayer(
      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act): ReLU()
    )
    (conv2): Sequential(
      (0): ConvLayer(
        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (1): ConvLayer(
        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (conv3): Sequential(
      (0): ConvLayer(
        (conv): Conv2d(32, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (1): ConvLayer(
        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=64, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): MLLABlock(
          dim=64, input_resolution=(56, 56), num_heads=2, mlp_ratio=4.0
          (cpe1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=64, out_features=64, bias=True)
          (act_proj): Linear(in_features=64, out_features=64, bias=True)
          (dwc): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (act): SiLU()
          (attn): LinearAttention(
            dim=64, num_heads=2
            (qk): Linear(in_features=64, out_features=128, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=64, out_features=64, bias=True)
          (drop_path): Identity()
          (cpe2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): MLLABlock(
          dim=64, input_resolution=(56, 56), num_heads=2, mlp_ratio=4.0
          (cpe1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=64, out_features=64, bias=True)
          (act_proj): Linear(in_features=64, out_features=64, bias=True)
          (dwc): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (act): SiLU()
          (attn): LinearAttention(
            dim=64, num_heads=2
            (qk): Linear(in_features=64, out_features=128, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=64, out_features=64, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        (conv): Sequential(
          (0): ConvLayer(
            (conv): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU()
          )
          (1): ConvLayer(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (act): ReLU()
          )
          (2): ConvLayer(
            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicLayer(
      dim=128, input_resolution=(28, 28), depth=4
      (blocks): ModuleList(
        (0): MLLABlock(
          dim=128, input_resolution=(28, 28), num_heads=4, mlp_ratio=4.0
          (cpe1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=128, out_features=128, bias=True)
          (act_proj): Linear(in_features=128, out_features=128, bias=True)
          (dwc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (act): SiLU()
          (attn): LinearAttention(
            dim=128, num_heads=4
            (qk): Linear(in_features=128, out_features=256, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): MLLABlock(
          dim=128, input_resolution=(28, 28), num_heads=4, mlp_ratio=4.0
          (cpe1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=128, out_features=128, bias=True)
          (act_proj): Linear(in_features=128, out_features=128, bias=True)
          (dwc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (act): SiLU()
          (attn): LinearAttention(
            dim=128, num_heads=4
            (qk): Linear(in_features=128, out_features=256, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): MLLABlock(
          dim=128, input_resolution=(28, 28), num_heads=4, mlp_ratio=4.0
          (cpe1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=128, out_features=128, bias=True)
          (act_proj): Linear(in_features=128, out_features=128, bias=True)
          (dwc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (act): SiLU()
          (attn): LinearAttention(
            dim=128, num_heads=4
            (qk): Linear(in_features=128, out_features=256, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): MLLABlock(
          dim=128, input_resolution=(28, 28), num_heads=4, mlp_ratio=4.0
          (cpe1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=128, out_features=128, bias=True)
          (act_proj): Linear(in_features=128, out_features=128, bias=True)
          (dwc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (act): SiLU()
          (attn): LinearAttention(
            dim=128, num_heads=4
            (qk): Linear(in_features=128, out_features=256, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        (conv): Sequential(
          (0): ConvLayer(
            (conv): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU()
          )
          (1): ConvLayer(
            (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024)
            (act): ReLU()
          )
          (2): ConvLayer(
            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (2): BasicLayer(
      dim=256, input_resolution=(14, 14), depth=8
      (blocks): ModuleList(
        (0): MLLABlock(
          dim=256, input_resolution=(14, 14), num_heads=8, mlp_ratio=4.0
          (cpe1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=256, out_features=256, bias=True)
          (act_proj): Linear(in_features=256, out_features=256, bias=True)
          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (act): SiLU()
          (attn): LinearAttention(
            dim=256, num_heads=8
            (qk): Linear(in_features=256, out_features=512, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): MLLABlock(
          dim=256, input_resolution=(14, 14), num_heads=8, mlp_ratio=4.0
          (cpe1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=256, out_features=256, bias=True)
          (act_proj): Linear(in_features=256, out_features=256, bias=True)
          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (act): SiLU()
          (attn): LinearAttention(
            dim=256, num_heads=8
            (qk): Linear(in_features=256, out_features=512, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): MLLABlock(
          dim=256, input_resolution=(14, 14), num_heads=8, mlp_ratio=4.0
          (cpe1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=256, out_features=256, bias=True)
          (act_proj): Linear(in_features=256, out_features=256, bias=True)
          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (act): SiLU()
          (attn): LinearAttention(
            dim=256, num_heads=8
            (qk): Linear(in_features=256, out_features=512, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): MLLABlock(
          dim=256, input_resolution=(14, 14), num_heads=8, mlp_ratio=4.0
          (cpe1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=256, out_features=256, bias=True)
          (act_proj): Linear(in_features=256, out_features=256, bias=True)
          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (act): SiLU()
          (attn): LinearAttention(
            dim=256, num_heads=8
            (qk): Linear(in_features=256, out_features=512, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): MLLABlock(
          dim=256, input_resolution=(14, 14), num_heads=8, mlp_ratio=4.0
          (cpe1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=256, out_features=256, bias=True)
          (act_proj): Linear(in_features=256, out_features=256, bias=True)
          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (act): SiLU()
          (attn): LinearAttention(
            dim=256, num_heads=8
            (qk): Linear(in_features=256, out_features=512, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): MLLABlock(
          dim=256, input_resolution=(14, 14), num_heads=8, mlp_ratio=4.0
          (cpe1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=256, out_features=256, bias=True)
          (act_proj): Linear(in_features=256, out_features=256, bias=True)
          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (act): SiLU()
          (attn): LinearAttention(
            dim=256, num_heads=8
            (qk): Linear(in_features=256, out_features=512, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): MLLABlock(
          dim=256, input_resolution=(14, 14), num_heads=8, mlp_ratio=4.0
          (cpe1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=256, out_features=256, bias=True)
          (act_proj): Linear(in_features=256, out_features=256, bias=True)
          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (act): SiLU()
          (attn): LinearAttention(
            dim=256, num_heads=8
            (qk): Linear(in_features=256, out_features=512, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): MLLABlock(
          dim=256, input_resolution=(14, 14), num_heads=8, mlp_ratio=4.0
          (cpe1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=256, out_features=256, bias=True)
          (act_proj): Linear(in_features=256, out_features=256, bias=True)
          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (act): SiLU()
          (attn): LinearAttention(
            dim=256, num_heads=8
            (qk): Linear(in_features=256, out_features=512, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        (conv): Sequential(
          (0): ConvLayer(
            (conv): Conv2d(256, 2048, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU()
          )
          (1): ConvLayer(
            (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=2048)
            (act): ReLU()
          )
          (2): ConvLayer(
            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
            (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (3): BasicLayer(
      dim=512, input_resolution=(7, 7), depth=4
      (blocks): ModuleList(
        (0): MLLABlock(
          dim=512, input_resolution=(7, 7), num_heads=16, mlp_ratio=4.0
          (cpe1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=512, out_features=512, bias=True)
          (act_proj): Linear(in_features=512, out_features=512, bias=True)
          (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (act): SiLU()
          (attn): LinearAttention(
            dim=512, num_heads=16
            (qk): Linear(in_features=512, out_features=1024, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): MLLABlock(
          dim=512, input_resolution=(7, 7), num_heads=16, mlp_ratio=4.0
          (cpe1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=512, out_features=512, bias=True)
          (act_proj): Linear(in_features=512, out_features=512, bias=True)
          (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (act): SiLU()
          (attn): LinearAttention(
            dim=512, num_heads=16
            (qk): Linear(in_features=512, out_features=1024, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): MLLABlock(
          dim=512, input_resolution=(7, 7), num_heads=16, mlp_ratio=4.0
          (cpe1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=512, out_features=512, bias=True)
          (act_proj): Linear(in_features=512, out_features=512, bias=True)
          (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (act): SiLU()
          (attn): LinearAttention(
            dim=512, num_heads=16
            (qk): Linear(in_features=512, out_features=1024, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): MLLABlock(
          dim=512, input_resolution=(7, 7), num_heads=16, mlp_ratio=4.0
          (cpe1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=512, out_features=512, bias=True)
          (act_proj): Linear(in_features=512, out_features=512, bias=True)
          (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (act): SiLU()
          (attn): LinearAttention(
            dim=512, num_heads=16
            (qk): Linear(in_features=512, out_features=1024, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=512, out_features=1000, bias=True)
)
[2024-10-23 19:33:19 mlla_tiny] (main.py 154): INFO no checkpoint found in work_dir/mlla_tiny/default, ignoring auto resume
[2024-10-23 19:33:19 mlla_tiny] (main.py 168): INFO Model EMA decay 0.9999874975774891
[2024-10-23 19:34:11 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-23 19:34:11 mlla_tiny] (main.py 177): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-23 19:34:11 mlla_tiny] (main.py 185): INFO Start training
[2024-10-23 19:35:02 mlla_tiny] (main.py 296): INFO Train: [1/300][100/312]	eta 0:01:50 lr 0.000002	time 0.3672 (0.5171)	loss 6.9278 (6.9229)	grad_norm 1.1303 (1.2545)	mem 15236MB
[2024-10-23 19:35:39 mlla_tiny] (main.py 296): INFO Train: [1/300][200/312]	eta 0:00:50 lr 0.000004	time 0.3685 (0.4425)	loss 6.9122 (6.9230)	grad_norm 1.0996 (1.2469)	mem 15236MB
[2024-10-23 19:36:16 mlla_tiny] (main.py 296): INFO Train: [1/300][300/312]	eta 0:00:05 lr 0.000006	time 0.3665 (0.4178)	loss 6.9385 (6.9223)	grad_norm 1.3088 (1.2449)	mem 15236MB
[2024-10-23 19:36:21 mlla_tiny] (main.py 304): INFO EPOCH 1 training takes 0:02:09
[2024-10-23 19:36:37 mlla_tiny] (main.py 350): INFO  * Acc@1 0.150 Acc@5 0.630
[2024-10-23 19:36:37 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 0.1%
[2024-10-23 19:36:54 mlla_tiny] (main.py 350): INFO  * Acc@1 0.110 Acc@5 0.500
[2024-10-23 19:36:54 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-23 19:36:54 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_1.pth saving......
[2024-10-23 19:36:55 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_1.pth saved !!!
[2024-10-23 19:36:55 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-23 19:36:56 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-23 19:36:56 mlla_tiny] (main.py 205): INFO Max accuracy: 0.15%
[2024-10-23 19:36:56 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_ema_acc.pth saving......
[2024-10-23 19:36:57 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_ema_acc.pth saved !!!
[2024-10-23 19:36:57 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-23 19:37:34 mlla_tiny] (main.py 296): INFO Train: [2/300][100/312]	eta 0:01:20 lr 0.000008	time 0.3694 (0.3770)	loss 6.8952 (6.9153)	grad_norm 1.0430 (1.1629)	mem 15236MB
[2024-10-23 19:38:11 mlla_tiny] (main.py 296): INFO Train: [2/300][200/312]	eta 0:00:42 lr 0.000010	time 0.3711 (0.3736)	loss 6.9153 (6.9147)	grad_norm 1.0482 (1.1457)	mem 15236MB
[2024-10-23 19:38:48 mlla_tiny] (main.py 296): INFO Train: [2/300][300/312]	eta 0:00:04 lr 0.000012	time 0.3683 (0.3725)	loss 6.9136 (6.9143)	grad_norm 1.2122 (1.1249)	mem 15236MB
[2024-10-23 19:38:53 mlla_tiny] (main.py 304): INFO EPOCH 2 training takes 0:01:56
[2024-10-23 19:39:10 mlla_tiny] (main.py 350): INFO  * Acc@1 0.220 Acc@5 0.820
[2024-10-23 19:39:10 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 0.2%
[2024-10-23 19:39:26 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-23 19:39:26 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-23 19:39:26 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_2.pth saving......
[2024-10-23 19:39:27 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_2.pth saved !!!
[2024-10-23 19:39:27 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-23 19:39:28 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-23 19:39:28 mlla_tiny] (main.py 205): INFO Max accuracy: 0.22%
[2024-10-23 19:39:28 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-23 19:40:06 mlla_tiny] (main.py 296): INFO Train: [3/300][100/312]	eta 0:01:20 lr 0.000015	time 0.3703 (0.3776)	loss 6.8953 (6.9100)	grad_norm 1.0219 (1.0778)	mem 15236MB
[2024-10-23 19:40:43 mlla_tiny] (main.py 296): INFO Train: [3/300][200/312]	eta 0:00:42 lr 0.000017	time 0.3695 (0.3739)	loss 6.9098 (6.9098)	grad_norm 0.9344 (1.0458)	mem 15236MB
[2024-10-23 19:41:20 mlla_tiny] (main.py 296): INFO Train: [3/300][300/312]	eta 0:00:04 lr 0.000019	time 0.3683 (0.3726)	loss 6.9097 (6.9095)	grad_norm 0.9769 (1.0312)	mem 15236MB
[2024-10-23 19:41:25 mlla_tiny] (main.py 304): INFO EPOCH 3 training takes 0:01:56
[2024-10-23 19:41:41 mlla_tiny] (main.py 350): INFO  * Acc@1 0.240 Acc@5 1.180
[2024-10-23 19:41:41 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 0.2%
[2024-10-23 19:41:58 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-23 19:41:58 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-23 19:41:58 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_3.pth saving......
[2024-10-23 19:41:59 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_3.pth saved !!!
[2024-10-23 19:41:59 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-23 19:42:00 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-23 19:42:00 mlla_tiny] (main.py 205): INFO Max accuracy: 0.24%
[2024-10-23 19:42:00 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-23 19:42:38 mlla_tiny] (main.py 296): INFO Train: [4/300][100/312]	eta 0:01:20 lr 0.000021	time 0.3693 (0.3788)	loss 6.9107 (6.9045)	grad_norm 0.9749 (0.9756)	mem 15236MB
[2024-10-23 19:43:15 mlla_tiny] (main.py 296): INFO Train: [4/300][200/312]	eta 0:00:42 lr 0.000023	time 0.3690 (0.3743)	loss 6.9056 (6.9042)	grad_norm 0.9322 (0.9753)	mem 15236MB
[2024-10-23 19:43:52 mlla_tiny] (main.py 296): INFO Train: [4/300][300/312]	eta 0:00:04 lr 0.000025	time 0.3679 (0.3728)	loss 6.8725 (6.9033)	grad_norm 1.2239 (0.9755)	mem 15236MB
[2024-10-23 19:43:56 mlla_tiny] (main.py 304): INFO EPOCH 4 training takes 0:01:56
[2024-10-23 19:44:13 mlla_tiny] (main.py 350): INFO  * Acc@1 0.430 Acc@5 1.650
[2024-10-23 19:44:13 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 0.4%
[2024-10-23 19:44:30 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-23 19:44:30 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-23 19:44:30 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_4.pth saving......
[2024-10-23 19:44:31 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_4.pth saved !!!
[2024-10-23 19:44:31 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-23 19:44:32 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-23 19:44:32 mlla_tiny] (main.py 205): INFO Max accuracy: 0.43%
[2024-10-23 19:44:32 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-23 19:45:09 mlla_tiny] (main.py 296): INFO Train: [5/300][100/312]	eta 0:01:20 lr 0.000027	time 0.3704 (0.3775)	loss 6.8958 (6.8899)	grad_norm 1.0220 (1.0608)	mem 15236MB
[2024-10-23 19:45:46 mlla_tiny] (main.py 296): INFO Train: [5/300][200/312]	eta 0:00:42 lr 0.000029	time 0.3693 (0.3737)	loss 6.8771 (6.8893)	grad_norm 1.2200 (1.0899)	mem 15236MB
[2024-10-24 01:20:59 mlla_tiny] (main.py 110): INFO Full config saved to work_dir/mlla_tiny/default/config.json
[2024-10-24 01:20:59 mlla_tiny] (main.py 113): INFO AMP: true
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MESA: 1.0
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /home/zq/pycode/MLLA/ImageNet-1000
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  MLLA:
    APE: false
    DEPTHS:
    - 2
    - 4
    - 8
    - 4
    EMBED_DIM: 64
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 2
    - 4
    - 8
    - 16
    PATCH_SIZE: 4
    QKV_BIAS: true
  NAME: mlla_tiny
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: mlla
OUTPUT: work_dir/mlla_tiny/default
PRINT_FREQ: 100
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
THROUGHPUT_MODE: false
TRAIN:
  AUTO_RESUME: true
  BASE_LR: 0.000125
  CLIP_GRAD: 5.0
  COOLDOWN_EPOCHS: 0
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 1.25e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.25e-07
  WEIGHT_DECAY: 0.05

[2024-10-24 01:21:01 mlla_tiny] (main.py 117): INFO Creating model:mlla/mlla_tiny
[2024-10-24 01:21:39 mlla_tiny] (main.py 120): INFO MLLA(
  (patch_embed): Stem(
    (conv1): ConvLayer(
      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act): ReLU()
    )
    (conv2): Sequential(
      (0): ConvLayer(
        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (1): ConvLayer(
        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (conv3): Sequential(
      (0): ConvLayer(
        (conv): Conv2d(32, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (1): ConvLayer(
        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=64, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): MLLABlock(
          dim=64, input_resolution=(56, 56), num_heads=2, mlp_ratio=4.0
          (cpe1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=64, out_features=64, bias=True)
          (act_proj): Linear(in_features=64, out_features=64, bias=True)
          (dwc): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (act): SiLU()
          (attn): LinearAttention(
            dim=64, num_heads=2
            (qk): Linear(in_features=64, out_features=128, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=64, out_features=64, bias=True)
          (drop_path): Identity()
          (cpe2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): MLLABlock(
          dim=64, input_resolution=(56, 56), num_heads=2, mlp_ratio=4.0
          (cpe1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=64, out_features=64, bias=True)
          (act_proj): Linear(in_features=64, out_features=64, bias=True)
          (dwc): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (act): SiLU()
          (attn): LinearAttention(
            dim=64, num_heads=2
            (qk): Linear(in_features=64, out_features=128, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=64, out_features=64, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        (conv): Sequential(
          (0): ConvLayer(
            (conv): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU()
          )
          (1): ConvLayer(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (act): ReLU()
          )
          (2): ConvLayer(
            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicLayer(
      dim=128, input_resolution=(28, 28), depth=4
      (blocks): ModuleList(
        (0): MLLABlock(
          dim=128, input_resolution=(28, 28), num_heads=4, mlp_ratio=4.0
          (cpe1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=128, out_features=128, bias=True)
          (act_proj): Linear(in_features=128, out_features=128, bias=True)
          (dwc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (act): SiLU()
          (attn): LinearAttention(
            dim=128, num_heads=4
            (qk): Linear(in_features=128, out_features=256, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): MLLABlock(
          dim=128, input_resolution=(28, 28), num_heads=4, mlp_ratio=4.0
          (cpe1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=128, out_features=128, bias=True)
          (act_proj): Linear(in_features=128, out_features=128, bias=True)
          (dwc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (act): SiLU()
          (attn): LinearAttention(
            dim=128, num_heads=4
            (qk): Linear(in_features=128, out_features=256, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): MLLABlock(
          dim=128, input_resolution=(28, 28), num_heads=4, mlp_ratio=4.0
          (cpe1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=128, out_features=128, bias=True)
          (act_proj): Linear(in_features=128, out_features=128, bias=True)
          (dwc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (act): SiLU()
          (attn): LinearAttention(
            dim=128, num_heads=4
            (qk): Linear(in_features=128, out_features=256, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): MLLABlock(
          dim=128, input_resolution=(28, 28), num_heads=4, mlp_ratio=4.0
          (cpe1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=128, out_features=128, bias=True)
          (act_proj): Linear(in_features=128, out_features=128, bias=True)
          (dwc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (act): SiLU()
          (attn): LinearAttention(
            dim=128, num_heads=4
            (qk): Linear(in_features=128, out_features=256, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        (conv): Sequential(
          (0): ConvLayer(
            (conv): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU()
          )
          (1): ConvLayer(
            (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024)
            (act): ReLU()
          )
          (2): ConvLayer(
            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (2): BasicLayer(
      dim=256, input_resolution=(14, 14), depth=8
      (blocks): ModuleList(
        (0): MLLABlock(
          dim=256, input_resolution=(14, 14), num_heads=8, mlp_ratio=4.0
          (cpe1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=256, out_features=256, bias=True)
          (act_proj): Linear(in_features=256, out_features=256, bias=True)
          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (act): SiLU()
          (attn): LinearAttention(
            dim=256, num_heads=8
            (qk): Linear(in_features=256, out_features=512, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): MLLABlock(
          dim=256, input_resolution=(14, 14), num_heads=8, mlp_ratio=4.0
          (cpe1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=256, out_features=256, bias=True)
          (act_proj): Linear(in_features=256, out_features=256, bias=True)
          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (act): SiLU()
          (attn): LinearAttention(
            dim=256, num_heads=8
            (qk): Linear(in_features=256, out_features=512, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): MLLABlock(
          dim=256, input_resolution=(14, 14), num_heads=8, mlp_ratio=4.0
          (cpe1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=256, out_features=256, bias=True)
          (act_proj): Linear(in_features=256, out_features=256, bias=True)
          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (act): SiLU()
          (attn): LinearAttention(
            dim=256, num_heads=8
            (qk): Linear(in_features=256, out_features=512, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): MLLABlock(
          dim=256, input_resolution=(14, 14), num_heads=8, mlp_ratio=4.0
          (cpe1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=256, out_features=256, bias=True)
          (act_proj): Linear(in_features=256, out_features=256, bias=True)
          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (act): SiLU()
          (attn): LinearAttention(
            dim=256, num_heads=8
            (qk): Linear(in_features=256, out_features=512, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): MLLABlock(
          dim=256, input_resolution=(14, 14), num_heads=8, mlp_ratio=4.0
          (cpe1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=256, out_features=256, bias=True)
          (act_proj): Linear(in_features=256, out_features=256, bias=True)
          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (act): SiLU()
          (attn): LinearAttention(
            dim=256, num_heads=8
            (qk): Linear(in_features=256, out_features=512, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): MLLABlock(
          dim=256, input_resolution=(14, 14), num_heads=8, mlp_ratio=4.0
          (cpe1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=256, out_features=256, bias=True)
          (act_proj): Linear(in_features=256, out_features=256, bias=True)
          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (act): SiLU()
          (attn): LinearAttention(
            dim=256, num_heads=8
            (qk): Linear(in_features=256, out_features=512, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): MLLABlock(
          dim=256, input_resolution=(14, 14), num_heads=8, mlp_ratio=4.0
          (cpe1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=256, out_features=256, bias=True)
          (act_proj): Linear(in_features=256, out_features=256, bias=True)
          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (act): SiLU()
          (attn): LinearAttention(
            dim=256, num_heads=8
            (qk): Linear(in_features=256, out_features=512, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): MLLABlock(
          dim=256, input_resolution=(14, 14), num_heads=8, mlp_ratio=4.0
          (cpe1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=256, out_features=256, bias=True)
          (act_proj): Linear(in_features=256, out_features=256, bias=True)
          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (act): SiLU()
          (attn): LinearAttention(
            dim=256, num_heads=8
            (qk): Linear(in_features=256, out_features=512, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        (conv): Sequential(
          (0): ConvLayer(
            (conv): Conv2d(256, 2048, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU()
          )
          (1): ConvLayer(
            (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=2048)
            (act): ReLU()
          )
          (2): ConvLayer(
            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
            (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (3): BasicLayer(
      dim=512, input_resolution=(7, 7), depth=4
      (blocks): ModuleList(
        (0): MLLABlock(
          dim=512, input_resolution=(7, 7), num_heads=16, mlp_ratio=4.0
          (cpe1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=512, out_features=512, bias=True)
          (act_proj): Linear(in_features=512, out_features=512, bias=True)
          (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (act): SiLU()
          (attn): LinearAttention(
            dim=512, num_heads=16
            (qk): Linear(in_features=512, out_features=1024, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): MLLABlock(
          dim=512, input_resolution=(7, 7), num_heads=16, mlp_ratio=4.0
          (cpe1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=512, out_features=512, bias=True)
          (act_proj): Linear(in_features=512, out_features=512, bias=True)
          (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (act): SiLU()
          (attn): LinearAttention(
            dim=512, num_heads=16
            (qk): Linear(in_features=512, out_features=1024, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): MLLABlock(
          dim=512, input_resolution=(7, 7), num_heads=16, mlp_ratio=4.0
          (cpe1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=512, out_features=512, bias=True)
          (act_proj): Linear(in_features=512, out_features=512, bias=True)
          (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (act): SiLU()
          (attn): LinearAttention(
            dim=512, num_heads=16
            (qk): Linear(in_features=512, out_features=1024, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): MLLABlock(
          dim=512, input_resolution=(7, 7), num_heads=16, mlp_ratio=4.0
          (cpe1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (in_proj): Linear(in_features=512, out_features=512, bias=True)
          (act_proj): Linear(in_features=512, out_features=512, bias=True)
          (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (act): SiLU()
          (attn): LinearAttention(
            dim=512, num_heads=16
            (qk): Linear(in_features=512, out_features=1024, bias=True)
            (elu): ELU(alpha=1.0)
            (lepe): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (rope): RoPE()
          )
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (drop_path): DropPath()
          (cpe2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=512, out_features=1000, bias=True)
)
[2024-10-24 01:21:40 mlla_tiny] (main.py 152): INFO auto resuming from work_dir/mlla_tiny/default/max_acc.pth
[2024-10-24 01:21:40 mlla_tiny] (utils.py 14): INFO ==============> Resuming form work_dir/mlla_tiny/default/max_acc.pth....................
[2024-10-24 01:21:41 mlla_tiny] (utils.py 21): INFO <All keys matched successfully>
[2024-10-24 01:21:41 mlla_tiny] (utils.py 30): INFO => loaded successfully 'work_dir/mlla_tiny/default/max_acc.pth' (epoch 4)
[2024-10-24 01:23:04 mlla_tiny] (main.py 350): INFO  * Acc@1 0.430 Acc@5 1.650
[2024-10-24 01:23:04 mlla_tiny] (main.py 161): INFO Accuracy of the network on the 10000 test images: 0.4%
[2024-10-24 01:23:04 mlla_tiny] (main.py 168): INFO Model EMA decay 0.9999874975774891
[2024-10-24 01:23:36 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 01:23:36 mlla_tiny] (main.py 177): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 01:23:36 mlla_tiny] (main.py 185): INFO Start training
[2024-10-24 01:24:50 mlla_tiny] (main.py 296): INFO Train: [5/300][100/312]	eta 0:02:38 lr 0.000027	time 0.5295 (0.7438)	loss 6.8887 (6.8932)	grad_norm 0.8940 (1.0347)	mem 15420MB
[2024-10-24 01:25:42 mlla_tiny] (main.py 296): INFO Train: [5/300][200/312]	eta 0:01:11 lr 0.000029	time 0.4416 (0.6302)	loss 6.9094 (6.8910)	grad_norm 0.9255 (1.0778)	mem 15420MB
[2024-10-24 01:26:30 mlla_tiny] (main.py 296): INFO Train: [5/300][300/312]	eta 0:00:07 lr 0.000031	time 0.4279 (0.5797)	loss 6.8833 (6.8866)	grad_norm 1.5013 (1.1301)	mem 15420MB
[2024-10-24 01:26:35 mlla_tiny] (main.py 304): INFO EPOCH 5 training takes 0:02:59
[2024-10-24 01:27:06 mlla_tiny] (main.py 350): INFO  * Acc@1 0.440 Acc@5 2.290
[2024-10-24 01:27:06 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 0.4%
[2024-10-24 01:27:38 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 01:27:38 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 01:27:38 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_5.pth saving......
[2024-10-24 01:27:39 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_5.pth saved !!!
[2024-10-24 01:27:39 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 01:27:40 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 01:27:40 mlla_tiny] (main.py 205): INFO Max accuracy: 0.44%
[2024-10-24 01:27:40 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 01:28:19 mlla_tiny] (main.py 296): INFO Train: [6/300][100/312]	eta 0:01:22 lr 0.000033	time 0.3669 (0.3877)	loss 6.8648 (6.8678)	grad_norm 1.1943 (1.2919)	mem 15420MB
[2024-10-24 01:28:58 mlla_tiny] (main.py 296): INFO Train: [6/300][200/312]	eta 0:00:43 lr 0.000035	time 0.4037 (0.3890)	loss 6.8487 (6.8649)	grad_norm 1.3119 (1.3328)	mem 15420MB
[2024-10-24 01:29:36 mlla_tiny] (main.py 296): INFO Train: [6/300][300/312]	eta 0:00:05 lr 0.000037	time 0.4003 (0.3874)	loss 6.8122 (6.8606)	grad_norm 1.7258 (1.3862)	mem 15420MB
[2024-10-24 01:29:41 mlla_tiny] (main.py 304): INFO EPOCH 6 training takes 0:02:00
[2024-10-24 01:30:13 mlla_tiny] (main.py 350): INFO  * Acc@1 0.650 Acc@5 2.880
[2024-10-24 01:30:13 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 0.7%
[2024-10-24 01:30:44 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 01:30:44 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 01:30:44 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_6.pth saving......
[2024-10-24 01:30:45 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_6.pth saved !!!
[2024-10-24 01:30:45 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 01:30:45 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 01:30:45 mlla_tiny] (main.py 205): INFO Max accuracy: 0.65%
[2024-10-24 01:30:45 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 01:31:25 mlla_tiny] (main.py 296): INFO Train: [7/300][100/312]	eta 0:01:23 lr 0.000040	time 0.4066 (0.3933)	loss 6.8627 (6.8262)	grad_norm 1.4743 (1.7117)	mem 15420MB
[2024-10-24 01:32:04 mlla_tiny] (main.py 296): INFO Train: [7/300][200/312]	eta 0:00:44 lr 0.000042	time 0.3690 (0.3927)	loss 6.8458 (6.8261)	grad_norm 1.5240 (1.7227)	mem 15420MB
[2024-10-24 01:32:43 mlla_tiny] (main.py 296): INFO Train: [7/300][300/312]	eta 0:00:05 lr 0.000044	time 0.4297 (0.3925)	loss 6.8359 (6.8186)	grad_norm 2.6629 (1.8005)	mem 15420MB
[2024-10-24 01:32:48 mlla_tiny] (main.py 304): INFO EPOCH 7 training takes 0:02:02
[2024-10-24 01:33:19 mlla_tiny] (main.py 350): INFO  * Acc@1 0.750 Acc@5 3.670
[2024-10-24 01:33:19 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 0.8%
[2024-10-24 01:33:50 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 01:33:50 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 01:33:51 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_7.pth saving......
[2024-10-24 01:33:52 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_7.pth saved !!!
[2024-10-24 01:33:52 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 01:33:53 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 01:33:53 mlla_tiny] (main.py 205): INFO Max accuracy: 0.75%
[2024-10-24 01:33:53 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 01:34:32 mlla_tiny] (main.py 296): INFO Train: [8/300][100/312]	eta 0:01:24 lr 0.000046	time 0.4224 (0.3960)	loss 6.7930 (6.7843)	grad_norm 2.1654 (2.0505)	mem 15420MB
[2024-10-24 01:35:11 mlla_tiny] (main.py 296): INFO Train: [8/300][200/312]	eta 0:00:44 lr 0.000048	time 0.3765 (0.3930)	loss 6.8441 (6.7782)	grad_norm 2.5108 (2.1605)	mem 15420MB
[2024-10-24 01:35:50 mlla_tiny] (main.py 296): INFO Train: [8/300][300/312]	eta 0:00:05 lr 0.000050	time 0.3695 (0.3904)	loss 6.6070 (6.7735)	grad_norm 2.2978 (2.2233)	mem 15420MB
[2024-10-24 01:35:55 mlla_tiny] (main.py 304): INFO EPOCH 8 training takes 0:02:01
[2024-10-24 01:36:26 mlla_tiny] (main.py 350): INFO  * Acc@1 0.900 Acc@5 3.450
[2024-10-24 01:36:26 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 0.9%
[2024-10-24 01:36:57 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 01:36:57 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 01:36:57 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_8.pth saving......
[2024-10-24 01:36:58 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_8.pth saved !!!
[2024-10-24 01:36:58 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 01:36:59 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 01:36:59 mlla_tiny] (main.py 205): INFO Max accuracy: 0.90%
[2024-10-24 01:36:59 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 01:37:39 mlla_tiny] (main.py 296): INFO Train: [9/300][100/312]	eta 0:01:23 lr 0.000052	time 0.3849 (0.3938)	loss 6.7658 (6.7324)	grad_norm 1.9529 (2.5333)	mem 15420MB
[2024-10-24 01:38:18 mlla_tiny] (main.py 296): INFO Train: [9/300][200/312]	eta 0:00:44 lr 0.000054	time 0.3683 (0.3924)	loss 6.6180 (6.7363)	grad_norm 2.9545 (2.6047)	mem 15420MB
[2024-10-24 01:38:57 mlla_tiny] (main.py 296): INFO Train: [9/300][300/312]	eta 0:00:05 lr 0.000056	time 0.3997 (0.3935)	loss 6.7230 (6.7316)	grad_norm 2.5317 (2.7041)	mem 15420MB
[2024-10-24 01:39:02 mlla_tiny] (main.py 304): INFO EPOCH 9 training takes 0:02:02
[2024-10-24 01:39:33 mlla_tiny] (main.py 350): INFO  * Acc@1 1.500 Acc@5 5.480
[2024-10-24 01:39:33 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 1.5%
[2024-10-24 01:40:05 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 01:40:05 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 01:40:05 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_9.pth saving......
[2024-10-24 01:40:06 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_9.pth saved !!!
[2024-10-24 01:40:06 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 01:40:07 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 01:40:07 mlla_tiny] (main.py 205): INFO Max accuracy: 1.50%
[2024-10-24 01:40:07 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 01:40:46 mlla_tiny] (main.py 296): INFO Train: [10/300][100/312]	eta 0:01:23 lr 0.000058	time 0.3820 (0.3926)	loss 6.7500 (6.6935)	grad_norm 2.9317 (3.0161)	mem 15420MB
[2024-10-24 01:41:25 mlla_tiny] (main.py 296): INFO Train: [10/300][200/312]	eta 0:00:44 lr 0.000060	time 0.4115 (0.3923)	loss 6.7560 (6.6976)	grad_norm 2.8987 (3.0487)	mem 15420MB
[2024-10-24 01:42:04 mlla_tiny] (main.py 296): INFO Train: [10/300][300/312]	eta 0:00:05 lr 0.000062	time 0.3938 (0.3918)	loss 6.6845 (6.6988)	grad_norm 2.7615 (3.0003)	mem 15420MB
[2024-10-24 01:42:09 mlla_tiny] (main.py 304): INFO EPOCH 10 training takes 0:02:02
[2024-10-24 01:42:40 mlla_tiny] (main.py 350): INFO  * Acc@1 1.360 Acc@5 5.450
[2024-10-24 01:42:40 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 1.4%
[2024-10-24 01:43:12 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 01:43:12 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 01:43:12 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_10.pth saving......
[2024-10-24 01:43:13 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_10.pth saved !!!
[2024-10-24 01:43:13 mlla_tiny] (main.py 205): INFO Max accuracy: 1.50%
[2024-10-24 01:43:13 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 01:43:52 mlla_tiny] (main.py 296): INFO Train: [11/300][100/312]	eta 0:01:23 lr 0.000065	time 0.3738 (0.3937)	loss 6.7789 (6.6568)	grad_norm 2.5649 (3.2056)	mem 15420MB
[2024-10-24 01:44:31 mlla_tiny] (main.py 296): INFO Train: [11/300][200/312]	eta 0:00:44 lr 0.000067	time 0.3804 (0.3948)	loss 6.7515 (6.6670)	grad_norm 2.7068 (3.1896)	mem 15420MB
[2024-10-24 01:45:11 mlla_tiny] (main.py 296): INFO Train: [11/300][300/312]	eta 0:00:05 lr 0.000069	time 0.3694 (0.3964)	loss 6.6401 (6.6724)	grad_norm 3.8796 (3.1825)	mem 15420MB
[2024-10-24 01:45:16 mlla_tiny] (main.py 304): INFO EPOCH 11 training takes 0:02:03
[2024-10-24 01:45:48 mlla_tiny] (main.py 350): INFO  * Acc@1 1.550 Acc@5 5.540
[2024-10-24 01:45:48 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 1.6%
[2024-10-24 01:46:18 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 01:46:18 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 01:46:18 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_11.pth saving......
[2024-10-24 01:46:20 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_11.pth saved !!!
[2024-10-24 01:46:20 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 01:46:21 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 01:46:21 mlla_tiny] (main.py 205): INFO Max accuracy: 1.55%
[2024-10-24 01:46:21 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 01:46:59 mlla_tiny] (main.py 296): INFO Train: [12/300][100/312]	eta 0:01:22 lr 0.000071	time 0.3702 (0.3893)	loss 6.5219 (6.6352)	grad_norm 6.1874 (3.3362)	mem 15420MB
[2024-10-24 01:47:38 mlla_tiny] (main.py 296): INFO Train: [12/300][200/312]	eta 0:00:43 lr 0.000073	time 0.3682 (0.3864)	loss 6.4613 (6.6381)	grad_norm 4.2498 (3.2982)	mem 15420MB
[2024-10-24 01:48:17 mlla_tiny] (main.py 296): INFO Train: [12/300][300/312]	eta 0:00:05 lr 0.000075	time 0.4171 (0.3878)	loss 6.7135 (6.6435)	grad_norm 3.3254 (inf)	mem 15420MB
[2024-10-24 01:48:22 mlla_tiny] (main.py 304): INFO EPOCH 12 training takes 0:02:01
[2024-10-24 01:48:53 mlla_tiny] (main.py 350): INFO  * Acc@1 1.820 Acc@5 7.130
[2024-10-24 01:48:53 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 1.8%
[2024-10-24 01:49:24 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 01:49:24 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 01:49:24 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_12.pth saving......
[2024-10-24 01:49:25 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_12.pth saved !!!
[2024-10-24 01:49:25 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 01:49:26 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 01:49:26 mlla_tiny] (main.py 205): INFO Max accuracy: 1.82%
[2024-10-24 01:49:26 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 01:50:05 mlla_tiny] (main.py 296): INFO Train: [13/300][100/312]	eta 0:01:22 lr 0.000077	time 0.4288 (0.3885)	loss 6.6116 (6.6347)	grad_norm 2.1988 (inf)	mem 15420MB
[2024-10-24 01:50:43 mlla_tiny] (main.py 296): INFO Train: [13/300][200/312]	eta 0:00:43 lr 0.000079	time 0.3879 (0.3880)	loss 6.5459 (6.6406)	grad_norm 4.3102 (inf)	mem 15420MB
[2024-10-24 01:51:22 mlla_tiny] (main.py 296): INFO Train: [13/300][300/312]	eta 0:00:05 lr 0.000081	time 0.3863 (0.3894)	loss 6.5294 (6.6365)	grad_norm 3.7219 (inf)	mem 15420MB
[2024-10-24 01:51:27 mlla_tiny] (main.py 304): INFO EPOCH 13 training takes 0:02:01
[2024-10-24 01:51:58 mlla_tiny] (main.py 350): INFO  * Acc@1 2.180 Acc@5 7.720
[2024-10-24 01:51:58 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 2.2%
[2024-10-24 01:52:30 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 01:52:30 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 01:52:30 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_13.pth saving......
[2024-10-24 01:52:31 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_13.pth saved !!!
[2024-10-24 01:52:31 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 01:52:31 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 01:52:31 mlla_tiny] (main.py 205): INFO Max accuracy: 2.18%
[2024-10-24 01:52:31 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 01:53:11 mlla_tiny] (main.py 296): INFO Train: [14/300][100/312]	eta 0:01:23 lr 0.000083	time 0.3955 (0.3937)	loss 6.7051 (6.5807)	grad_norm 2.8336 (inf)	mem 15420MB
[2024-10-24 01:53:49 mlla_tiny] (main.py 296): INFO Train: [14/300][200/312]	eta 0:00:44 lr 0.000085	time 0.3743 (0.3899)	loss 6.4577 (6.5921)	grad_norm 2.9087 (inf)	mem 15420MB
[2024-10-24 01:54:28 mlla_tiny] (main.py 296): INFO Train: [14/300][300/312]	eta 0:00:05 lr 0.000087	time 0.3805 (0.3878)	loss 6.6932 (6.5942)	grad_norm 2.8840 (inf)	mem 15420MB
[2024-10-24 01:54:32 mlla_tiny] (main.py 304): INFO EPOCH 14 training takes 0:02:00
[2024-10-24 01:55:03 mlla_tiny] (main.py 350): INFO  * Acc@1 2.090 Acc@5 7.550
[2024-10-24 01:55:03 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 2.1%
[2024-10-24 01:55:35 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 01:55:35 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 01:55:35 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_14.pth saving......
[2024-10-24 01:55:36 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_14.pth saved !!!
[2024-10-24 01:55:36 mlla_tiny] (main.py 205): INFO Max accuracy: 2.18%
[2024-10-24 01:55:36 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 01:56:15 mlla_tiny] (main.py 296): INFO Train: [15/300][100/312]	eta 0:01:24 lr 0.000090	time 0.3675 (0.3949)	loss 6.6658 (6.5571)	grad_norm 3.2685 (3.3095)	mem 15420MB
[2024-10-24 01:56:54 mlla_tiny] (main.py 296): INFO Train: [15/300][200/312]	eta 0:00:44 lr 0.000092	time 0.4119 (0.3935)	loss 6.6406 (6.5729)	grad_norm 3.8238 (3.2542)	mem 15420MB
[2024-10-24 01:57:33 mlla_tiny] (main.py 296): INFO Train: [15/300][300/312]	eta 0:00:05 lr 0.000094	time 0.3706 (0.3921)	loss 6.5452 (6.5722)	grad_norm 3.5359 (3.2224)	mem 15420MB
[2024-10-24 01:57:38 mlla_tiny] (main.py 304): INFO EPOCH 15 training takes 0:02:02
[2024-10-24 01:58:09 mlla_tiny] (main.py 350): INFO  * Acc@1 2.750 Acc@5 9.500
[2024-10-24 01:58:09 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 2.8%
[2024-10-24 01:58:41 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 01:58:41 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 01:58:41 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_15.pth saving......
[2024-10-24 01:58:42 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_15.pth saved !!!
[2024-10-24 01:58:42 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 01:58:42 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 01:58:43 mlla_tiny] (main.py 205): INFO Max accuracy: 2.75%
[2024-10-24 01:58:43 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 01:59:22 mlla_tiny] (main.py 296): INFO Train: [16/300][100/312]	eta 0:01:24 lr 0.000096	time 0.3695 (0.3944)	loss 6.7453 (6.5244)	grad_norm 3.1431 (inf)	mem 15420MB
[2024-10-24 02:00:01 mlla_tiny] (main.py 296): INFO Train: [16/300][200/312]	eta 0:00:44 lr 0.000098	time 0.3705 (0.3903)	loss 6.7565 (6.5428)	grad_norm 2.4689 (inf)	mem 15420MB
[2024-10-24 02:00:40 mlla_tiny] (main.py 296): INFO Train: [16/300][300/312]	eta 0:00:05 lr 0.000100	time 0.3682 (0.3904)	loss 6.6613 (6.5457)	grad_norm 4.0662 (inf)	mem 15420MB
[2024-10-24 02:00:45 mlla_tiny] (main.py 304): INFO EPOCH 16 training takes 0:02:01
[2024-10-24 02:01:16 mlla_tiny] (main.py 350): INFO  * Acc@1 2.780 Acc@5 9.580
[2024-10-24 02:01:16 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 2.8%
[2024-10-24 02:01:48 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:01:48 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:01:48 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_16.pth saving......
[2024-10-24 02:01:49 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_16.pth saved !!!
[2024-10-24 02:01:49 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:01:50 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:01:50 mlla_tiny] (main.py 205): INFO Max accuracy: 2.78%
[2024-10-24 02:01:50 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:02:29 mlla_tiny] (main.py 296): INFO Train: [17/300][100/312]	eta 0:01:22 lr 0.000102	time 0.3667 (0.3878)	loss 6.4272 (6.5188)	grad_norm 3.0459 (3.3200)	mem 15420MB
[2024-10-24 02:03:07 mlla_tiny] (main.py 296): INFO Train: [17/300][200/312]	eta 0:00:43 lr 0.000104	time 0.3686 (0.3863)	loss 6.5114 (6.5090)	grad_norm 3.4618 (inf)	mem 15420MB
[2024-10-24 02:03:46 mlla_tiny] (main.py 296): INFO Train: [17/300][300/312]	eta 0:00:05 lr 0.000106	time 0.3914 (0.3886)	loss 6.5984 (6.5115)	grad_norm 3.2959 (inf)	mem 15420MB
[2024-10-24 02:03:51 mlla_tiny] (main.py 304): INFO EPOCH 17 training takes 0:02:01
[2024-10-24 02:04:22 mlla_tiny] (main.py 350): INFO  * Acc@1 2.980 Acc@5 10.680
[2024-10-24 02:04:22 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 3.0%
[2024-10-24 02:04:53 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:04:53 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:04:53 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_17.pth saving......
[2024-10-24 02:04:54 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_17.pth saved !!!
[2024-10-24 02:04:54 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:04:55 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:04:55 mlla_tiny] (main.py 205): INFO Max accuracy: 2.98%
[2024-10-24 02:04:55 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:05:34 mlla_tiny] (main.py 296): INFO Train: [18/300][100/312]	eta 0:01:23 lr 0.000108	time 0.3978 (0.3941)	loss 6.3392 (6.4524)	grad_norm 3.7287 (3.6487)	mem 15420MB
[2024-10-24 02:06:13 mlla_tiny] (main.py 296): INFO Train: [18/300][200/312]	eta 0:00:44 lr 0.000110	time 0.3987 (0.3912)	loss 6.6703 (6.4686)	grad_norm 4.2379 (inf)	mem 15420MB
[2024-10-24 02:06:52 mlla_tiny] (main.py 296): INFO Train: [18/300][300/312]	eta 0:00:05 lr 0.000112	time 0.3781 (0.3898)	loss 6.3974 (6.4706)	grad_norm 2.9744 (inf)	mem 15420MB
[2024-10-24 02:06:57 mlla_tiny] (main.py 304): INFO EPOCH 18 training takes 0:02:01
[2024-10-24 02:07:28 mlla_tiny] (main.py 350): INFO  * Acc@1 3.550 Acc@5 11.600
[2024-10-24 02:07:28 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 3.5%
[2024-10-24 02:07:59 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.480
[2024-10-24 02:07:59 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:07:59 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_18.pth saving......
[2024-10-24 02:08:00 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_18.pth saved !!!
[2024-10-24 02:08:00 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:08:01 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:08:01 mlla_tiny] (main.py 205): INFO Max accuracy: 3.55%
[2024-10-24 02:08:01 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:08:41 mlla_tiny] (main.py 296): INFO Train: [19/300][100/312]	eta 0:01:24 lr 0.000114	time 0.3689 (0.3966)	loss 6.5713 (6.4662)	grad_norm 3.6033 (inf)	mem 15420MB
[2024-10-24 02:09:20 mlla_tiny] (main.py 296): INFO Train: [19/300][200/312]	eta 0:00:44 lr 0.000116	time 0.3797 (0.3912)	loss 6.5962 (6.4665)	grad_norm 2.6498 (inf)	mem 15420MB
[2024-10-24 02:09:58 mlla_tiny] (main.py 296): INFO Train: [19/300][300/312]	eta 0:00:05 lr 0.000118	time 0.3881 (0.3895)	loss 6.2935 (6.4673)	grad_norm 3.3645 (inf)	mem 15420MB
[2024-10-24 02:10:03 mlla_tiny] (main.py 304): INFO EPOCH 19 training takes 0:02:01
[2024-10-24 02:10:34 mlla_tiny] (main.py 350): INFO  * Acc@1 4.460 Acc@5 13.270
[2024-10-24 02:10:34 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 4.5%
[2024-10-24 02:11:05 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:11:05 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:11:05 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_19.pth saving......
[2024-10-24 02:11:06 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_19.pth saved !!!
[2024-10-24 02:11:06 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:11:07 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:11:07 mlla_tiny] (main.py 205): INFO Max accuracy: 4.46%
[2024-10-24 02:11:07 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:11:46 mlla_tiny] (main.py 296): INFO Train: [20/300][100/312]	eta 0:01:24 lr 0.000121	time 0.4304 (0.3967)	loss 6.4138 (6.4369)	grad_norm 4.0579 (inf)	mem 15420MB
[2024-10-24 02:12:25 mlla_tiny] (main.py 296): INFO Train: [20/300][200/312]	eta 0:00:44 lr 0.000123	time 0.3732 (0.3911)	loss 6.0020 (6.4243)	grad_norm 3.8713 (inf)	mem 15420MB
[2024-10-24 02:13:04 mlla_tiny] (main.py 296): INFO Train: [20/300][300/312]	eta 0:00:05 lr 0.000125	time 0.3719 (0.3898)	loss 6.4224 (6.4260)	grad_norm 2.7907 (inf)	mem 15420MB
[2024-10-24 02:13:08 mlla_tiny] (main.py 304): INFO EPOCH 20 training takes 0:02:01
[2024-10-24 02:13:40 mlla_tiny] (main.py 350): INFO  * Acc@1 4.700 Acc@5 14.880
[2024-10-24 02:13:40 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 4.7%
[2024-10-24 02:14:11 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:14:11 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:14:11 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_20.pth saving......
[2024-10-24 02:14:12 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_20.pth saved !!!
[2024-10-24 02:14:12 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:14:13 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:14:13 mlla_tiny] (main.py 205): INFO Max accuracy: 4.70%
[2024-10-24 02:14:13 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:14:52 mlla_tiny] (main.py 296): INFO Train: [21/300][100/312]	eta 0:01:24 lr 0.000124	time 0.3846 (0.3952)	loss 6.2509 (6.3921)	grad_norm 4.6807 (inf)	mem 15420MB
[2024-10-24 02:15:31 mlla_tiny] (main.py 296): INFO Train: [21/300][200/312]	eta 0:00:44 lr 0.000124	time 0.4013 (0.3916)	loss 6.4893 (6.3975)	grad_norm 2.4985 (inf)	mem 15420MB
[2024-10-24 02:16:11 mlla_tiny] (main.py 296): INFO Train: [21/300][300/312]	eta 0:00:05 lr 0.000124	time 0.3955 (0.3924)	loss 6.1380 (6.4073)	grad_norm 4.8620 (inf)	mem 15420MB
[2024-10-24 02:16:15 mlla_tiny] (main.py 304): INFO EPOCH 21 training takes 0:02:02
[2024-10-24 02:16:46 mlla_tiny] (main.py 350): INFO  * Acc@1 5.220 Acc@5 15.600
[2024-10-24 02:16:46 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 5.2%
[2024-10-24 02:17:18 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:17:18 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:17:18 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_21.pth saving......
[2024-10-24 02:17:18 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_21.pth saved !!!
[2024-10-24 02:17:18 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:17:19 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:17:19 mlla_tiny] (main.py 205): INFO Max accuracy: 5.22%
[2024-10-24 02:17:19 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:17:59 mlla_tiny] (main.py 296): INFO Train: [22/300][100/312]	eta 0:01:23 lr 0.000123	time 0.3800 (0.3913)	loss 6.3896 (6.3635)	grad_norm 3.3455 (inf)	mem 15420MB
[2024-10-24 02:18:37 mlla_tiny] (main.py 296): INFO Train: [22/300][200/312]	eta 0:00:43 lr 0.000123	time 0.3761 (0.3894)	loss 6.2013 (6.3695)	grad_norm 4.5230 (inf)	mem 15420MB
[2024-10-24 02:19:17 mlla_tiny] (main.py 296): INFO Train: [22/300][300/312]	eta 0:00:05 lr 0.000123	time 0.4244 (0.3912)	loss 6.1695 (6.3650)	grad_norm 4.0019 (inf)	mem 15420MB
[2024-10-24 02:19:21 mlla_tiny] (main.py 304): INFO EPOCH 22 training takes 0:02:01
[2024-10-24 02:19:53 mlla_tiny] (main.py 350): INFO  * Acc@1 5.580 Acc@5 16.290
[2024-10-24 02:19:53 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 5.6%
[2024-10-24 02:20:25 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:20:25 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:20:25 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_22.pth saving......
[2024-10-24 02:20:26 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_22.pth saved !!!
[2024-10-24 02:20:26 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:20:27 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:20:27 mlla_tiny] (main.py 205): INFO Max accuracy: 5.58%
[2024-10-24 02:20:27 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:21:07 mlla_tiny] (main.py 296): INFO Train: [23/300][100/312]	eta 0:01:24 lr 0.000123	time 0.3696 (0.3986)	loss 6.3622 (6.3414)	grad_norm 4.7703 (3.6351)	mem 15420MB
[2024-10-24 02:21:46 mlla_tiny] (main.py 296): INFO Train: [23/300][200/312]	eta 0:00:44 lr 0.000123	time 0.4197 (0.3953)	loss 6.1031 (6.3342)	grad_norm 3.7854 (inf)	mem 15420MB
[2024-10-24 02:22:25 mlla_tiny] (main.py 296): INFO Train: [23/300][300/312]	eta 0:00:05 lr 0.000123	time 0.3725 (0.3948)	loss 6.3629 (6.3469)	grad_norm 3.3102 (inf)	mem 15420MB
[2024-10-24 02:22:30 mlla_tiny] (main.py 304): INFO EPOCH 23 training takes 0:02:03
[2024-10-24 02:23:01 mlla_tiny] (main.py 350): INFO  * Acc@1 6.670 Acc@5 18.720
[2024-10-24 02:23:01 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 6.7%
[2024-10-24 02:23:32 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:23:32 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:23:32 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_23.pth saving......
[2024-10-24 02:23:33 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_23.pth saved !!!
[2024-10-24 02:23:33 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:23:34 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:23:34 mlla_tiny] (main.py 205): INFO Max accuracy: 6.67%
[2024-10-24 02:23:34 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:24:14 mlla_tiny] (main.py 296): INFO Train: [24/300][100/312]	eta 0:01:23 lr 0.000123	time 0.3767 (0.3930)	loss 6.3695 (6.3302)	grad_norm 2.6963 (inf)	mem 15420MB
[2024-10-24 02:24:52 mlla_tiny] (main.py 296): INFO Train: [24/300][200/312]	eta 0:00:44 lr 0.000123	time 0.3703 (0.3902)	loss 6.1916 (6.3183)	grad_norm 3.6392 (inf)	mem 15420MB
[2024-10-24 02:25:31 mlla_tiny] (main.py 296): INFO Train: [24/300][300/312]	eta 0:00:05 lr 0.000123	time 0.3702 (0.3899)	loss 5.8580 (6.3131)	grad_norm 4.5569 (inf)	mem 15420MB
[2024-10-24 02:25:36 mlla_tiny] (main.py 304): INFO EPOCH 24 training takes 0:02:01
[2024-10-24 02:26:07 mlla_tiny] (main.py 350): INFO  * Acc@1 6.550 Acc@5 19.200
[2024-10-24 02:26:07 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 6.5%
[2024-10-24 02:26:39 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:26:39 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:26:39 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_24.pth saving......
[2024-10-24 02:26:39 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_24.pth saved !!!
[2024-10-24 02:26:39 mlla_tiny] (main.py 205): INFO Max accuracy: 6.67%
[2024-10-24 02:26:39 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:27:19 mlla_tiny] (main.py 296): INFO Train: [25/300][100/312]	eta 0:01:24 lr 0.000123	time 0.3896 (0.3944)	loss 6.3128 (6.3457)	grad_norm 3.9835 (inf)	mem 15420MB
[2024-10-24 02:27:58 mlla_tiny] (main.py 296): INFO Train: [25/300][200/312]	eta 0:00:44 lr 0.000123	time 0.4089 (0.3942)	loss 6.3007 (6.3104)	grad_norm 3.6114 (inf)	mem 15420MB
[2024-10-24 02:28:38 mlla_tiny] (main.py 296): INFO Train: [25/300][300/312]	eta 0:00:05 lr 0.000123	time 0.3896 (0.3939)	loss 6.4991 (6.2888)	grad_norm 3.3205 (inf)	mem 15420MB
[2024-10-24 02:28:42 mlla_tiny] (main.py 304): INFO EPOCH 25 training takes 0:02:02
[2024-10-24 02:29:14 mlla_tiny] (main.py 350): INFO  * Acc@1 6.910 Acc@5 20.090
[2024-10-24 02:29:14 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 6.9%
[2024-10-24 02:29:45 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:29:45 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:29:45 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_25.pth saving......
[2024-10-24 02:29:46 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_25.pth saved !!!
[2024-10-24 02:29:46 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:29:47 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:29:47 mlla_tiny] (main.py 205): INFO Max accuracy: 6.91%
[2024-10-24 02:29:47 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:30:27 mlla_tiny] (main.py 296): INFO Train: [26/300][100/312]	eta 0:01:24 lr 0.000123	time 0.4010 (0.3944)	loss 6.3182 (6.2549)	grad_norm 3.2077 (inf)	mem 15420MB
[2024-10-24 02:31:06 mlla_tiny] (main.py 296): INFO Train: [26/300][200/312]	eta 0:00:44 lr 0.000123	time 0.4148 (0.3937)	loss 6.2644 (6.2429)	grad_norm 3.8245 (inf)	mem 15420MB
[2024-10-24 02:31:45 mlla_tiny] (main.py 296): INFO Train: [26/300][300/312]	eta 0:00:05 lr 0.000123	time 0.3828 (0.3936)	loss 6.2182 (6.2446)	grad_norm 4.5650 (inf)	mem 15420MB
[2024-10-24 02:31:50 mlla_tiny] (main.py 304): INFO EPOCH 26 training takes 0:02:02
[2024-10-24 02:32:21 mlla_tiny] (main.py 350): INFO  * Acc@1 7.260 Acc@5 19.720
[2024-10-24 02:32:21 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 7.3%
[2024-10-24 02:32:53 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:32:53 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:32:53 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_26.pth saving......
[2024-10-24 02:32:54 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_26.pth saved !!!
[2024-10-24 02:32:54 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:32:55 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:32:55 mlla_tiny] (main.py 205): INFO Max accuracy: 7.26%
[2024-10-24 02:32:55 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:33:34 mlla_tiny] (main.py 296): INFO Train: [27/300][100/312]	eta 0:01:23 lr 0.000123	time 0.3693 (0.3915)	loss 6.4755 (6.1802)	grad_norm 4.3094 (inf)	mem 15420MB
[2024-10-24 02:34:13 mlla_tiny] (main.py 296): INFO Train: [27/300][200/312]	eta 0:00:44 lr 0.000123	time 0.3696 (0.3897)	loss 6.0782 (6.1897)	grad_norm 3.7566 (inf)	mem 15420MB
[2024-10-24 02:34:52 mlla_tiny] (main.py 296): INFO Train: [27/300][300/312]	eta 0:00:05 lr 0.000123	time 0.3753 (0.3893)	loss 6.2248 (6.2053)	grad_norm 3.5533 (inf)	mem 15420MB
[2024-10-24 02:34:56 mlla_tiny] (main.py 304): INFO EPOCH 27 training takes 0:02:01
[2024-10-24 02:35:28 mlla_tiny] (main.py 350): INFO  * Acc@1 8.430 Acc@5 22.490
[2024-10-24 02:35:28 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 8.4%
[2024-10-24 02:35:59 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:35:59 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:35:59 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_27.pth saving......
[2024-10-24 02:36:00 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_27.pth saved !!!
[2024-10-24 02:36:00 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:36:01 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:36:01 mlla_tiny] (main.py 205): INFO Max accuracy: 8.43%
[2024-10-24 02:36:01 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:36:41 mlla_tiny] (main.py 296): INFO Train: [28/300][100/312]	eta 0:01:24 lr 0.000122	time 0.3680 (0.3957)	loss 5.8053 (6.1988)	grad_norm 4.0902 (inf)	mem 15420MB
[2024-10-24 02:37:20 mlla_tiny] (main.py 296): INFO Train: [28/300][200/312]	eta 0:00:44 lr 0.000122	time 0.3780 (0.3932)	loss 6.5025 (6.1987)	grad_norm 4.7641 (inf)	mem 15420MB
[2024-10-24 02:37:58 mlla_tiny] (main.py 296): INFO Train: [28/300][300/312]	eta 0:00:05 lr 0.000122	time 0.3682 (0.3905)	loss 5.9983 (6.1953)	grad_norm 4.8840 (inf)	mem 15420MB
[2024-10-24 02:38:03 mlla_tiny] (main.py 304): INFO EPOCH 28 training takes 0:02:01
[2024-10-24 02:38:34 mlla_tiny] (main.py 350): INFO  * Acc@1 8.950 Acc@5 24.100
[2024-10-24 02:38:34 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 8.9%
[2024-10-24 02:39:06 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:39:06 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:39:06 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_28.pth saving......
[2024-10-24 02:39:07 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_28.pth saved !!!
[2024-10-24 02:39:07 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:39:08 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:39:08 mlla_tiny] (main.py 205): INFO Max accuracy: 8.95%
[2024-10-24 02:39:08 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:39:47 mlla_tiny] (main.py 296): INFO Train: [29/300][100/312]	eta 0:01:23 lr 0.000122	time 0.3783 (0.3918)	loss 6.3672 (6.1348)	grad_norm 4.3365 (inf)	mem 15420MB
[2024-10-24 02:40:26 mlla_tiny] (main.py 296): INFO Train: [29/300][200/312]	eta 0:00:44 lr 0.000122	time 0.3884 (0.3904)	loss 5.8837 (6.1501)	grad_norm 5.1590 (inf)	mem 15420MB
[2024-10-24 02:41:05 mlla_tiny] (main.py 296): INFO Train: [29/300][300/312]	eta 0:00:05 lr 0.000122	time 0.3771 (0.3912)	loss 5.9004 (6.1505)	grad_norm 4.1475 (inf)	mem 15420MB
[2024-10-24 02:41:10 mlla_tiny] (main.py 304): INFO EPOCH 29 training takes 0:02:02
[2024-10-24 02:41:41 mlla_tiny] (main.py 350): INFO  * Acc@1 9.460 Acc@5 25.330
[2024-10-24 02:41:41 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 9.5%
[2024-10-24 02:42:12 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:42:12 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:42:12 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_29.pth saving......
[2024-10-24 02:42:13 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_29.pth saved !!!
[2024-10-24 02:42:13 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:42:14 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:42:14 mlla_tiny] (main.py 205): INFO Max accuracy: 9.46%
[2024-10-24 02:42:14 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:42:53 mlla_tiny] (main.py 296): INFO Train: [30/300][100/312]	eta 0:01:23 lr 0.000122	time 0.3844 (0.3919)	loss 5.9125 (6.1641)	grad_norm 5.5530 (inf)	mem 15420MB
[2024-10-24 02:43:32 mlla_tiny] (main.py 296): INFO Train: [30/300][200/312]	eta 0:00:44 lr 0.000122	time 0.4012 (0.3894)	loss 6.3577 (6.1480)	grad_norm 3.5133 (inf)	mem 15420MB
[2024-10-24 02:44:11 mlla_tiny] (main.py 296): INFO Train: [30/300][300/312]	eta 0:00:05 lr 0.000122	time 0.3741 (0.3893)	loss 5.6730 (6.1423)	grad_norm 4.5714 (inf)	mem 15420MB
[2024-10-24 02:44:15 mlla_tiny] (main.py 304): INFO EPOCH 30 training takes 0:02:01
[2024-10-24 02:44:47 mlla_tiny] (main.py 350): INFO  * Acc@1 10.230 Acc@5 26.310
[2024-10-24 02:44:47 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 10.2%
[2024-10-24 02:45:18 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:45:18 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:45:18 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_30.pth saving......
[2024-10-24 02:45:19 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_30.pth saved !!!
[2024-10-24 02:45:19 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:45:21 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:45:21 mlla_tiny] (main.py 205): INFO Max accuracy: 10.23%
[2024-10-24 02:45:21 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:46:00 mlla_tiny] (main.py 296): INFO Train: [31/300][100/312]	eta 0:01:24 lr 0.000122	time 0.3826 (0.3972)	loss 6.4228 (6.1078)	grad_norm 3.4568 (inf)	mem 15420MB
[2024-10-24 02:46:40 mlla_tiny] (main.py 296): INFO Train: [31/300][200/312]	eta 0:00:44 lr 0.000122	time 0.3679 (0.3938)	loss 6.4192 (6.1051)	grad_norm 4.3591 (inf)	mem 15420MB
[2024-10-24 02:47:19 mlla_tiny] (main.py 296): INFO Train: [31/300][300/312]	eta 0:00:05 lr 0.000122	time 0.4040 (0.3928)	loss 5.7903 (6.1140)	grad_norm 4.6077 (inf)	mem 15420MB
[2024-10-24 02:47:23 mlla_tiny] (main.py 304): INFO EPOCH 31 training takes 0:02:02
[2024-10-24 02:47:55 mlla_tiny] (main.py 350): INFO  * Acc@1 10.530 Acc@5 26.280
[2024-10-24 02:47:55 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 10.5%
[2024-10-24 02:48:26 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:48:26 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:48:26 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_31.pth saving......
[2024-10-24 02:48:27 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_31.pth saved !!!
[2024-10-24 02:48:27 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:48:28 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:48:28 mlla_tiny] (main.py 205): INFO Max accuracy: 10.53%
[2024-10-24 02:48:28 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:49:08 mlla_tiny] (main.py 296): INFO Train: [32/300][100/312]	eta 0:01:24 lr 0.000122	time 0.3759 (0.3959)	loss 6.3848 (6.0999)	grad_norm 3.8044 (4.1950)	mem 15420MB
[2024-10-24 02:49:47 mlla_tiny] (main.py 296): INFO Train: [32/300][200/312]	eta 0:00:44 lr 0.000122	time 0.4170 (0.3926)	loss 5.9933 (6.1210)	grad_norm 3.8852 (inf)	mem 15420MB
[2024-10-24 02:50:26 mlla_tiny] (main.py 296): INFO Train: [32/300][300/312]	eta 0:00:05 lr 0.000122	time 0.3683 (0.3929)	loss 6.0778 (6.1038)	grad_norm 3.6499 (inf)	mem 15420MB
[2024-10-24 02:50:31 mlla_tiny] (main.py 304): INFO EPOCH 32 training takes 0:02:02
[2024-10-24 02:51:02 mlla_tiny] (main.py 350): INFO  * Acc@1 10.790 Acc@5 27.350
[2024-10-24 02:51:02 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 10.8%
[2024-10-24 02:51:33 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:51:33 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:51:33 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_32.pth saving......
[2024-10-24 02:51:34 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_32.pth saved !!!
[2024-10-24 02:51:34 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:51:35 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:51:35 mlla_tiny] (main.py 205): INFO Max accuracy: 10.79%
[2024-10-24 02:51:35 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:52:15 mlla_tiny] (main.py 296): INFO Train: [33/300][100/312]	eta 0:01:24 lr 0.000121	time 0.3768 (0.3972)	loss 5.9428 (6.1146)	grad_norm 3.8194 (inf)	mem 15420MB
[2024-10-24 02:52:54 mlla_tiny] (main.py 296): INFO Train: [33/300][200/312]	eta 0:00:44 lr 0.000121	time 0.3938 (0.3947)	loss 6.3096 (6.0971)	grad_norm 4.1197 (inf)	mem 15420MB
[2024-10-24 02:53:33 mlla_tiny] (main.py 296): INFO Train: [33/300][300/312]	eta 0:00:05 lr 0.000121	time 0.3975 (0.3928)	loss 6.4842 (6.0863)	grad_norm 5.3378 (inf)	mem 15420MB
[2024-10-24 02:53:38 mlla_tiny] (main.py 304): INFO EPOCH 33 training takes 0:02:02
[2024-10-24 02:54:09 mlla_tiny] (main.py 350): INFO  * Acc@1 11.130 Acc@5 28.130
[2024-10-24 02:54:09 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 11.1%
[2024-10-24 02:54:40 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:54:40 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:54:40 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_33.pth saving......
[2024-10-24 02:54:41 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_33.pth saved !!!
[2024-10-24 02:54:41 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:54:42 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:54:42 mlla_tiny] (main.py 205): INFO Max accuracy: 11.13%
[2024-10-24 02:54:42 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:55:22 mlla_tiny] (main.py 296): INFO Train: [34/300][100/312]	eta 0:01:26 lr 0.000121	time 0.4133 (0.4048)	loss 6.1623 (6.0298)	grad_norm 3.9728 (inf)	mem 15420MB
[2024-10-24 02:56:02 mlla_tiny] (main.py 296): INFO Train: [34/300][200/312]	eta 0:00:45 lr 0.000121	time 0.3889 (0.3994)	loss 5.7469 (6.0163)	grad_norm 5.7403 (inf)	mem 15420MB
[2024-10-24 02:56:41 mlla_tiny] (main.py 296): INFO Train: [34/300][300/312]	eta 0:00:05 lr 0.000121	time 0.4245 (0.3972)	loss 6.3947 (6.0208)	grad_norm 3.7771 (inf)	mem 15420MB
[2024-10-24 02:56:46 mlla_tiny] (main.py 304): INFO EPOCH 34 training takes 0:02:03
[2024-10-24 02:57:17 mlla_tiny] (main.py 350): INFO  * Acc@1 11.920 Acc@5 29.540
[2024-10-24 02:57:17 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 11.9%
[2024-10-24 02:57:49 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 02:57:49 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 02:57:49 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_34.pth saving......
[2024-10-24 02:57:50 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_34.pth saved !!!
[2024-10-24 02:57:50 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 02:57:51 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 02:57:51 mlla_tiny] (main.py 205): INFO Max accuracy: 11.92%
[2024-10-24 02:57:51 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 02:58:31 mlla_tiny] (main.py 296): INFO Train: [35/300][100/312]	eta 0:01:24 lr 0.000121	time 0.4145 (0.3958)	loss 6.2335 (6.0586)	grad_norm 4.8809 (inf)	mem 15420MB
[2024-10-24 02:59:10 mlla_tiny] (main.py 296): INFO Train: [35/300][200/312]	eta 0:00:44 lr 0.000121	time 0.4664 (0.3929)	loss 5.9107 (6.0385)	grad_norm 3.7350 (inf)	mem 15420MB
[2024-10-24 02:59:49 mlla_tiny] (main.py 296): INFO Train: [35/300][300/312]	eta 0:00:05 lr 0.000121	time 0.3731 (0.3932)	loss 6.2851 (6.0193)	grad_norm 3.5990 (inf)	mem 15420MB
[2024-10-24 02:59:54 mlla_tiny] (main.py 304): INFO EPOCH 35 training takes 0:02:02
[2024-10-24 03:00:25 mlla_tiny] (main.py 350): INFO  * Acc@1 12.520 Acc@5 30.300
[2024-10-24 03:00:25 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 12.5%
[2024-10-24 03:00:56 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 03:00:56 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:00:56 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_35.pth saving......
[2024-10-24 03:00:57 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_35.pth saved !!!
[2024-10-24 03:00:57 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 03:00:58 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 03:00:58 mlla_tiny] (main.py 205): INFO Max accuracy: 12.52%
[2024-10-24 03:00:58 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:01:38 mlla_tiny] (main.py 296): INFO Train: [36/300][100/312]	eta 0:01:24 lr 0.000121	time 0.3683 (0.3967)	loss 6.0255 (5.9940)	grad_norm 5.7659 (inf)	mem 15420MB
[2024-10-24 03:02:17 mlla_tiny] (main.py 296): INFO Train: [36/300][200/312]	eta 0:00:44 lr 0.000121	time 0.3694 (0.3939)	loss 5.8651 (5.9901)	grad_norm 4.5376 (inf)	mem 15420MB
[2024-10-24 03:02:56 mlla_tiny] (main.py 296): INFO Train: [36/300][300/312]	eta 0:00:05 lr 0.000121	time 0.3762 (0.3936)	loss 6.1232 (5.9957)	grad_norm 3.3412 (inf)	mem 15420MB
[2024-10-24 03:03:01 mlla_tiny] (main.py 304): INFO EPOCH 36 training takes 0:02:03
[2024-10-24 03:03:32 mlla_tiny] (main.py 350): INFO  * Acc@1 13.550 Acc@5 32.470
[2024-10-24 03:03:32 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 13.6%
[2024-10-24 03:04:04 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 03:04:04 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:04:04 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_36.pth saving......
[2024-10-24 03:04:05 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_36.pth saved !!!
[2024-10-24 03:04:05 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 03:04:06 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 03:04:06 mlla_tiny] (main.py 205): INFO Max accuracy: 13.55%
[2024-10-24 03:04:06 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:04:45 mlla_tiny] (main.py 296): INFO Train: [37/300][100/312]	eta 0:01:23 lr 0.000121	time 0.3752 (0.3912)	loss 5.8633 (6.0292)	grad_norm 5.5553 (nan)	mem 15420MB
[2024-10-24 03:05:23 mlla_tiny] (main.py 296): INFO Train: [37/300][200/312]	eta 0:00:44 lr 0.000121	time 0.3704 (0.3894)	loss 6.0373 (6.0028)	grad_norm 5.5325 (nan)	mem 15420MB
[2024-10-24 03:06:02 mlla_tiny] (main.py 296): INFO Train: [37/300][300/312]	eta 0:00:05 lr 0.000120	time 0.3695 (0.3898)	loss 6.1199 (6.0043)	grad_norm 3.9738 (nan)	mem 15420MB
[2024-10-24 03:06:07 mlla_tiny] (main.py 304): INFO EPOCH 37 training takes 0:02:01
[2024-10-24 03:06:38 mlla_tiny] (main.py 350): INFO  * Acc@1 13.790 Acc@5 32.650
[2024-10-24 03:06:38 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 13.8%
[2024-10-24 03:07:10 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 03:07:10 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:07:10 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_37.pth saving......
[2024-10-24 03:07:11 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_37.pth saved !!!
[2024-10-24 03:07:11 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 03:07:11 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 03:07:11 mlla_tiny] (main.py 205): INFO Max accuracy: 13.79%
[2024-10-24 03:07:11 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:07:51 mlla_tiny] (main.py 296): INFO Train: [38/300][100/312]	eta 0:01:24 lr 0.000120	time 0.3995 (0.3976)	loss 6.1495 (5.9372)	grad_norm 4.4512 (inf)	mem 15420MB
[2024-10-24 03:08:30 mlla_tiny] (main.py 296): INFO Train: [38/300][200/312]	eta 0:00:44 lr 0.000120	time 0.3683 (0.3949)	loss 5.7247 (5.9251)	grad_norm 4.6779 (nan)	mem 15420MB
[2024-10-24 03:09:10 mlla_tiny] (main.py 296): INFO Train: [38/300][300/312]	eta 0:00:05 lr 0.000120	time 0.4216 (0.3955)	loss 5.3413 (5.9188)	grad_norm 5.1141 (nan)	mem 15420MB
[2024-10-24 03:09:15 mlla_tiny] (main.py 304): INFO EPOCH 38 training takes 0:02:03
[2024-10-24 03:09:46 mlla_tiny] (main.py 350): INFO  * Acc@1 14.780 Acc@5 34.330
[2024-10-24 03:09:46 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 14.8%
[2024-10-24 03:10:18 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 03:10:18 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:10:18 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_38.pth saving......
[2024-10-24 03:10:19 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_38.pth saved !!!
[2024-10-24 03:10:19 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 03:10:20 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 03:10:20 mlla_tiny] (main.py 205): INFO Max accuracy: 14.78%
[2024-10-24 03:10:20 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:10:59 mlla_tiny] (main.py 296): INFO Train: [39/300][100/312]	eta 0:01:23 lr 0.000120	time 0.3988 (0.3931)	loss 6.0473 (5.9351)	grad_norm 4.5935 (inf)	mem 15420MB
[2024-10-24 03:11:38 mlla_tiny] (main.py 296): INFO Train: [39/300][200/312]	eta 0:00:44 lr 0.000120	time 0.4318 (0.3943)	loss 5.9194 (5.9147)	grad_norm 3.5630 (inf)	mem 15420MB
[2024-10-24 03:12:18 mlla_tiny] (main.py 296): INFO Train: [39/300][300/312]	eta 0:00:05 lr 0.000120	time 0.3830 (0.3934)	loss 6.0400 (5.9273)	grad_norm 3.3786 (inf)	mem 15420MB
[2024-10-24 03:12:22 mlla_tiny] (main.py 304): INFO EPOCH 39 training takes 0:02:02
[2024-10-24 03:12:54 mlla_tiny] (main.py 350): INFO  * Acc@1 15.390 Acc@5 34.280
[2024-10-24 03:12:54 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 15.4%
[2024-10-24 03:13:25 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 03:13:25 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:13:25 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_39.pth saving......
[2024-10-24 03:13:26 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_39.pth saved !!!
[2024-10-24 03:13:26 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 03:13:27 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 03:13:27 mlla_tiny] (main.py 205): INFO Max accuracy: 15.39%
[2024-10-24 03:13:27 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:14:07 mlla_tiny] (main.py 296): INFO Train: [40/300][100/312]	eta 0:01:24 lr 0.000120	time 0.3713 (0.3972)	loss 6.2020 (5.9292)	grad_norm 4.7718 (inf)	mem 15420MB
[2024-10-24 03:14:46 mlla_tiny] (main.py 296): INFO Train: [40/300][200/312]	eta 0:00:44 lr 0.000120	time 0.3894 (0.3953)	loss 5.3128 (5.9135)	grad_norm 5.9190 (inf)	mem 15420MB
[2024-10-24 03:15:25 mlla_tiny] (main.py 296): INFO Train: [40/300][300/312]	eta 0:00:05 lr 0.000120	time 0.3687 (0.3948)	loss 5.5539 (5.9084)	grad_norm 8.3779 (inf)	mem 15420MB
[2024-10-24 03:15:30 mlla_tiny] (main.py 304): INFO EPOCH 40 training takes 0:02:03
[2024-10-24 03:16:01 mlla_tiny] (main.py 350): INFO  * Acc@1 14.550 Acc@5 33.670
[2024-10-24 03:16:01 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 14.6%
[2024-10-24 03:16:33 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 03:16:33 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:16:33 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_40.pth saving......
[2024-10-24 03:16:36 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_40.pth saved !!!
[2024-10-24 03:16:36 mlla_tiny] (main.py 205): INFO Max accuracy: 15.39%
[2024-10-24 03:16:36 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:17:16 mlla_tiny] (main.py 296): INFO Train: [41/300][100/312]	eta 0:01:25 lr 0.000120	time 0.3692 (0.3994)	loss 5.4018 (5.8561)	grad_norm 4.1304 (inf)	mem 15420MB
[2024-10-24 03:17:55 mlla_tiny] (main.py 296): INFO Train: [41/300][200/312]	eta 0:00:44 lr 0.000119	time 0.3678 (0.3937)	loss 5.9855 (5.8858)	grad_norm 5.8869 (inf)	mem 15420MB
[2024-10-24 03:18:34 mlla_tiny] (main.py 296): INFO Train: [41/300][300/312]	eta 0:00:05 lr 0.000119	time 0.3837 (0.3932)	loss 6.2770 (5.9040)	grad_norm 3.5799 (inf)	mem 15420MB
[2024-10-24 03:18:39 mlla_tiny] (main.py 304): INFO EPOCH 41 training takes 0:02:02
[2024-10-24 03:19:10 mlla_tiny] (main.py 350): INFO  * Acc@1 15.840 Acc@5 36.190
[2024-10-24 03:19:10 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 15.8%
[2024-10-24 03:19:41 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 03:19:41 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:19:41 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_41.pth saving......
[2024-10-24 03:19:42 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_41.pth saved !!!
[2024-10-24 03:19:42 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 03:19:43 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 03:19:43 mlla_tiny] (main.py 205): INFO Max accuracy: 15.84%
[2024-10-24 03:19:43 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:20:22 mlla_tiny] (main.py 296): INFO Train: [42/300][100/312]	eta 0:01:23 lr 0.000119	time 0.3954 (0.3936)	loss 6.2402 (5.8026)	grad_norm 4.4489 (inf)	mem 15420MB
[2024-10-24 03:21:02 mlla_tiny] (main.py 296): INFO Train: [42/300][200/312]	eta 0:00:44 lr 0.000119	time 0.4806 (0.3948)	loss 6.0251 (5.8164)	grad_norm 6.5443 (inf)	mem 15420MB
[2024-10-24 03:21:41 mlla_tiny] (main.py 296): INFO Train: [42/300][300/312]	eta 0:00:05 lr 0.000119	time 0.3691 (0.3932)	loss 5.4630 (5.8288)	grad_norm 5.0032 (inf)	mem 15420MB
[2024-10-24 03:21:46 mlla_tiny] (main.py 304): INFO EPOCH 42 training takes 0:02:02
[2024-10-24 03:22:17 mlla_tiny] (main.py 350): INFO  * Acc@1 16.280 Acc@5 36.410
[2024-10-24 03:22:17 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 16.3%
[2024-10-24 03:22:48 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 03:22:48 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:22:48 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_42.pth saving......
[2024-10-24 03:22:49 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_42.pth saved !!!
[2024-10-24 03:22:49 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 03:22:50 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 03:22:50 mlla_tiny] (main.py 205): INFO Max accuracy: 16.28%
[2024-10-24 03:22:50 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:23:29 mlla_tiny] (main.py 296): INFO Train: [43/300][100/312]	eta 0:01:23 lr 0.000119	time 0.3699 (0.3927)	loss 5.1044 (5.8061)	grad_norm 6.7071 (inf)	mem 15420MB
[2024-10-24 03:24:08 mlla_tiny] (main.py 296): INFO Train: [43/300][200/312]	eta 0:00:44 lr 0.000119	time 0.3803 (0.3919)	loss 5.7941 (5.8350)	grad_norm 4.0309 (inf)	mem 15420MB
[2024-10-24 03:24:47 mlla_tiny] (main.py 296): INFO Train: [43/300][300/312]	eta 0:00:05 lr 0.000119	time 0.4641 (0.3906)	loss 5.4390 (5.8077)	grad_norm 7.7639 (inf)	mem 15420MB
[2024-10-24 03:24:51 mlla_tiny] (main.py 304): INFO EPOCH 43 training takes 0:02:01
[2024-10-24 03:25:22 mlla_tiny] (main.py 350): INFO  * Acc@1 17.080 Acc@5 37.690
[2024-10-24 03:25:22 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 17.1%
[2024-10-24 03:25:53 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 03:25:53 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:25:53 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_43.pth saving......
[2024-10-24 03:25:55 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_43.pth saved !!!
[2024-10-24 03:25:55 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 03:25:56 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 03:25:56 mlla_tiny] (main.py 205): INFO Max accuracy: 17.08%
[2024-10-24 03:25:56 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:26:35 mlla_tiny] (main.py 296): INFO Train: [44/300][100/312]	eta 0:01:23 lr 0.000119	time 0.4232 (0.3921)	loss 6.1985 (5.7484)	grad_norm 4.0943 (inf)	mem 15420MB
[2024-10-24 03:27:14 mlla_tiny] (main.py 296): INFO Train: [44/300][200/312]	eta 0:00:43 lr 0.000119	time 0.3698 (0.3875)	loss 5.8566 (5.7635)	grad_norm 4.0697 (inf)	mem 15420MB
[2024-10-24 03:27:52 mlla_tiny] (main.py 296): INFO Train: [44/300][300/312]	eta 0:00:05 lr 0.000119	time 0.3800 (0.3869)	loss 5.8677 (5.7597)	grad_norm 6.0269 (inf)	mem 15420MB
[2024-10-24 03:27:57 mlla_tiny] (main.py 304): INFO EPOCH 44 training takes 0:02:00
[2024-10-24 03:28:28 mlla_tiny] (main.py 350): INFO  * Acc@1 18.440 Acc@5 39.040
[2024-10-24 03:28:28 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 18.4%
[2024-10-24 03:28:59 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 03:28:59 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:28:59 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_44.pth saving......
[2024-10-24 03:29:00 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_44.pth saved !!!
[2024-10-24 03:29:00 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 03:29:01 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 03:29:01 mlla_tiny] (main.py 205): INFO Max accuracy: 18.44%
[2024-10-24 03:29:01 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:29:41 mlla_tiny] (main.py 296): INFO Train: [45/300][100/312]	eta 0:01:24 lr 0.000118	time 0.3688 (0.3944)	loss 6.1781 (5.7919)	grad_norm 3.9669 (inf)	mem 15420MB
[2024-10-24 03:30:20 mlla_tiny] (main.py 296): INFO Train: [45/300][200/312]	eta 0:00:44 lr 0.000118	time 0.4023 (0.3934)	loss 6.0791 (5.8152)	grad_norm 5.2325 (inf)	mem 15420MB
[2024-10-24 03:30:59 mlla_tiny] (main.py 296): INFO Train: [45/300][300/312]	eta 0:00:05 lr 0.000118	time 0.3693 (0.3928)	loss 5.6637 (5.8130)	grad_norm 3.9157 (inf)	mem 15420MB
[2024-10-24 03:31:04 mlla_tiny] (main.py 304): INFO EPOCH 45 training takes 0:02:02
[2024-10-24 03:31:35 mlla_tiny] (main.py 350): INFO  * Acc@1 18.430 Acc@5 38.640
[2024-10-24 03:31:35 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 18.4%
[2024-10-24 03:32:06 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 03:32:06 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:32:06 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_45.pth saving......
[2024-10-24 03:32:07 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_45.pth saved !!!
[2024-10-24 03:32:07 mlla_tiny] (main.py 205): INFO Max accuracy: 18.44%
[2024-10-24 03:32:07 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:32:47 mlla_tiny] (main.py 296): INFO Train: [46/300][100/312]	eta 0:01:24 lr 0.000118	time 0.3686 (0.3963)	loss 6.0455 (5.7806)	grad_norm 4.8179 (inf)	mem 15420MB
[2024-10-24 03:33:26 mlla_tiny] (main.py 296): INFO Train: [46/300][200/312]	eta 0:00:44 lr 0.000118	time 0.3747 (0.3944)	loss 5.6565 (5.7808)	grad_norm 4.1941 (inf)	mem 15420MB
[2024-10-24 03:34:05 mlla_tiny] (main.py 296): INFO Train: [46/300][300/312]	eta 0:00:05 lr 0.000118	time 0.3681 (0.3918)	loss 6.2233 (5.7867)	grad_norm 4.4481 (inf)	mem 15420MB
[2024-10-24 03:34:09 mlla_tiny] (main.py 304): INFO EPOCH 46 training takes 0:02:02
[2024-10-24 03:34:41 mlla_tiny] (main.py 350): INFO  * Acc@1 17.880 Acc@5 37.950
[2024-10-24 03:34:41 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 17.9%
[2024-10-24 03:35:12 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 03:35:12 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:35:12 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_46.pth saving......
[2024-10-24 03:35:13 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_46.pth saved !!!
[2024-10-24 03:35:13 mlla_tiny] (main.py 205): INFO Max accuracy: 18.44%
[2024-10-24 03:35:13 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:35:53 mlla_tiny] (main.py 296): INFO Train: [47/300][100/312]	eta 0:01:24 lr 0.000118	time 0.4096 (0.3957)	loss 4.9927 (5.7316)	grad_norm 7.0602 (inf)	mem 15420MB
[2024-10-24 03:36:31 mlla_tiny] (main.py 296): INFO Train: [47/300][200/312]	eta 0:00:44 lr 0.000118	time 0.3696 (0.3908)	loss 5.1215 (5.7231)	grad_norm 4.5675 (inf)	mem 15420MB
[2024-10-24 03:37:10 mlla_tiny] (main.py 296): INFO Train: [47/300][300/312]	eta 0:00:05 lr 0.000118	time 0.4523 (0.3901)	loss 4.9827 (5.7246)	grad_norm 5.7464 (inf)	mem 15420MB
[2024-10-24 03:37:15 mlla_tiny] (main.py 304): INFO EPOCH 47 training takes 0:02:01
[2024-10-24 03:37:47 mlla_tiny] (main.py 350): INFO  * Acc@1 20.040 Acc@5 41.490
[2024-10-24 03:37:47 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 20.0%
[2024-10-24 03:38:18 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 03:38:18 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:38:18 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_47.pth saving......
[2024-10-24 03:38:19 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_47.pth saved !!!
[2024-10-24 03:38:19 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 03:38:20 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 03:38:20 mlla_tiny] (main.py 205): INFO Max accuracy: 20.04%
[2024-10-24 03:38:20 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:39:00 mlla_tiny] (main.py 296): INFO Train: [48/300][100/312]	eta 0:01:25 lr 0.000118	time 0.3916 (0.4010)	loss 5.3592 (5.7407)	grad_norm 4.0895 (inf)	mem 15420MB
[2024-10-24 03:39:39 mlla_tiny] (main.py 296): INFO Train: [48/300][200/312]	eta 0:00:44 lr 0.000117	time 0.3692 (0.3957)	loss 6.2283 (5.6904)	grad_norm 4.3125 (inf)	mem 15420MB
[2024-10-24 03:40:18 mlla_tiny] (main.py 296): INFO Train: [48/300][300/312]	eta 0:00:05 lr 0.000117	time 0.3981 (0.3945)	loss 5.7370 (5.6802)	grad_norm 4.2897 (inf)	mem 15420MB
[2024-10-24 03:40:23 mlla_tiny] (main.py 304): INFO EPOCH 48 training takes 0:02:02
[2024-10-24 03:40:54 mlla_tiny] (main.py 350): INFO  * Acc@1 20.060 Acc@5 41.440
[2024-10-24 03:40:54 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 20.1%
[2024-10-24 03:41:26 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.470
[2024-10-24 03:41:26 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:41:26 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_48.pth saving......
[2024-10-24 03:41:27 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_48.pth saved !!!
[2024-10-24 03:41:27 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 03:41:28 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 03:41:28 mlla_tiny] (main.py 205): INFO Max accuracy: 20.06%
[2024-10-24 03:41:28 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:42:07 mlla_tiny] (main.py 296): INFO Train: [49/300][100/312]	eta 0:01:23 lr 0.000117	time 0.3915 (0.3941)	loss 5.6423 (5.6948)	grad_norm 4.1264 (inf)	mem 15420MB
[2024-10-24 03:42:46 mlla_tiny] (main.py 296): INFO Train: [49/300][200/312]	eta 0:00:44 lr 0.000117	time 0.3810 (0.3909)	loss 5.9729 (5.6910)	grad_norm 3.8728 (inf)	mem 15420MB
[2024-10-24 03:43:25 mlla_tiny] (main.py 296): INFO Train: [49/300][300/312]	eta 0:00:05 lr 0.000117	time 0.4557 (0.3900)	loss 6.1292 (5.7022)	grad_norm 5.2726 (inf)	mem 15420MB
[2024-10-24 03:43:29 mlla_tiny] (main.py 304): INFO EPOCH 49 training takes 0:02:01
[2024-10-24 03:44:00 mlla_tiny] (main.py 350): INFO  * Acc@1 20.280 Acc@5 42.090
[2024-10-24 03:44:00 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 20.3%
[2024-10-24 03:44:32 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 03:44:32 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:44:32 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_49.pth saving......
[2024-10-24 03:44:33 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_49.pth saved !!!
[2024-10-24 03:44:33 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 03:44:34 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 03:44:34 mlla_tiny] (main.py 205): INFO Max accuracy: 20.28%
[2024-10-24 03:44:34 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:45:13 mlla_tiny] (main.py 296): INFO Train: [50/300][100/312]	eta 0:01:24 lr 0.000117	time 0.3899 (0.3954)	loss 5.9111 (5.7077)	grad_norm 5.2387 (inf)	mem 15420MB
[2024-10-24 03:45:53 mlla_tiny] (main.py 296): INFO Train: [50/300][200/312]	eta 0:00:44 lr 0.000117	time 0.3898 (0.3947)	loss 5.5328 (5.6874)	grad_norm 5.3805 (inf)	mem 15420MB
[2024-10-24 03:46:32 mlla_tiny] (main.py 296): INFO Train: [50/300][300/312]	eta 0:00:05 lr 0.000117	time 0.3906 (0.3931)	loss 5.9370 (5.6905)	grad_norm 4.7300 (inf)	mem 15420MB
[2024-10-24 03:46:36 mlla_tiny] (main.py 304): INFO EPOCH 50 training takes 0:02:02
[2024-10-24 03:47:08 mlla_tiny] (main.py 350): INFO  * Acc@1 21.180 Acc@5 43.140
[2024-10-24 03:47:08 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 21.2%
[2024-10-24 03:47:39 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 03:47:39 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:47:39 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_50.pth saving......
[2024-10-24 03:47:40 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_50.pth saved !!!
[2024-10-24 03:47:40 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 03:47:41 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 03:47:41 mlla_tiny] (main.py 205): INFO Max accuracy: 21.18%
[2024-10-24 03:47:41 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:48:20 mlla_tiny] (main.py 296): INFO Train: [51/300][100/312]	eta 0:01:23 lr 0.000117	time 0.3868 (0.3942)	loss 6.0893 (5.7033)	grad_norm 4.9003 (inf)	mem 15420MB
[2024-10-24 03:48:59 mlla_tiny] (main.py 296): INFO Train: [51/300][200/312]	eta 0:00:44 lr 0.000117	time 0.4292 (0.3918)	loss 6.0547 (5.7223)	grad_norm 4.0556 (inf)	mem 15420MB
[2024-10-24 03:49:38 mlla_tiny] (main.py 296): INFO Train: [51/300][300/312]	eta 0:00:05 lr 0.000116	time 0.4258 (0.3912)	loss 5.0745 (5.7065)	grad_norm 5.4481 (inf)	mem 15420MB
[2024-10-24 03:49:43 mlla_tiny] (main.py 304): INFO EPOCH 51 training takes 0:02:01
[2024-10-24 03:50:14 mlla_tiny] (main.py 350): INFO  * Acc@1 20.740 Acc@5 43.300
[2024-10-24 03:50:14 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 20.7%
[2024-10-24 03:50:45 mlla_tiny] (main.py 350): INFO  * Acc@1 0.090 Acc@5 0.500
[2024-10-24 03:50:45 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:50:45 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_51.pth saving......
[2024-10-24 03:50:46 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_51.pth saved !!!
[2024-10-24 03:50:46 mlla_tiny] (main.py 205): INFO Max accuracy: 21.18%
[2024-10-24 03:50:46 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:51:25 mlla_tiny] (main.py 296): INFO Train: [52/300][100/312]	eta 0:01:23 lr 0.000116	time 0.3800 (0.3918)	loss 5.0442 (5.5254)	grad_norm 8.9191 (inf)	mem 15420MB
[2024-10-24 03:52:04 mlla_tiny] (main.py 296): INFO Train: [52/300][200/312]	eta 0:00:43 lr 0.000116	time 0.3814 (0.3878)	loss 5.6481 (5.5754)	grad_norm 5.3619 (inf)	mem 15420MB
[2024-10-24 03:52:42 mlla_tiny] (main.py 296): INFO Train: [52/300][300/312]	eta 0:00:05 lr 0.000116	time 0.3701 (0.3877)	loss 5.5940 (5.6052)	grad_norm 5.1943 (inf)	mem 15420MB
[2024-10-24 03:52:47 mlla_tiny] (main.py 304): INFO EPOCH 52 training takes 0:02:00
[2024-10-24 03:53:18 mlla_tiny] (main.py 350): INFO  * Acc@1 21.660 Acc@5 43.770
[2024-10-24 03:53:18 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 21.7%
[2024-10-24 03:53:49 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 03:53:49 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:53:49 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_52.pth saving......
[2024-10-24 03:53:50 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_52.pth saved !!!
[2024-10-24 03:53:50 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 03:53:51 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 03:53:51 mlla_tiny] (main.py 205): INFO Max accuracy: 21.66%
[2024-10-24 03:53:51 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:54:30 mlla_tiny] (main.py 296): INFO Train: [53/300][100/312]	eta 0:01:23 lr 0.000116	time 0.3721 (0.3907)	loss 5.8909 (5.5880)	grad_norm 4.6752 (inf)	mem 15420MB
[2024-10-24 03:55:08 mlla_tiny] (main.py 296): INFO Train: [53/300][200/312]	eta 0:00:43 lr 0.000116	time 0.4155 (0.3855)	loss 5.8955 (5.6233)	grad_norm 6.4415 (inf)	mem 15420MB
[2024-10-24 03:55:47 mlla_tiny] (main.py 296): INFO Train: [53/300][300/312]	eta 0:00:05 lr 0.000116	time 0.3684 (0.3858)	loss 6.1285 (5.6309)	grad_norm 4.1926 (inf)	mem 15420MB
[2024-10-24 03:55:51 mlla_tiny] (main.py 304): INFO EPOCH 53 training takes 0:02:00
[2024-10-24 03:56:23 mlla_tiny] (main.py 350): INFO  * Acc@1 21.990 Acc@5 45.210
[2024-10-24 03:56:23 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 22.0%
[2024-10-24 03:56:54 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 03:56:54 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 03:56:54 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_53.pth saving......
[2024-10-24 03:56:55 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_53.pth saved !!!
[2024-10-24 03:56:55 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 03:56:56 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 03:56:56 mlla_tiny] (main.py 205): INFO Max accuracy: 21.99%
[2024-10-24 03:56:56 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 03:57:36 mlla_tiny] (main.py 296): INFO Train: [54/300][100/312]	eta 0:01:26 lr 0.000116	time 0.4757 (0.4053)	loss 4.9896 (5.5844)	grad_norm 6.1300 (inf)	mem 15420MB
[2024-10-24 03:58:15 mlla_tiny] (main.py 296): INFO Train: [54/300][200/312]	eta 0:00:44 lr 0.000115	time 0.3755 (0.3970)	loss 6.0841 (5.5576)	grad_norm 4.9914 (inf)	mem 15420MB
[2024-10-24 03:58:54 mlla_tiny] (main.py 296): INFO Train: [54/300][300/312]	eta 0:00:05 lr 0.000115	time 0.3751 (0.3946)	loss 5.0216 (5.5919)	grad_norm 5.1716 (inf)	mem 15420MB
[2024-10-24 03:58:59 mlla_tiny] (main.py 304): INFO EPOCH 54 training takes 0:02:03
[2024-10-24 03:59:30 mlla_tiny] (main.py 350): INFO  * Acc@1 22.480 Acc@5 45.550
[2024-10-24 03:59:30 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 22.5%
[2024-10-24 04:00:01 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:00:01 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:00:02 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_54.pth saving......
[2024-10-24 04:00:02 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_54.pth saved !!!
[2024-10-24 04:00:02 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 04:00:03 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 04:00:03 mlla_tiny] (main.py 205): INFO Max accuracy: 22.48%
[2024-10-24 04:00:03 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:00:43 mlla_tiny] (main.py 296): INFO Train: [55/300][100/312]	eta 0:01:23 lr 0.000115	time 0.3671 (0.3937)	loss 5.0673 (5.5412)	grad_norm 6.6585 (inf)	mem 15420MB
[2024-10-24 04:01:22 mlla_tiny] (main.py 296): INFO Train: [55/300][200/312]	eta 0:00:44 lr 0.000115	time 0.4029 (0.3922)	loss 5.6429 (5.5678)	grad_norm 4.5270 (inf)	mem 15420MB
[2024-10-24 04:02:01 mlla_tiny] (main.py 296): INFO Train: [55/300][300/312]	eta 0:00:05 lr 0.000115	time 0.3813 (0.3915)	loss 5.8015 (5.5981)	grad_norm 5.1409 (inf)	mem 15420MB
[2024-10-24 04:02:05 mlla_tiny] (main.py 304): INFO EPOCH 55 training takes 0:02:02
[2024-10-24 04:02:36 mlla_tiny] (main.py 350): INFO  * Acc@1 22.100 Acc@5 45.300
[2024-10-24 04:02:36 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 22.1%
[2024-10-24 04:03:07 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:03:07 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:03:07 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_55.pth saving......
[2024-10-24 04:03:09 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_55.pth saved !!!
[2024-10-24 04:03:09 mlla_tiny] (main.py 205): INFO Max accuracy: 22.48%
[2024-10-24 04:03:09 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:03:48 mlla_tiny] (main.py 296): INFO Train: [56/300][100/312]	eta 0:01:23 lr 0.000115	time 0.3688 (0.3918)	loss 4.4551 (5.4513)	grad_norm 7.3308 (inf)	mem 15420MB
[2024-10-24 04:04:26 mlla_tiny] (main.py 296): INFO Train: [56/300][200/312]	eta 0:00:43 lr 0.000115	time 0.3978 (0.3889)	loss 5.0985 (5.5015)	grad_norm 5.6996 (inf)	mem 15420MB
[2024-10-24 04:05:05 mlla_tiny] (main.py 296): INFO Train: [56/300][300/312]	eta 0:00:05 lr 0.000115	time 0.3683 (0.3890)	loss 4.7794 (5.5331)	grad_norm 5.9966 (inf)	mem 15420MB
[2024-10-24 04:05:10 mlla_tiny] (main.py 304): INFO EPOCH 56 training takes 0:02:01
[2024-10-24 04:05:41 mlla_tiny] (main.py 350): INFO  * Acc@1 23.070 Acc@5 45.910
[2024-10-24 04:05:41 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 23.1%
[2024-10-24 04:06:13 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:06:13 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:06:13 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_56.pth saving......
[2024-10-24 04:06:14 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_56.pth saved !!!
[2024-10-24 04:06:14 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 04:06:15 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 04:06:15 mlla_tiny] (main.py 205): INFO Max accuracy: 23.07%
[2024-10-24 04:06:15 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:06:55 mlla_tiny] (main.py 296): INFO Train: [57/300][100/312]	eta 0:01:24 lr 0.000115	time 0.3782 (0.3970)	loss 5.4704 (5.4931)	grad_norm 7.2061 (inf)	mem 15420MB
[2024-10-24 04:07:34 mlla_tiny] (main.py 296): INFO Train: [57/300][200/312]	eta 0:00:44 lr 0.000114	time 0.4310 (0.3945)	loss 5.2482 (5.4888)	grad_norm 6.2767 (inf)	mem 15420MB
[2024-10-24 04:08:14 mlla_tiny] (main.py 296): INFO Train: [57/300][300/312]	eta 0:00:05 lr 0.000114	time 0.3695 (0.3947)	loss 6.0458 (5.5206)	grad_norm 4.4201 (inf)	mem 15420MB
[2024-10-24 04:08:18 mlla_tiny] (main.py 304): INFO EPOCH 57 training takes 0:02:03
[2024-10-24 04:08:49 mlla_tiny] (main.py 350): INFO  * Acc@1 24.120 Acc@5 46.720
[2024-10-24 04:08:49 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 24.1%
[2024-10-24 04:09:20 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:09:20 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:09:20 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_57.pth saving......
[2024-10-24 04:09:21 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_57.pth saved !!!
[2024-10-24 04:09:21 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 04:09:22 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 04:09:22 mlla_tiny] (main.py 205): INFO Max accuracy: 24.12%
[2024-10-24 04:09:22 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:10:01 mlla_tiny] (main.py 296): INFO Train: [58/300][100/312]	eta 0:01:23 lr 0.000114	time 0.3671 (0.3921)	loss 4.6028 (5.4727)	grad_norm 7.6220 (inf)	mem 15420MB
[2024-10-24 04:10:40 mlla_tiny] (main.py 296): INFO Train: [58/300][200/312]	eta 0:00:44 lr 0.000114	time 0.4475 (0.3903)	loss 5.5502 (5.4879)	grad_norm 5.5562 (inf)	mem 15420MB
[2024-10-24 04:11:19 mlla_tiny] (main.py 296): INFO Train: [58/300][300/312]	eta 0:00:05 lr 0.000114	time 0.3977 (0.3906)	loss 5.7847 (5.5088)	grad_norm 5.8084 (inf)	mem 15420MB
[2024-10-24 04:11:24 mlla_tiny] (main.py 304): INFO EPOCH 58 training takes 0:02:01
[2024-10-24 04:11:55 mlla_tiny] (main.py 350): INFO  * Acc@1 23.800 Acc@5 46.800
[2024-10-24 04:11:55 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 23.8%
[2024-10-24 04:12:26 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:12:26 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:12:26 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_58.pth saving......
[2024-10-24 04:12:27 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_58.pth saved !!!
[2024-10-24 04:12:27 mlla_tiny] (main.py 205): INFO Max accuracy: 24.12%
[2024-10-24 04:12:27 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:13:07 mlla_tiny] (main.py 296): INFO Train: [59/300][100/312]	eta 0:01:25 lr 0.000114	time 0.4098 (0.3996)	loss 5.2753 (5.4247)	grad_norm 4.3542 (inf)	mem 15420MB
[2024-10-24 04:13:46 mlla_tiny] (main.py 296): INFO Train: [59/300][200/312]	eta 0:00:44 lr 0.000114	time 0.3930 (0.3946)	loss 6.0059 (5.4463)	grad_norm 4.5776 (inf)	mem 15420MB
[2024-10-24 04:14:25 mlla_tiny] (main.py 296): INFO Train: [59/300][300/312]	eta 0:00:05 lr 0.000114	time 0.4046 (0.3936)	loss 5.7787 (5.4735)	grad_norm 4.4961 (inf)	mem 15420MB
[2024-10-24 04:14:30 mlla_tiny] (main.py 304): INFO EPOCH 59 training takes 0:02:02
[2024-10-24 04:15:01 mlla_tiny] (main.py 350): INFO  * Acc@1 23.670 Acc@5 47.120
[2024-10-24 04:15:01 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 23.7%
[2024-10-24 04:15:32 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:15:32 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:15:32 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_59.pth saving......
[2024-10-24 04:15:33 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_59.pth saved !!!
[2024-10-24 04:15:33 mlla_tiny] (main.py 205): INFO Max accuracy: 24.12%
[2024-10-24 04:15:33 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:16:13 mlla_tiny] (main.py 296): INFO Train: [60/300][100/312]	eta 0:01:25 lr 0.000113	time 0.3921 (0.4005)	loss 5.8588 (5.4264)	grad_norm 5.7310 (nan)	mem 15420MB
[2024-10-24 04:16:52 mlla_tiny] (main.py 296): INFO Train: [60/300][200/312]	eta 0:00:44 lr 0.000113	time 0.3875 (0.3954)	loss 4.9301 (5.4425)	grad_norm 7.8381 (nan)	mem 15420MB
[2024-10-24 04:17:31 mlla_tiny] (main.py 296): INFO Train: [60/300][300/312]	eta 0:00:05 lr 0.000113	time 0.3704 (0.3926)	loss 5.2082 (5.4407)	grad_norm 6.9543 (nan)	mem 15420MB
[2024-10-24 04:17:36 mlla_tiny] (main.py 304): INFO EPOCH 60 training takes 0:02:02
[2024-10-24 04:18:07 mlla_tiny] (main.py 350): INFO  * Acc@1 24.670 Acc@5 48.940
[2024-10-24 04:18:07 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 24.7%
[2024-10-24 04:18:39 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:18:39 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:18:39 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_60.pth saving......
[2024-10-24 04:18:39 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_60.pth saved !!!
[2024-10-24 04:18:39 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 04:18:40 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 04:18:40 mlla_tiny] (main.py 205): INFO Max accuracy: 24.67%
[2024-10-24 04:18:40 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:19:20 mlla_tiny] (main.py 296): INFO Train: [61/300][100/312]	eta 0:01:24 lr 0.000113	time 0.3852 (0.3973)	loss 5.6954 (5.4422)	grad_norm 5.4921 (inf)	mem 15420MB
[2024-10-24 04:20:00 mlla_tiny] (main.py 296): INFO Train: [61/300][200/312]	eta 0:00:44 lr 0.000113	time 0.3832 (0.3953)	loss 5.8231 (5.4600)	grad_norm 4.4937 (inf)	mem 15420MB
[2024-10-24 04:20:38 mlla_tiny] (main.py 296): INFO Train: [61/300][300/312]	eta 0:00:05 lr 0.000113	time 0.3703 (0.3932)	loss 4.6512 (5.4489)	grad_norm 5.4241 (inf)	mem 15420MB
[2024-10-24 04:20:43 mlla_tiny] (main.py 304): INFO EPOCH 61 training takes 0:02:02
[2024-10-24 04:21:15 mlla_tiny] (main.py 350): INFO  * Acc@1 25.600 Acc@5 49.990
[2024-10-24 04:21:15 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 25.6%
[2024-10-24 04:21:46 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:21:46 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:21:46 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_61.pth saving......
[2024-10-24 04:21:47 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_61.pth saved !!!
[2024-10-24 04:21:47 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 04:21:48 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 04:21:48 mlla_tiny] (main.py 205): INFO Max accuracy: 25.60%
[2024-10-24 04:21:48 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:22:28 mlla_tiny] (main.py 296): INFO Train: [62/300][100/312]	eta 0:01:25 lr 0.000113	time 0.4408 (0.3992)	loss 4.4199 (5.3763)	grad_norm 5.6982 (inf)	mem 15420MB
[2024-10-24 04:23:08 mlla_tiny] (main.py 296): INFO Train: [62/300][200/312]	eta 0:00:44 lr 0.000113	time 0.3769 (0.3964)	loss 4.9794 (5.3955)	grad_norm 6.4350 (inf)	mem 15420MB
[2024-10-24 04:23:46 mlla_tiny] (main.py 296): INFO Train: [62/300][300/312]	eta 0:00:05 lr 0.000112	time 0.3746 (0.3940)	loss 4.6743 (5.4125)	grad_norm 6.9548 (inf)	mem 15420MB
[2024-10-24 04:23:51 mlla_tiny] (main.py 304): INFO EPOCH 62 training takes 0:02:02
[2024-10-24 04:24:23 mlla_tiny] (main.py 350): INFO  * Acc@1 24.980 Acc@5 48.760
[2024-10-24 04:24:23 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 25.0%
[2024-10-24 04:24:55 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:24:55 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:24:55 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_62.pth saving......
[2024-10-24 04:24:56 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_62.pth saved !!!
[2024-10-24 04:24:56 mlla_tiny] (main.py 205): INFO Max accuracy: 25.60%
[2024-10-24 04:24:56 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:25:35 mlla_tiny] (main.py 296): INFO Train: [63/300][100/312]	eta 0:01:23 lr 0.000112	time 0.4449 (0.3918)	loss 5.7781 (5.4326)	grad_norm 5.1190 (inf)	mem 15420MB
[2024-10-24 04:26:14 mlla_tiny] (main.py 296): INFO Train: [63/300][200/312]	eta 0:00:44 lr 0.000112	time 0.3668 (0.3934)	loss 5.1651 (5.4835)	grad_norm 4.2339 (inf)	mem 15420MB
[2024-10-24 04:26:53 mlla_tiny] (main.py 296): INFO Train: [63/300][300/312]	eta 0:00:05 lr 0.000112	time 0.3874 (0.3914)	loss 5.8111 (5.4667)	grad_norm 4.1332 (inf)	mem 15420MB
[2024-10-24 04:26:58 mlla_tiny] (main.py 304): INFO EPOCH 63 training takes 0:02:01
[2024-10-24 04:27:29 mlla_tiny] (main.py 350): INFO  * Acc@1 26.410 Acc@5 50.490
[2024-10-24 04:27:29 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 26.4%
[2024-10-24 04:28:00 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:28:00 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:28:00 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_63.pth saving......
[2024-10-24 04:28:01 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_63.pth saved !!!
[2024-10-24 04:28:01 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 04:28:02 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 04:28:02 mlla_tiny] (main.py 205): INFO Max accuracy: 26.41%
[2024-10-24 04:28:02 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:28:41 mlla_tiny] (main.py 296): INFO Train: [64/300][100/312]	eta 0:01:22 lr 0.000112	time 0.3834 (0.3893)	loss 5.1657 (5.3845)	grad_norm 5.1069 (inf)	mem 15420MB
[2024-10-24 04:29:20 mlla_tiny] (main.py 296): INFO Train: [64/300][200/312]	eta 0:00:44 lr 0.000112	time 0.4169 (0.3899)	loss 6.0319 (5.3790)	grad_norm 6.1495 (inf)	mem 15420MB
[2024-10-24 04:29:59 mlla_tiny] (main.py 296): INFO Train: [64/300][300/312]	eta 0:00:05 lr 0.000112	time 0.3687 (0.3889)	loss 5.9436 (5.3703)	grad_norm 4.1750 (inf)	mem 15420MB
[2024-10-24 04:30:03 mlla_tiny] (main.py 304): INFO EPOCH 64 training takes 0:02:01
[2024-10-24 04:30:35 mlla_tiny] (main.py 350): INFO  * Acc@1 26.670 Acc@5 50.620
[2024-10-24 04:30:35 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 26.7%
[2024-10-24 04:31:06 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:31:06 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:31:06 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_64.pth saving......
[2024-10-24 04:31:08 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_64.pth saved !!!
[2024-10-24 04:31:08 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 04:31:09 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 04:31:09 mlla_tiny] (main.py 205): INFO Max accuracy: 26.67%
[2024-10-24 04:31:09 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:31:49 mlla_tiny] (main.py 296): INFO Train: [65/300][100/312]	eta 0:01:25 lr 0.000111	time 0.3720 (0.3999)	loss 4.6365 (5.3816)	grad_norm 7.2957 (inf)	mem 15420MB
[2024-10-24 04:32:28 mlla_tiny] (main.py 296): INFO Train: [65/300][200/312]	eta 0:00:44 lr 0.000111	time 0.3732 (0.3958)	loss 5.4705 (5.3795)	grad_norm 5.6037 (inf)	mem 15420MB
[2024-10-24 04:33:07 mlla_tiny] (main.py 296): INFO Train: [65/300][300/312]	eta 0:00:05 lr 0.000111	time 0.4012 (0.3951)	loss 5.5577 (5.3643)	grad_norm 6.2773 (inf)	mem 15420MB
[2024-10-24 04:33:12 mlla_tiny] (main.py 304): INFO EPOCH 65 training takes 0:02:03
[2024-10-24 04:33:43 mlla_tiny] (main.py 350): INFO  * Acc@1 27.110 Acc@5 51.330
[2024-10-24 04:33:43 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 27.1%
[2024-10-24 04:34:16 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.460
[2024-10-24 04:34:16 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:34:16 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_65.pth saving......
[2024-10-24 04:34:16 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_65.pth saved !!!
[2024-10-24 04:34:16 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 04:34:17 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 04:34:17 mlla_tiny] (main.py 205): INFO Max accuracy: 27.11%
[2024-10-24 04:34:17 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:34:57 mlla_tiny] (main.py 296): INFO Train: [66/300][100/312]	eta 0:01:23 lr 0.000111	time 0.3671 (0.3919)	loss 4.5436 (5.3754)	grad_norm 5.0681 (inf)	mem 15420MB
[2024-10-24 04:35:36 mlla_tiny] (main.py 296): INFO Train: [66/300][200/312]	eta 0:00:44 lr 0.000111	time 0.4067 (0.3914)	loss 5.1233 (5.4058)	grad_norm 4.7254 (inf)	mem 15420MB
[2024-10-24 04:36:15 mlla_tiny] (main.py 296): INFO Train: [66/300][300/312]	eta 0:00:05 lr 0.000111	time 0.3783 (0.3906)	loss 5.7485 (5.3672)	grad_norm 5.3474 (inf)	mem 15420MB
[2024-10-24 04:36:19 mlla_tiny] (main.py 304): INFO EPOCH 66 training takes 0:02:01
[2024-10-24 04:36:51 mlla_tiny] (main.py 350): INFO  * Acc@1 26.840 Acc@5 51.170
[2024-10-24 04:36:51 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 26.8%
[2024-10-24 04:37:22 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:37:22 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:37:22 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_66.pth saving......
[2024-10-24 04:37:23 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_66.pth saved !!!
[2024-10-24 04:37:23 mlla_tiny] (main.py 205): INFO Max accuracy: 27.11%
[2024-10-24 04:37:23 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:38:02 mlla_tiny] (main.py 296): INFO Train: [67/300][100/312]	eta 0:01:23 lr 0.000111	time 0.4201 (0.3914)	loss 5.9301 (5.3296)	grad_norm 5.7871 (inf)	mem 15420MB
[2024-10-24 04:38:41 mlla_tiny] (main.py 296): INFO Train: [67/300][200/312]	eta 0:00:44 lr 0.000111	time 0.3992 (0.3924)	loss 5.6449 (5.3519)	grad_norm 5.4081 (inf)	mem 15420MB
[2024-10-24 04:39:20 mlla_tiny] (main.py 296): INFO Train: [67/300][300/312]	eta 0:00:05 lr 0.000110	time 0.3734 (0.3904)	loss 4.6605 (5.3586)	grad_norm 8.5208 (inf)	mem 15420MB
[2024-10-24 04:39:24 mlla_tiny] (main.py 304): INFO EPOCH 67 training takes 0:02:01
[2024-10-24 04:39:56 mlla_tiny] (main.py 350): INFO  * Acc@1 28.450 Acc@5 52.600
[2024-10-24 04:39:56 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 28.4%
[2024-10-24 04:40:28 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:40:28 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:40:28 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_67.pth saving......
[2024-10-24 04:40:29 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_67.pth saved !!!
[2024-10-24 04:40:29 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 04:40:30 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 04:40:30 mlla_tiny] (main.py 205): INFO Max accuracy: 28.45%
[2024-10-24 04:40:30 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:41:10 mlla_tiny] (main.py 296): INFO Train: [68/300][100/312]	eta 0:01:24 lr 0.000110	time 0.4030 (0.3959)	loss 5.7041 (5.3207)	grad_norm 5.3108 (inf)	mem 15420MB
[2024-10-24 04:41:49 mlla_tiny] (main.py 296): INFO Train: [68/300][200/312]	eta 0:00:44 lr 0.000110	time 0.3691 (0.3947)	loss 5.2586 (5.2822)	grad_norm 5.0950 (inf)	mem 15420MB
[2024-10-24 04:42:29 mlla_tiny] (main.py 296): INFO Train: [68/300][300/312]	eta 0:00:05 lr 0.000110	time 0.3801 (0.3950)	loss 5.7092 (5.3207)	grad_norm 6.9089 (inf)	mem 15420MB
[2024-10-24 04:42:34 mlla_tiny] (main.py 304): INFO EPOCH 68 training takes 0:02:03
[2024-10-24 04:43:05 mlla_tiny] (main.py 350): INFO  * Acc@1 28.230 Acc@5 52.790
[2024-10-24 04:43:05 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 28.2%
[2024-10-24 04:43:37 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:43:37 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:43:37 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_68.pth saving......
[2024-10-24 04:43:38 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_68.pth saved !!!
[2024-10-24 04:43:38 mlla_tiny] (main.py 205): INFO Max accuracy: 28.45%
[2024-10-24 04:43:38 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:44:17 mlla_tiny] (main.py 296): INFO Train: [69/300][100/312]	eta 0:01:24 lr 0.000110	time 0.3971 (0.3952)	loss 5.4018 (5.3055)	grad_norm 6.3834 (inf)	mem 15420MB
[2024-10-24 04:44:57 mlla_tiny] (main.py 296): INFO Train: [69/300][200/312]	eta 0:00:44 lr 0.000110	time 0.4361 (0.3931)	loss 5.4106 (5.3177)	grad_norm 6.4117 (inf)	mem 15420MB
[2024-10-24 04:45:36 mlla_tiny] (main.py 296): INFO Train: [69/300][300/312]	eta 0:00:05 lr 0.000110	time 0.4104 (0.3944)	loss 5.7372 (5.2835)	grad_norm 4.5055 (inf)	mem 15420MB
[2024-10-24 04:45:41 mlla_tiny] (main.py 304): INFO EPOCH 69 training takes 0:02:03
[2024-10-24 04:46:12 mlla_tiny] (main.py 350): INFO  * Acc@1 28.370 Acc@5 53.160
[2024-10-24 04:46:12 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 28.4%
[2024-10-24 04:46:44 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:46:44 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:46:44 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_69.pth saving......
[2024-10-24 04:46:44 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_69.pth saved !!!
[2024-10-24 04:46:44 mlla_tiny] (main.py 205): INFO Max accuracy: 28.45%
[2024-10-24 04:46:44 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:47:24 mlla_tiny] (main.py 296): INFO Train: [70/300][100/312]	eta 0:01:24 lr 0.000109	time 0.3831 (0.3956)	loss 5.1078 (5.2699)	grad_norm 6.1635 (inf)	mem 15420MB
[2024-10-24 04:48:03 mlla_tiny] (main.py 296): INFO Train: [70/300][200/312]	eta 0:00:44 lr 0.000109	time 0.3721 (0.3926)	loss 4.6978 (5.2872)	grad_norm 9.8581 (inf)	mem 15420MB
[2024-10-24 04:48:43 mlla_tiny] (main.py 296): INFO Train: [70/300][300/312]	eta 0:00:05 lr 0.000109	time 0.3695 (0.3943)	loss 5.5005 (5.2989)	grad_norm 6.5291 (inf)	mem 15420MB
[2024-10-24 04:48:48 mlla_tiny] (main.py 304): INFO EPOCH 70 training takes 0:02:03
[2024-10-24 04:49:19 mlla_tiny] (main.py 350): INFO  * Acc@1 28.080 Acc@5 52.640
[2024-10-24 04:49:19 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 28.1%
[2024-10-24 04:49:51 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:49:51 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:49:51 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_70.pth saving......
[2024-10-24 04:49:52 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_70.pth saved !!!
[2024-10-24 04:49:52 mlla_tiny] (main.py 205): INFO Max accuracy: 28.45%
[2024-10-24 04:49:52 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:50:31 mlla_tiny] (main.py 296): INFO Train: [71/300][100/312]	eta 0:01:23 lr 0.000109	time 0.3752 (0.3942)	loss 5.7073 (5.3204)	grad_norm 5.6217 (inf)	mem 15420MB
[2024-10-24 04:51:11 mlla_tiny] (main.py 296): INFO Train: [71/300][200/312]	eta 0:00:44 lr 0.000109	time 0.3725 (0.3943)	loss 5.8293 (5.3101)	grad_norm 4.1648 (inf)	mem 15420MB
[2024-10-24 04:51:50 mlla_tiny] (main.py 296): INFO Train: [71/300][300/312]	eta 0:00:05 lr 0.000109	time 0.3827 (0.3945)	loss 5.6378 (5.2945)	grad_norm 4.4542 (inf)	mem 15420MB
[2024-10-24 04:51:55 mlla_tiny] (main.py 304): INFO EPOCH 71 training takes 0:02:03
[2024-10-24 04:52:27 mlla_tiny] (main.py 350): INFO  * Acc@1 29.230 Acc@5 54.140
[2024-10-24 04:52:27 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 29.2%
[2024-10-24 04:52:58 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:52:58 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:52:58 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_71.pth saving......
[2024-10-24 04:52:59 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_71.pth saved !!!
[2024-10-24 04:52:59 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 04:53:00 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 04:53:00 mlla_tiny] (main.py 205): INFO Max accuracy: 29.23%
[2024-10-24 04:53:00 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:53:39 mlla_tiny] (main.py 296): INFO Train: [72/300][100/312]	eta 0:01:23 lr 0.000109	time 0.3778 (0.3941)	loss 5.6886 (5.1897)	grad_norm 5.5556 (inf)	mem 15420MB
[2024-10-24 04:54:18 mlla_tiny] (main.py 296): INFO Train: [72/300][200/312]	eta 0:00:44 lr 0.000108	time 0.3693 (0.3911)	loss 5.7007 (5.1870)	grad_norm 4.3178 (inf)	mem 15420MB
[2024-10-24 04:54:57 mlla_tiny] (main.py 296): INFO Train: [72/300][300/312]	eta 0:00:05 lr 0.000108	time 0.4082 (0.3899)	loss 4.9391 (5.2070)	grad_norm 4.8580 (inf)	mem 15420MB
[2024-10-24 04:55:01 mlla_tiny] (main.py 304): INFO EPOCH 72 training takes 0:02:01
[2024-10-24 04:55:32 mlla_tiny] (main.py 350): INFO  * Acc@1 28.660 Acc@5 53.870
[2024-10-24 04:55:32 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 28.7%
[2024-10-24 04:56:03 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 04:56:03 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:56:03 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_72.pth saving......
[2024-10-24 04:56:04 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_72.pth saved !!!
[2024-10-24 04:56:04 mlla_tiny] (main.py 205): INFO Max accuracy: 29.23%
[2024-10-24 04:56:04 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:56:44 mlla_tiny] (main.py 296): INFO Train: [73/300][100/312]	eta 0:01:23 lr 0.000108	time 0.4539 (0.3939)	loss 4.5160 (5.1495)	grad_norm 6.5109 (inf)	mem 15420MB
[2024-10-24 04:57:22 mlla_tiny] (main.py 296): INFO Train: [73/300][200/312]	eta 0:00:44 lr 0.000108	time 0.3689 (0.3916)	loss 5.7807 (5.2120)	grad_norm 6.3198 (inf)	mem 15420MB
[2024-10-24 04:58:01 mlla_tiny] (main.py 296): INFO Train: [73/300][300/312]	eta 0:00:05 lr 0.000108	time 0.3679 (0.3904)	loss 5.6840 (5.1891)	grad_norm 4.4293 (inf)	mem 15420MB
[2024-10-24 04:58:06 mlla_tiny] (main.py 304): INFO EPOCH 73 training takes 0:02:01
[2024-10-24 04:58:37 mlla_tiny] (main.py 350): INFO  * Acc@1 30.360 Acc@5 55.390
[2024-10-24 04:58:37 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 30.4%
[2024-10-24 04:59:08 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.510
[2024-10-24 04:59:08 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 04:59:08 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_73.pth saving......
[2024-10-24 04:59:10 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_73.pth saved !!!
[2024-10-24 04:59:10 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 04:59:10 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 04:59:10 mlla_tiny] (main.py 205): INFO Max accuracy: 30.36%
[2024-10-24 04:59:10 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 04:59:50 mlla_tiny] (main.py 296): INFO Train: [74/300][100/312]	eta 0:01:23 lr 0.000108	time 0.3698 (0.3927)	loss 3.9518 (5.0833)	grad_norm 8.3856 (inf)	mem 15420MB
[2024-10-24 05:00:28 mlla_tiny] (main.py 296): INFO Train: [74/300][200/312]	eta 0:00:43 lr 0.000107	time 0.3694 (0.3874)	loss 5.2239 (5.1897)	grad_norm 5.5286 (inf)	mem 15420MB
[2024-10-24 05:01:07 mlla_tiny] (main.py 296): INFO Train: [74/300][300/312]	eta 0:00:05 lr 0.000107	time 0.3854 (0.3881)	loss 5.6637 (5.2178)	grad_norm 4.1664 (inf)	mem 15420MB
[2024-10-24 05:01:12 mlla_tiny] (main.py 304): INFO EPOCH 74 training takes 0:02:01
[2024-10-24 05:01:43 mlla_tiny] (main.py 350): INFO  * Acc@1 29.960 Acc@5 54.540
[2024-10-24 05:01:43 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 30.0%
[2024-10-24 05:02:14 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 05:02:14 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 05:02:14 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_74.pth saving......
[2024-10-24 05:02:15 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_74.pth saved !!!
[2024-10-24 05:02:15 mlla_tiny] (main.py 205): INFO Max accuracy: 30.36%
[2024-10-24 05:02:15 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 05:02:54 mlla_tiny] (main.py 296): INFO Train: [75/300][100/312]	eta 0:01:23 lr 0.000107	time 0.4059 (0.3923)	loss 5.2305 (5.1966)	grad_norm 7.8143 (inf)	mem 15420MB
[2024-10-24 05:03:33 mlla_tiny] (main.py 296): INFO Train: [75/300][200/312]	eta 0:00:44 lr 0.000107	time 0.4335 (0.3897)	loss 5.4563 (5.1864)	grad_norm 4.4857 (inf)	mem 15420MB
[2024-10-24 05:04:12 mlla_tiny] (main.py 296): INFO Train: [75/300][300/312]	eta 0:00:05 lr 0.000107	time 0.3840 (0.3889)	loss 5.1943 (5.1834)	grad_norm 5.1529 (nan)	mem 15420MB
[2024-10-24 05:04:16 mlla_tiny] (main.py 304): INFO EPOCH 75 training takes 0:02:01
[2024-10-24 05:04:48 mlla_tiny] (main.py 350): INFO  * Acc@1 30.070 Acc@5 54.910
[2024-10-24 05:04:48 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 30.1%
[2024-10-24 05:05:19 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 05:05:19 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 05:05:19 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_75.pth saving......
[2024-10-24 05:05:20 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_75.pth saved !!!
[2024-10-24 05:05:20 mlla_tiny] (main.py 205): INFO Max accuracy: 30.36%
[2024-10-24 05:05:20 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 05:06:08 mlla_tiny] (main.py 296): INFO Train: [76/300][100/312]	eta 0:01:41 lr 0.000107	time 0.4705 (0.4764)	loss 12.2599 (12.7719)	grad_norm 5.3619 (nan)	mem 15420MB
[2024-10-24 05:06:55 mlla_tiny] (main.py 296): INFO Train: [76/300][200/312]	eta 0:00:53 lr 0.000107	time 0.4742 (0.4747)	loss 12.4870 (12.7877)	grad_norm 4.0570 (nan)	mem 15420MB
[2024-10-24 05:07:42 mlla_tiny] (main.py 296): INFO Train: [76/300][300/312]	eta 0:00:06 lr 0.000106	time 0.4729 (0.4742)	loss 13.2055 (12.7854)	grad_norm 3.6490 (nan)	mem 15420MB
[2024-10-24 05:07:48 mlla_tiny] (main.py 304): INFO EPOCH 76 training takes 0:02:27
[2024-10-24 05:08:19 mlla_tiny] (main.py 350): INFO  * Acc@1 30.860 Acc@5 55.250
[2024-10-24 05:08:19 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 30.9%
[2024-10-24 05:08:51 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 05:08:51 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 05:08:51 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_76.pth saving......
[2024-10-24 05:08:52 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_76.pth saved !!!
[2024-10-24 05:08:52 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 05:08:53 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 05:08:53 mlla_tiny] (main.py 205): INFO Max accuracy: 30.86%
[2024-10-24 05:08:53 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 05:09:40 mlla_tiny] (main.py 296): INFO Train: [77/300][100/312]	eta 0:01:41 lr 0.000106	time 0.4723 (0.4761)	loss 12.1521 (12.6628)	grad_norm 4.5498 (inf)	mem 15420MB
[2024-10-24 05:10:28 mlla_tiny] (main.py 296): INFO Train: [77/300][200/312]	eta 0:00:53 lr 0.000106	time 0.4742 (0.4744)	loss 12.6807 (12.6883)	grad_norm 3.5797 (inf)	mem 15420MB
[2024-10-24 05:11:15 mlla_tiny] (main.py 296): INFO Train: [77/300][300/312]	eta 0:00:06 lr 0.000106	time 0.4737 (0.4741)	loss 12.8256 (12.6673)	grad_norm 3.3006 (inf)	mem 15420MB
[2024-10-24 05:11:21 mlla_tiny] (main.py 304): INFO EPOCH 77 training takes 0:02:27
[2024-10-24 05:11:52 mlla_tiny] (main.py 350): INFO  * Acc@1 30.490 Acc@5 55.250
[2024-10-24 05:11:52 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 30.5%
[2024-10-24 05:12:23 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 05:12:23 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 05:12:23 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_77.pth saving......
[2024-10-24 05:12:24 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_77.pth saved !!!
[2024-10-24 05:12:24 mlla_tiny] (main.py 205): INFO Max accuracy: 30.86%
[2024-10-24 05:12:24 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 05:13:12 mlla_tiny] (main.py 296): INFO Train: [78/300][100/312]	eta 0:01:41 lr 0.000106	time 0.4724 (0.4767)	loss 11.9278 (12.6369)	grad_norm 5.0770 (inf)	mem 15420MB
[2024-10-24 05:13:59 mlla_tiny] (main.py 296): INFO Train: [78/300][200/312]	eta 0:00:53 lr 0.000106	time 0.4730 (0.4747)	loss 12.2400 (12.6375)	grad_norm 3.9403 (inf)	mem 15420MB
[2024-10-24 05:14:46 mlla_tiny] (main.py 296): INFO Train: [78/300][300/312]	eta 0:00:06 lr 0.000106	time 0.4737 (0.4741)	loss 12.5214 (12.6374)	grad_norm 5.0205 (inf)	mem 15420MB
[2024-10-24 05:14:52 mlla_tiny] (main.py 304): INFO EPOCH 78 training takes 0:02:27
[2024-10-24 05:15:23 mlla_tiny] (main.py 350): INFO  * Acc@1 31.090 Acc@5 56.050
[2024-10-24 05:15:23 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 31.1%
[2024-10-24 05:15:54 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 05:15:54 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 05:15:54 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_78.pth saving......
[2024-10-24 05:15:56 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_78.pth saved !!!
[2024-10-24 05:15:56 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 05:15:56 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 05:15:56 mlla_tiny] (main.py 205): INFO Max accuracy: 31.09%
[2024-10-24 05:15:56 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 05:16:44 mlla_tiny] (main.py 296): INFO Train: [79/300][100/312]	eta 0:01:41 lr 0.000105	time 0.4714 (0.4762)	loss 11.9714 (12.5878)	grad_norm 5.3058 (inf)	mem 15420MB
[2024-10-24 05:17:31 mlla_tiny] (main.py 296): INFO Train: [79/300][200/312]	eta 0:00:53 lr 0.000105	time 0.4736 (0.4743)	loss 12.0690 (12.6206)	grad_norm 4.8022 (inf)	mem 15420MB
[2024-10-24 05:18:19 mlla_tiny] (main.py 296): INFO Train: [79/300][300/312]	eta 0:00:06 lr 0.000105	time 0.4731 (0.4739)	loss 13.1608 (12.6259)	grad_norm 3.7510 (inf)	mem 15420MB
[2024-10-24 05:18:24 mlla_tiny] (main.py 304): INFO EPOCH 79 training takes 0:02:27
[2024-10-24 05:18:56 mlla_tiny] (main.py 350): INFO  * Acc@1 30.830 Acc@5 56.550
[2024-10-24 05:18:56 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 30.8%
[2024-10-24 05:19:28 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 05:19:28 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 05:19:28 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_79.pth saving......
[2024-10-24 05:19:29 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_79.pth saved !!!
[2024-10-24 05:19:29 mlla_tiny] (main.py 205): INFO Max accuracy: 31.09%
[2024-10-24 05:19:29 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 05:20:17 mlla_tiny] (main.py 296): INFO Train: [80/300][100/312]	eta 0:01:41 lr 0.000105	time 0.4719 (0.4760)	loss 12.9603 (12.5725)	grad_norm 3.2088 (inf)	mem 15420MB
[2024-10-24 05:21:04 mlla_tiny] (main.py 296): INFO Train: [80/300][200/312]	eta 0:00:53 lr 0.000105	time 0.4731 (0.4743)	loss 12.8818 (12.6009)	grad_norm 3.4520 (inf)	mem 15420MB
[2024-10-24 05:21:51 mlla_tiny] (main.py 296): INFO Train: [80/300][300/312]	eta 0:00:06 lr 0.000105	time 0.4734 (0.4739)	loss 12.9055 (12.6197)	grad_norm 3.5340 (inf)	mem 15420MB
[2024-10-24 05:21:57 mlla_tiny] (main.py 304): INFO EPOCH 80 training takes 0:02:27
[2024-10-24 05:22:28 mlla_tiny] (main.py 350): INFO  * Acc@1 31.290 Acc@5 57.020
[2024-10-24 05:22:28 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 31.3%
[2024-10-24 05:22:59 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.490
[2024-10-24 05:22:59 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 05:22:59 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_80.pth saving......
[2024-10-24 05:23:00 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_80.pth saved !!!
[2024-10-24 05:23:00 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 05:23:01 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 05:23:01 mlla_tiny] (main.py 205): INFO Max accuracy: 31.29%
[2024-10-24 05:23:01 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 05:23:49 mlla_tiny] (main.py 296): INFO Train: [81/300][100/312]	eta 0:01:41 lr 0.000104	time 0.4706 (0.4763)	loss 11.9059 (12.5237)	grad_norm 5.4974 (inf)	mem 15420MB
[2024-10-24 05:24:36 mlla_tiny] (main.py 296): INFO Train: [81/300][200/312]	eta 0:00:53 lr 0.000104	time 0.4725 (0.4743)	loss 11.9878 (12.5651)	grad_norm 4.6603 (inf)	mem 15420MB
[2024-10-24 05:25:23 mlla_tiny] (main.py 296): INFO Train: [81/300][300/312]	eta 0:00:06 lr 0.000104	time 0.4731 (0.4739)	loss 12.8300 (12.5891)	grad_norm 3.8694 (inf)	mem 15420MB
[2024-10-24 05:25:29 mlla_tiny] (main.py 304): INFO EPOCH 81 training takes 0:02:27
[2024-10-24 05:26:00 mlla_tiny] (main.py 350): INFO  * Acc@1 31.980 Acc@5 56.570
[2024-10-24 05:26:00 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 32.0%
[2024-10-24 05:26:32 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 05:26:32 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 05:26:32 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_81.pth saving......
[2024-10-24 05:26:32 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_81.pth saved !!!
[2024-10-24 05:26:32 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 05:26:33 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 05:26:33 mlla_tiny] (main.py 205): INFO Max accuracy: 31.98%
[2024-10-24 05:26:33 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 05:27:21 mlla_tiny] (main.py 296): INFO Train: [82/300][100/312]	eta 0:01:41 lr 0.000104	time 0.4713 (0.4756)	loss 12.1236 (12.5429)	grad_norm 5.5953 (inf)	mem 15420MB
[2024-10-24 05:28:08 mlla_tiny] (main.py 296): INFO Train: [82/300][200/312]	eta 0:00:53 lr 0.000104	time 0.4733 (0.4740)	loss 12.4971 (12.5732)	grad_norm 3.5301 (inf)	mem 15420MB
[2024-10-24 05:28:56 mlla_tiny] (main.py 296): INFO Train: [82/300][300/312]	eta 0:00:06 lr 0.000104	time 0.4728 (0.4737)	loss 12.9273 (12.5824)	grad_norm 4.2579 (inf)	mem 15420MB
[2024-10-24 05:29:01 mlla_tiny] (main.py 304): INFO EPOCH 82 training takes 0:02:27
[2024-10-24 05:29:32 mlla_tiny] (main.py 350): INFO  * Acc@1 32.320 Acc@5 57.500
[2024-10-24 05:29:32 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 32.3%
[2024-10-24 05:30:04 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 05:30:04 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 05:30:04 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_82.pth saving......
[2024-10-24 05:30:05 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_82.pth saved !!!
[2024-10-24 05:30:05 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 05:30:06 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 05:30:06 mlla_tiny] (main.py 205): INFO Max accuracy: 32.32%
[2024-10-24 05:30:06 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 05:30:53 mlla_tiny] (main.py 296): INFO Train: [83/300][100/312]	eta 0:01:41 lr 0.000103	time 0.4717 (0.4762)	loss 12.1572 (12.4806)	grad_norm 4.6917 (inf)	mem 15420MB
[2024-10-24 05:31:41 mlla_tiny] (main.py 296): INFO Train: [83/300][200/312]	eta 0:00:53 lr 0.000103	time 0.4718 (0.4742)	loss 12.9778 (12.5170)	grad_norm 3.5253 (inf)	mem 15420MB
[2024-10-24 05:32:28 mlla_tiny] (main.py 296): INFO Train: [83/300][300/312]	eta 0:00:06 lr 0.000103	time 0.4728 (0.4739)	loss 12.7884 (12.5477)	grad_norm 4.9695 (inf)	mem 15420MB
[2024-10-24 05:32:34 mlla_tiny] (main.py 304): INFO EPOCH 83 training takes 0:02:27
[2024-10-24 05:33:05 mlla_tiny] (main.py 350): INFO  * Acc@1 31.840 Acc@5 57.110
[2024-10-24 05:33:05 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 31.8%
[2024-10-24 05:33:37 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 05:33:37 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 05:33:37 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_83.pth saving......
[2024-10-24 05:33:38 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_83.pth saved !!!
[2024-10-24 05:33:38 mlla_tiny] (main.py 205): INFO Max accuracy: 32.32%
[2024-10-24 05:33:38 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 05:34:25 mlla_tiny] (main.py 296): INFO Train: [84/300][100/312]	eta 0:01:41 lr 0.000103	time 0.4731 (0.4765)	loss 13.0039 (12.6114)	grad_norm 4.9343 (inf)	mem 15420MB
[2024-10-24 05:35:13 mlla_tiny] (main.py 296): INFO Train: [84/300][200/312]	eta 0:00:53 lr 0.000103	time 0.4733 (0.4748)	loss 12.2881 (12.5540)	grad_norm 4.9448 (inf)	mem 15420MB
[2024-10-24 05:36:00 mlla_tiny] (main.py 296): INFO Train: [84/300][300/312]	eta 0:00:06 lr 0.000103	time 0.4749 (0.4745)	loss 12.4573 (12.5573)	grad_norm 6.3616 (inf)	mem 15420MB
[2024-10-24 05:36:06 mlla_tiny] (main.py 304): INFO EPOCH 84 training takes 0:02:28
[2024-10-24 05:36:37 mlla_tiny] (main.py 350): INFO  * Acc@1 32.510 Acc@5 58.220
[2024-10-24 05:36:37 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 32.5%
[2024-10-24 05:37:09 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 05:37:09 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 05:37:09 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_84.pth saving......
[2024-10-24 05:37:10 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_84.pth saved !!!
[2024-10-24 05:37:10 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 05:37:11 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 05:37:11 mlla_tiny] (main.py 205): INFO Max accuracy: 32.51%
[2024-10-24 05:37:11 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 05:37:58 mlla_tiny] (main.py 296): INFO Train: [85/300][100/312]	eta 0:01:41 lr 0.000102	time 0.4720 (0.4764)	loss 12.8323 (12.5380)	grad_norm 4.4320 (inf)	mem 15420MB
[2024-10-24 05:38:45 mlla_tiny] (main.py 296): INFO Train: [85/300][200/312]	eta 0:00:53 lr 0.000102	time 0.4734 (0.4745)	loss 12.4572 (12.4893)	grad_norm 4.4599 (inf)	mem 15420MB
[2024-10-24 05:39:33 mlla_tiny] (main.py 296): INFO Train: [85/300][300/312]	eta 0:00:06 lr 0.000102	time 0.4727 (0.4740)	loss 12.9328 (12.5348)	grad_norm 3.4065 (inf)	mem 15420MB
[2024-10-24 05:39:38 mlla_tiny] (main.py 304): INFO EPOCH 85 training takes 0:02:27
[2024-10-24 05:40:09 mlla_tiny] (main.py 350): INFO  * Acc@1 32.590 Acc@5 58.110
[2024-10-24 05:40:09 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 32.6%
[2024-10-24 05:40:41 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 05:40:41 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 05:40:41 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_85.pth saving......
[2024-10-24 05:40:42 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_85.pth saved !!!
[2024-10-24 05:40:42 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 05:40:43 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 05:40:43 mlla_tiny] (main.py 205): INFO Max accuracy: 32.59%
[2024-10-24 05:40:43 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 05:41:30 mlla_tiny] (main.py 296): INFO Train: [86/300][100/312]	eta 0:01:41 lr 0.000102	time 0.4715 (0.4765)	loss 11.7479 (12.5367)	grad_norm 5.3100 (inf)	mem 15420MB
[2024-10-24 05:42:18 mlla_tiny] (main.py 296): INFO Train: [86/300][200/312]	eta 0:00:53 lr 0.000102	time 0.4734 (0.4746)	loss 13.0120 (12.5048)	grad_norm 3.5075 (inf)	mem 15420MB
[2024-10-24 05:43:05 mlla_tiny] (main.py 296): INFO Train: [86/300][300/312]	eta 0:00:06 lr 0.000102	time 0.4729 (0.4742)	loss 12.7600 (12.4814)	grad_norm 4.0279 (inf)	mem 15420MB
[2024-10-24 05:43:11 mlla_tiny] (main.py 304): INFO EPOCH 86 training takes 0:02:27
[2024-10-24 05:43:42 mlla_tiny] (main.py 350): INFO  * Acc@1 32.870 Acc@5 58.220
[2024-10-24 05:43:42 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 32.9%
[2024-10-24 05:44:13 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 05:44:13 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 05:44:13 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_86.pth saving......
[2024-10-24 05:44:14 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_86.pth saved !!!
[2024-10-24 05:44:14 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 05:44:15 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 05:44:15 mlla_tiny] (main.py 205): INFO Max accuracy: 32.87%
[2024-10-24 05:44:15 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 05:45:03 mlla_tiny] (main.py 296): INFO Train: [87/300][100/312]	eta 0:01:41 lr 0.000101	time 0.4721 (0.4765)	loss 11.7139 (12.4544)	grad_norm 4.5377 (inf)	mem 15420MB
[2024-10-24 05:45:50 mlla_tiny] (main.py 296): INFO Train: [87/300][200/312]	eta 0:00:53 lr 0.000101	time 0.4731 (0.4745)	loss 12.9195 (12.4711)	grad_norm 3.5229 (inf)	mem 15420MB
[2024-10-24 05:46:37 mlla_tiny] (main.py 296): INFO Train: [87/300][300/312]	eta 0:00:06 lr 0.000101	time 0.4728 (0.4741)	loss 11.8010 (12.4815)	grad_norm 5.0027 (inf)	mem 15420MB
[2024-10-24 05:46:43 mlla_tiny] (main.py 304): INFO EPOCH 87 training takes 0:02:27
[2024-10-24 05:47:15 mlla_tiny] (main.py 350): INFO  * Acc@1 33.290 Acc@5 58.670
[2024-10-24 05:47:15 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 33.3%
[2024-10-24 05:47:46 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 05:47:46 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 05:47:46 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_87.pth saving......
[2024-10-24 05:47:47 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_87.pth saved !!!
[2024-10-24 05:47:47 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 05:47:48 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 05:47:48 mlla_tiny] (main.py 205): INFO Max accuracy: 33.29%
[2024-10-24 05:47:48 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 05:48:35 mlla_tiny] (main.py 296): INFO Train: [88/300][100/312]	eta 0:01:41 lr 0.000101	time 0.4719 (0.4768)	loss 12.0924 (12.3676)	grad_norm 4.9148 (inf)	mem 15420MB
[2024-10-24 05:49:23 mlla_tiny] (main.py 296): INFO Train: [88/300][200/312]	eta 0:00:53 lr 0.000101	time 0.4731 (0.4748)	loss 12.3510 (12.3983)	grad_norm 5.4706 (inf)	mem 15420MB
[2024-10-24 05:50:10 mlla_tiny] (main.py 296): INFO Train: [88/300][300/312]	eta 0:00:06 lr 0.000101	time 0.4729 (0.4742)	loss 12.9657 (12.4189)	grad_norm 3.8106 (inf)	mem 15420MB
[2024-10-24 05:50:16 mlla_tiny] (main.py 304): INFO EPOCH 88 training takes 0:02:27
[2024-10-24 05:50:47 mlla_tiny] (main.py 350): INFO  * Acc@1 32.930 Acc@5 58.930
[2024-10-24 05:50:47 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 32.9%
[2024-10-24 05:51:18 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 05:51:18 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 05:51:18 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_88.pth saving......
[2024-10-24 05:51:19 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_88.pth saved !!!
[2024-10-24 05:51:19 mlla_tiny] (main.py 205): INFO Max accuracy: 33.29%
[2024-10-24 05:51:19 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 05:52:07 mlla_tiny] (main.py 296): INFO Train: [89/300][100/312]	eta 0:01:41 lr 0.000100	time 0.4719 (0.4765)	loss 12.8140 (12.5044)	grad_norm 4.9264 (inf)	mem 15420MB
[2024-10-24 05:52:54 mlla_tiny] (main.py 296): INFO Train: [89/300][200/312]	eta 0:00:53 lr 0.000100	time 0.4731 (0.4745)	loss 11.7746 (12.4859)	grad_norm 5.4923 (inf)	mem 15420MB
[2024-10-24 05:53:41 mlla_tiny] (main.py 296): INFO Train: [89/300][300/312]	eta 0:00:06 lr 0.000100	time 0.4726 (0.4740)	loss 12.9450 (12.4784)	grad_norm 3.9098 (inf)	mem 15420MB
[2024-10-24 05:53:47 mlla_tiny] (main.py 304): INFO EPOCH 89 training takes 0:02:27
[2024-10-24 05:54:18 mlla_tiny] (main.py 350): INFO  * Acc@1 34.110 Acc@5 59.130
[2024-10-24 05:54:18 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 34.1%
[2024-10-24 05:54:49 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 05:54:49 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 05:54:49 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_89.pth saving......
[2024-10-24 05:54:50 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_89.pth saved !!!
[2024-10-24 05:54:50 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 05:54:51 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 05:54:51 mlla_tiny] (main.py 205): INFO Max accuracy: 34.11%
[2024-10-24 05:54:51 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 05:55:39 mlla_tiny] (main.py 296): INFO Train: [90/300][100/312]	eta 0:01:41 lr 0.000100	time 0.4737 (0.4761)	loss 12.0352 (12.4634)	grad_norm 5.9564 (inf)	mem 15420MB
[2024-10-24 05:56:26 mlla_tiny] (main.py 296): INFO Train: [90/300][200/312]	eta 0:00:53 lr 0.000100	time 0.4734 (0.4742)	loss 12.6829 (12.4781)	grad_norm 3.1672 (inf)	mem 15420MB
[2024-10-24 05:57:13 mlla_tiny] (main.py 296): INFO Train: [90/300][300/312]	eta 0:00:06 lr 0.000100	time 0.4737 (0.4740)	loss 13.0585 (12.4739)	grad_norm 3.6020 (inf)	mem 15420MB
[2024-10-24 05:57:19 mlla_tiny] (main.py 304): INFO EPOCH 90 training takes 0:02:27
[2024-10-24 05:57:50 mlla_tiny] (main.py 350): INFO  * Acc@1 34.470 Acc@5 60.000
[2024-10-24 05:57:50 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 34.5%
[2024-10-24 05:58:22 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 05:58:22 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 05:58:22 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_90.pth saving......
[2024-10-24 05:58:23 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_90.pth saved !!!
[2024-10-24 05:58:23 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 05:58:24 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 05:58:24 mlla_tiny] (main.py 205): INFO Max accuracy: 34.47%
[2024-10-24 05:58:24 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 05:59:11 mlla_tiny] (main.py 296): INFO Train: [91/300][100/312]	eta 0:01:41 lr 0.000099	time 0.4713 (0.4759)	loss 12.7142 (12.4429)	grad_norm 3.6437 (inf)	mem 15420MB
[2024-10-24 05:59:58 mlla_tiny] (main.py 296): INFO Train: [91/300][200/312]	eta 0:00:53 lr 0.000099	time 0.4730 (0.4741)	loss 11.7524 (12.4389)	grad_norm 5.3460 (inf)	mem 15420MB
[2024-10-24 06:00:46 mlla_tiny] (main.py 296): INFO Train: [91/300][300/312]	eta 0:00:06 lr 0.000099	time 0.4731 (0.4737)	loss 11.5605 (12.4593)	grad_norm 8.0984 (inf)	mem 15420MB
[2024-10-24 06:00:51 mlla_tiny] (main.py 304): INFO EPOCH 91 training takes 0:02:27
[2024-10-24 06:01:23 mlla_tiny] (main.py 350): INFO  * Acc@1 33.850 Acc@5 59.740
[2024-10-24 06:01:23 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 33.9%
[2024-10-24 06:01:54 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 06:01:54 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 06:01:54 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_91.pth saving......
[2024-10-24 06:01:58 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_91.pth saved !!!
[2024-10-24 06:01:58 mlla_tiny] (main.py 205): INFO Max accuracy: 34.47%
[2024-10-24 06:01:58 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 06:02:46 mlla_tiny] (main.py 296): INFO Train: [92/300][100/312]	eta 0:01:41 lr 0.000099	time 0.4714 (0.4766)	loss 11.6613 (12.3558)	grad_norm 6.0996 (inf)	mem 15420MB
[2024-10-24 06:03:33 mlla_tiny] (main.py 296): INFO Train: [92/300][200/312]	eta 0:00:53 lr 0.000099	time 0.4729 (0.4744)	loss 12.9811 (12.3959)	grad_norm 3.9379 (inf)	mem 15420MB
[2024-10-24 06:04:20 mlla_tiny] (main.py 296): INFO Train: [92/300][300/312]	eta 0:00:06 lr 0.000098	time 0.4728 (0.4740)	loss 11.4491 (12.4083)	grad_norm 5.0887 (inf)	mem 15420MB
[2024-10-24 06:04:26 mlla_tiny] (main.py 304): INFO EPOCH 92 training takes 0:02:27
[2024-10-24 06:04:57 mlla_tiny] (main.py 350): INFO  * Acc@1 35.110 Acc@5 60.210
[2024-10-24 06:04:57 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 35.1%
[2024-10-24 06:05:29 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 06:05:29 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 06:05:29 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_92.pth saving......
[2024-10-24 06:05:30 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_92.pth saved !!!
[2024-10-24 06:05:30 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 06:05:31 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 06:05:31 mlla_tiny] (main.py 205): INFO Max accuracy: 35.11%
[2024-10-24 06:05:31 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 06:06:18 mlla_tiny] (main.py 296): INFO Train: [93/300][100/312]	eta 0:01:41 lr 0.000098	time 0.4718 (0.4762)	loss 12.6163 (12.3919)	grad_norm 3.2175 (inf)	mem 15420MB
[2024-10-24 06:07:06 mlla_tiny] (main.py 296): INFO Train: [93/300][200/312]	eta 0:00:53 lr 0.000098	time 0.4725 (0.4746)	loss 12.8377 (12.3707)	grad_norm 5.1659 (inf)	mem 15420MB
[2024-10-24 06:07:53 mlla_tiny] (main.py 296): INFO Train: [93/300][300/312]	eta 0:00:06 lr 0.000098	time 0.4732 (0.4742)	loss 12.7519 (12.3755)	grad_norm 3.6359 (inf)	mem 15420MB
[2024-10-24 06:07:59 mlla_tiny] (main.py 304): INFO EPOCH 93 training takes 0:02:27
[2024-10-24 06:08:30 mlla_tiny] (main.py 350): INFO  * Acc@1 34.910 Acc@5 60.210
[2024-10-24 06:08:30 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 34.9%
[2024-10-24 06:09:01 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 06:09:01 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 06:09:01 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_93.pth saving......
[2024-10-24 06:09:02 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_93.pth saved !!!
[2024-10-24 06:09:02 mlla_tiny] (main.py 205): INFO Max accuracy: 35.11%
[2024-10-24 06:09:02 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 06:09:50 mlla_tiny] (main.py 296): INFO Train: [94/300][100/312]	eta 0:01:41 lr 0.000098	time 0.4719 (0.4763)	loss 12.7809 (12.4601)	grad_norm 6.4471 (inf)	mem 15420MB
[2024-10-24 06:10:37 mlla_tiny] (main.py 296): INFO Train: [94/300][200/312]	eta 0:00:53 lr 0.000098	time 0.4728 (0.4748)	loss 11.6418 (12.4085)	grad_norm 7.1287 (inf)	mem 15420MB
[2024-10-24 06:11:24 mlla_tiny] (main.py 296): INFO Train: [94/300][300/312]	eta 0:00:06 lr 0.000097	time 0.4730 (0.4744)	loss 12.4671 (12.3909)	grad_norm 4.0403 (inf)	mem 15420MB
[2024-10-24 06:11:30 mlla_tiny] (main.py 304): INFO EPOCH 94 training takes 0:02:28
[2024-10-24 06:12:02 mlla_tiny] (main.py 350): INFO  * Acc@1 33.940 Acc@5 59.470
[2024-10-24 06:12:02 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 33.9%
[2024-10-24 06:12:33 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 06:12:33 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 06:12:33 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_94.pth saving......
[2024-10-24 06:12:34 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_94.pth saved !!!
[2024-10-24 06:12:34 mlla_tiny] (main.py 205): INFO Max accuracy: 35.11%
[2024-10-24 06:12:34 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 06:13:21 mlla_tiny] (main.py 296): INFO Train: [95/300][100/312]	eta 0:01:41 lr 0.000097	time 0.4718 (0.4764)	loss 12.8691 (12.3564)	grad_norm 3.5300 (inf)	mem 15420MB
[2024-10-24 06:14:09 mlla_tiny] (main.py 296): INFO Train: [95/300][200/312]	eta 0:00:53 lr 0.000097	time 0.4731 (0.4744)	loss 12.8891 (12.3716)	grad_norm 3.6715 (inf)	mem 15420MB
[2024-10-24 06:14:56 mlla_tiny] (main.py 296): INFO Train: [95/300][300/312]	eta 0:00:06 lr 0.000097	time 0.4729 (0.4740)	loss 12.5014 (12.3651)	grad_norm 6.0628 (inf)	mem 15420MB
[2024-10-24 06:15:02 mlla_tiny] (main.py 304): INFO EPOCH 95 training takes 0:02:27
[2024-10-24 06:15:33 mlla_tiny] (main.py 350): INFO  * Acc@1 35.620 Acc@5 61.100
[2024-10-24 06:15:33 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 35.6%
[2024-10-24 06:16:04 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 06:16:04 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 06:16:04 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_95.pth saving......
[2024-10-24 06:16:05 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_95.pth saved !!!
[2024-10-24 06:16:05 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 06:16:06 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 06:16:06 mlla_tiny] (main.py 205): INFO Max accuracy: 35.62%
[2024-10-24 06:16:06 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 06:16:54 mlla_tiny] (main.py 296): INFO Train: [96/300][100/312]	eta 0:01:41 lr 0.000097	time 0.4717 (0.4762)	loss 11.9006 (12.3078)	grad_norm 5.8591 (inf)	mem 15420MB
[2024-10-24 06:17:41 mlla_tiny] (main.py 296): INFO Train: [96/300][200/312]	eta 0:00:53 lr 0.000096	time 0.4739 (0.4743)	loss 12.3067 (12.3435)	grad_norm 5.0052 (inf)	mem 15420MB
[2024-10-24 06:18:28 mlla_tiny] (main.py 296): INFO Train: [96/300][300/312]	eta 0:00:06 lr 0.000096	time 0.4734 (0.4742)	loss 12.7167 (12.3648)	grad_norm 4.6767 (inf)	mem 15420MB
[2024-10-24 06:18:34 mlla_tiny] (main.py 304): INFO EPOCH 96 training takes 0:02:27
[2024-10-24 06:19:06 mlla_tiny] (main.py 350): INFO  * Acc@1 35.260 Acc@5 61.180
[2024-10-24 06:19:06 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 35.3%
[2024-10-24 06:19:38 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 06:19:38 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 06:19:38 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_96.pth saving......
[2024-10-24 06:19:39 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_96.pth saved !!!
[2024-10-24 06:19:39 mlla_tiny] (main.py 205): INFO Max accuracy: 35.62%
[2024-10-24 06:19:39 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 06:20:26 mlla_tiny] (main.py 296): INFO Train: [97/300][100/312]	eta 0:01:41 lr 0.000096	time 0.4718 (0.4755)	loss 12.5874 (12.3273)	grad_norm 4.8762 (inf)	mem 15420MB
[2024-10-24 06:21:13 mlla_tiny] (main.py 296): INFO Train: [97/300][200/312]	eta 0:00:53 lr 0.000096	time 0.4728 (0.4739)	loss 12.5166 (12.3326)	grad_norm 5.2731 (inf)	mem 15420MB
[2024-10-24 06:22:01 mlla_tiny] (main.py 296): INFO Train: [97/300][300/312]	eta 0:00:06 lr 0.000096	time 0.4735 (0.4737)	loss 12.6458 (12.3249)	grad_norm 5.4185 (inf)	mem 15420MB
[2024-10-24 06:22:06 mlla_tiny] (main.py 304): INFO EPOCH 97 training takes 0:02:27
[2024-10-24 06:22:38 mlla_tiny] (main.py 350): INFO  * Acc@1 35.640 Acc@5 61.510
[2024-10-24 06:22:38 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 35.6%
[2024-10-24 06:23:09 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 06:23:09 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 06:23:09 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_97.pth saving......
[2024-10-24 06:23:11 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_97.pth saved !!!
[2024-10-24 06:23:11 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 06:23:12 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 06:23:12 mlla_tiny] (main.py 205): INFO Max accuracy: 35.64%
[2024-10-24 06:23:12 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 06:23:59 mlla_tiny] (main.py 296): INFO Train: [98/300][100/312]	eta 0:01:41 lr 0.000096	time 0.4716 (0.4770)	loss 11.7662 (12.3413)	grad_norm 4.7602 (inf)	mem 15420MB
[2024-10-24 06:24:47 mlla_tiny] (main.py 296): INFO Train: [98/300][200/312]	eta 0:00:53 lr 0.000095	time 0.4735 (0.4751)	loss 12.5299 (12.3127)	grad_norm 5.0704 (inf)	mem 15420MB
[2024-10-24 06:25:34 mlla_tiny] (main.py 296): INFO Train: [98/300][300/312]	eta 0:00:06 lr 0.000095	time 0.4735 (0.4747)	loss 12.8188 (12.3347)	grad_norm 3.7723 (inf)	mem 15420MB
[2024-10-24 06:25:40 mlla_tiny] (main.py 304): INFO EPOCH 98 training takes 0:02:28
[2024-10-24 06:26:11 mlla_tiny] (main.py 350): INFO  * Acc@1 35.990 Acc@5 62.150
[2024-10-24 06:26:11 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 36.0%
[2024-10-24 06:26:42 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 06:26:42 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 06:26:42 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_98.pth saving......
[2024-10-24 06:26:43 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_98.pth saved !!!
[2024-10-24 06:26:43 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 06:26:44 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 06:26:44 mlla_tiny] (main.py 205): INFO Max accuracy: 35.99%
[2024-10-24 06:26:44 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 06:27:32 mlla_tiny] (main.py 296): INFO Train: [99/300][100/312]	eta 0:01:41 lr 0.000095	time 0.4725 (0.4763)	loss 12.6241 (12.3038)	grad_norm 5.9226 (inf)	mem 15420MB
[2024-10-24 06:28:19 mlla_tiny] (main.py 296): INFO Train: [99/300][200/312]	eta 0:00:53 lr 0.000095	time 0.4734 (0.4744)	loss 12.3119 (12.3190)	grad_norm 4.0052 (inf)	mem 15420MB
[2024-10-24 06:29:07 mlla_tiny] (main.py 296): INFO Train: [99/300][300/312]	eta 0:00:06 lr 0.000095	time 0.4736 (0.4741)	loss 11.5527 (12.3017)	grad_norm 5.0479 (inf)	mem 15420MB
[2024-10-24 06:29:12 mlla_tiny] (main.py 304): INFO EPOCH 99 training takes 0:02:27
[2024-10-24 06:29:44 mlla_tiny] (main.py 350): INFO  * Acc@1 35.810 Acc@5 61.840
[2024-10-24 06:29:44 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 35.8%
[2024-10-24 06:30:16 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 06:30:16 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 06:30:16 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_99.pth saving......
[2024-10-24 06:30:17 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_99.pth saved !!!
[2024-10-24 06:30:17 mlla_tiny] (main.py 205): INFO Max accuracy: 35.99%
[2024-10-24 06:30:17 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 06:31:04 mlla_tiny] (main.py 296): INFO Train: [100/300][100/312]	eta 0:01:41 lr 0.000094	time 0.4724 (0.4756)	loss 12.8656 (12.3383)	grad_norm 4.2994 (inf)	mem 15420MB
[2024-10-24 06:31:52 mlla_tiny] (main.py 296): INFO Train: [100/300][200/312]	eta 0:00:53 lr 0.000094	time 0.4726 (0.4739)	loss 12.8545 (12.3331)	grad_norm 3.6560 (inf)	mem 15420MB
[2024-10-24 06:32:39 mlla_tiny] (main.py 296): INFO Train: [100/300][300/312]	eta 0:00:06 lr 0.000094	time 0.4729 (0.4739)	loss 12.2303 (12.3051)	grad_norm 5.2548 (inf)	mem 15420MB
[2024-10-24 06:32:45 mlla_tiny] (main.py 304): INFO EPOCH 100 training takes 0:02:27
[2024-10-24 06:33:16 mlla_tiny] (main.py 350): INFO  * Acc@1 36.130 Acc@5 62.290
[2024-10-24 06:33:16 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 36.1%
[2024-10-24 06:33:47 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 06:33:47 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 06:33:47 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_100.pth saving......
[2024-10-24 06:33:48 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_100.pth saved !!!
[2024-10-24 06:33:48 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 06:33:49 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 06:33:49 mlla_tiny] (main.py 205): INFO Max accuracy: 36.13%
[2024-10-24 06:33:49 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 06:34:37 mlla_tiny] (main.py 296): INFO Train: [101/300][100/312]	eta 0:01:41 lr 0.000094	time 0.4716 (0.4763)	loss 11.2586 (12.2893)	grad_norm 5.0639 (inf)	mem 15420MB
[2024-10-24 06:35:24 mlla_tiny] (main.py 296): INFO Train: [101/300][200/312]	eta 0:00:53 lr 0.000094	time 0.4730 (0.4744)	loss 12.3087 (12.3232)	grad_norm 6.2252 (inf)	mem 15420MB
[2024-10-24 06:36:11 mlla_tiny] (main.py 296): INFO Train: [101/300][300/312]	eta 0:00:06 lr 0.000094	time 0.4734 (0.4740)	loss 12.7650 (12.3210)	grad_norm 4.0988 (inf)	mem 15420MB
[2024-10-24 06:36:17 mlla_tiny] (main.py 304): INFO EPOCH 101 training takes 0:02:27
[2024-10-24 06:36:48 mlla_tiny] (main.py 350): INFO  * Acc@1 36.350 Acc@5 61.930
[2024-10-24 06:36:48 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 36.4%
[2024-10-24 06:37:19 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 06:37:19 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 06:37:19 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_101.pth saving......
[2024-10-24 06:37:20 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_101.pth saved !!!
[2024-10-24 06:37:20 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 06:37:21 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 06:37:21 mlla_tiny] (main.py 205): INFO Max accuracy: 36.35%
[2024-10-24 06:37:21 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 06:38:09 mlla_tiny] (main.py 296): INFO Train: [102/300][100/312]	eta 0:01:41 lr 0.000093	time 0.4716 (0.4755)	loss 12.7122 (12.2920)	grad_norm 6.9550 (inf)	mem 15420MB
[2024-10-24 06:38:56 mlla_tiny] (main.py 296): INFO Train: [102/300][200/312]	eta 0:00:53 lr 0.000093	time 0.4731 (0.4740)	loss 12.6850 (12.2695)	grad_norm 5.1131 (inf)	mem 15420MB
[2024-10-24 06:39:44 mlla_tiny] (main.py 296): INFO Train: [102/300][300/312]	eta 0:00:06 lr 0.000093	time 0.4735 (0.4739)	loss 12.6778 (12.2545)	grad_norm 4.0019 (inf)	mem 15420MB
[2024-10-24 06:39:49 mlla_tiny] (main.py 304): INFO EPOCH 102 training takes 0:02:27
[2024-10-24 06:40:21 mlla_tiny] (main.py 350): INFO  * Acc@1 36.480 Acc@5 62.770
[2024-10-24 06:40:21 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 36.5%
[2024-10-24 06:40:52 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 06:40:52 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 06:40:52 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_102.pth saving......
[2024-10-24 06:40:53 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_102.pth saved !!!
[2024-10-24 06:40:53 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 06:40:54 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 06:40:54 mlla_tiny] (main.py 205): INFO Max accuracy: 36.48%
[2024-10-24 06:40:54 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 06:41:42 mlla_tiny] (main.py 296): INFO Train: [103/300][100/312]	eta 0:01:41 lr 0.000093	time 0.4722 (0.4763)	loss 12.8633 (12.2958)	grad_norm 3.7921 (inf)	mem 15420MB
[2024-10-24 06:42:29 mlla_tiny] (main.py 296): INFO Train: [103/300][200/312]	eta 0:00:53 lr 0.000093	time 0.4737 (0.4746)	loss 11.9370 (12.2883)	grad_norm 5.7494 (inf)	mem 15420MB
[2024-10-24 06:43:16 mlla_tiny] (main.py 296): INFO Train: [103/300][300/312]	eta 0:00:06 lr 0.000092	time 0.4725 (0.4742)	loss 12.4551 (12.3402)	grad_norm 4.0946 (inf)	mem 15420MB
[2024-10-24 06:43:22 mlla_tiny] (main.py 304): INFO EPOCH 103 training takes 0:02:27
[2024-10-24 06:43:54 mlla_tiny] (main.py 350): INFO  * Acc@1 36.520 Acc@5 62.620
[2024-10-24 06:43:54 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 36.5%
[2024-10-24 06:44:25 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 06:44:25 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 06:44:25 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_103.pth saving......
[2024-10-24 06:44:26 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_103.pth saved !!!
[2024-10-24 06:44:26 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 06:44:27 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 06:44:27 mlla_tiny] (main.py 205): INFO Max accuracy: 36.52%
[2024-10-24 06:44:27 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 06:45:15 mlla_tiny] (main.py 296): INFO Train: [104/300][100/312]	eta 0:01:41 lr 0.000092	time 0.4732 (0.4763)	loss 11.4979 (12.2017)	grad_norm 8.7915 (inf)	mem 15420MB
[2024-10-24 06:46:02 mlla_tiny] (main.py 296): INFO Train: [104/300][200/312]	eta 0:00:53 lr 0.000092	time 0.4734 (0.4748)	loss 12.3121 (12.2773)	grad_norm 4.2439 (inf)	mem 15420MB
[2024-10-24 06:46:50 mlla_tiny] (main.py 296): INFO Train: [104/300][300/312]	eta 0:00:06 lr 0.000092	time 0.4733 (0.4744)	loss 12.1225 (12.3020)	grad_norm 5.5716 (inf)	mem 15420MB
[2024-10-24 06:46:55 mlla_tiny] (main.py 304): INFO EPOCH 104 training takes 0:02:28
[2024-10-24 06:47:26 mlla_tiny] (main.py 350): INFO  * Acc@1 37.480 Acc@5 62.860
[2024-10-24 06:47:26 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 37.5%
[2024-10-24 06:47:57 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 06:47:57 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 06:47:57 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_104.pth saving......
[2024-10-24 06:47:58 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_104.pth saved !!!
[2024-10-24 06:47:58 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 06:47:59 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 06:47:59 mlla_tiny] (main.py 205): INFO Max accuracy: 37.48%
[2024-10-24 06:47:59 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 06:48:47 mlla_tiny] (main.py 296): INFO Train: [105/300][100/312]	eta 0:01:41 lr 0.000092	time 0.4734 (0.4763)	loss 11.4211 (12.2357)	grad_norm 6.4147 (inf)	mem 15420MB
[2024-10-24 06:49:34 mlla_tiny] (main.py 296): INFO Train: [105/300][200/312]	eta 0:00:53 lr 0.000091	time 0.4734 (0.4747)	loss 12.0203 (12.2488)	grad_norm 5.3706 (inf)	mem 15420MB
[2024-10-24 06:50:22 mlla_tiny] (main.py 296): INFO Train: [105/300][300/312]	eta 0:00:06 lr 0.000091	time 0.4737 (0.4742)	loss 12.8295 (12.2698)	grad_norm 4.4801 (inf)	mem 15420MB
[2024-10-24 06:50:27 mlla_tiny] (main.py 304): INFO EPOCH 105 training takes 0:02:27
[2024-10-24 06:50:59 mlla_tiny] (main.py 350): INFO  * Acc@1 36.990 Acc@5 62.560
[2024-10-24 06:50:59 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 37.0%
[2024-10-24 06:51:31 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 06:51:31 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 06:51:31 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_105.pth saving......
[2024-10-24 06:51:32 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_105.pth saved !!!
[2024-10-24 06:51:32 mlla_tiny] (main.py 205): INFO Max accuracy: 37.48%
[2024-10-24 06:51:32 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 06:52:19 mlla_tiny] (main.py 296): INFO Train: [106/300][100/312]	eta 0:01:41 lr 0.000091	time 0.4710 (0.4765)	loss 12.5338 (12.2376)	grad_norm 5.7286 (inf)	mem 15420MB
[2024-10-24 06:53:07 mlla_tiny] (main.py 296): INFO Train: [106/300][200/312]	eta 0:00:53 lr 0.000091	time 0.4737 (0.4747)	loss 12.8040 (12.2645)	grad_norm 4.0808 (inf)	mem 15420MB
[2024-10-24 06:53:54 mlla_tiny] (main.py 296): INFO Train: [106/300][300/312]	eta 0:00:06 lr 0.000091	time 0.4737 (0.4743)	loss 12.7208 (12.2763)	grad_norm 5.3144 (inf)	mem 15420MB
[2024-10-24 06:54:00 mlla_tiny] (main.py 304): INFO EPOCH 106 training takes 0:02:28
[2024-10-24 06:54:31 mlla_tiny] (main.py 350): INFO  * Acc@1 37.300 Acc@5 63.240
[2024-10-24 06:54:31 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 37.3%
[2024-10-24 06:55:02 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 06:55:02 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 06:55:02 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_106.pth saving......
[2024-10-24 06:55:03 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_106.pth saved !!!
[2024-10-24 06:55:03 mlla_tiny] (main.py 205): INFO Max accuracy: 37.48%
[2024-10-24 06:55:03 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 06:55:51 mlla_tiny] (main.py 296): INFO Train: [107/300][100/312]	eta 0:01:41 lr 0.000090	time 0.4720 (0.4775)	loss 12.3355 (12.2031)	grad_norm 4.8911 (inf)	mem 15420MB
[2024-10-24 06:56:38 mlla_tiny] (main.py 296): INFO Train: [107/300][200/312]	eta 0:00:53 lr 0.000090	time 0.4719 (0.4751)	loss 11.5466 (12.1898)	grad_norm 7.2635 (inf)	mem 15420MB
[2024-10-24 06:57:26 mlla_tiny] (main.py 296): INFO Train: [107/300][300/312]	eta 0:00:06 lr 0.000090	time 0.4738 (0.4749)	loss 12.8132 (12.2226)	grad_norm 4.0814 (inf)	mem 15420MB
[2024-10-24 06:57:31 mlla_tiny] (main.py 304): INFO EPOCH 107 training takes 0:02:28
[2024-10-24 06:58:03 mlla_tiny] (main.py 350): INFO  * Acc@1 37.460 Acc@5 63.620
[2024-10-24 06:58:03 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 37.5%
[2024-10-24 06:58:34 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 06:58:34 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 06:58:34 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_107.pth saving......
[2024-10-24 06:58:35 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_107.pth saved !!!
[2024-10-24 06:58:35 mlla_tiny] (main.py 205): INFO Max accuracy: 37.48%
[2024-10-24 06:58:35 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 06:59:22 mlla_tiny] (main.py 296): INFO Train: [108/300][100/312]	eta 0:01:41 lr 0.000090	time 0.4726 (0.4760)	loss 12.7972 (12.2936)	grad_norm 4.2508 (inf)	mem 15420MB
[2024-10-24 07:00:10 mlla_tiny] (main.py 296): INFO Train: [108/300][200/312]	eta 0:00:53 lr 0.000090	time 0.4735 (0.4747)	loss 12.4341 (12.2851)	grad_norm 4.1787 (inf)	mem 15420MB
[2024-10-24 07:00:57 mlla_tiny] (main.py 296): INFO Train: [108/300][300/312]	eta 0:00:06 lr 0.000089	time 0.4744 (0.4743)	loss 12.0792 (12.2668)	grad_norm 4.4306 (inf)	mem 15420MB
[2024-10-24 07:01:03 mlla_tiny] (main.py 304): INFO EPOCH 108 training takes 0:02:28
[2024-10-24 07:01:34 mlla_tiny] (main.py 350): INFO  * Acc@1 37.520 Acc@5 63.480
[2024-10-24 07:01:34 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 37.5%
[2024-10-24 07:02:05 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 07:02:05 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 07:02:05 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_108.pth saving......
[2024-10-24 07:02:06 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_108.pth saved !!!
[2024-10-24 07:02:06 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 07:02:07 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 07:02:07 mlla_tiny] (main.py 205): INFO Max accuracy: 37.52%
[2024-10-24 07:02:07 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 07:02:55 mlla_tiny] (main.py 296): INFO Train: [109/300][100/312]	eta 0:01:41 lr 0.000089	time 0.4714 (0.4763)	loss 12.3802 (12.1365)	grad_norm 4.9813 (inf)	mem 15420MB
[2024-10-24 07:03:42 mlla_tiny] (main.py 296): INFO Train: [109/300][200/312]	eta 0:00:53 lr 0.000089	time 0.4720 (0.4745)	loss 12.4182 (12.1876)	grad_norm 5.9190 (inf)	mem 15420MB
[2024-10-24 07:04:29 mlla_tiny] (main.py 296): INFO Train: [109/300][300/312]	eta 0:00:06 lr 0.000089	time 0.4736 (0.4741)	loss 12.0545 (12.1951)	grad_norm 4.2503 (inf)	mem 15420MB
[2024-10-24 07:04:35 mlla_tiny] (main.py 304): INFO EPOCH 109 training takes 0:02:27
[2024-10-24 07:05:07 mlla_tiny] (main.py 350): INFO  * Acc@1 37.820 Acc@5 63.360
[2024-10-24 07:05:07 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 37.8%
[2024-10-24 07:05:38 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 07:05:38 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 07:05:38 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_109.pth saving......
[2024-10-24 07:05:39 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_109.pth saved !!!
[2024-10-24 07:05:39 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 07:05:40 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 07:05:40 mlla_tiny] (main.py 205): INFO Max accuracy: 37.82%
[2024-10-24 07:05:40 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 07:06:28 mlla_tiny] (main.py 296): INFO Train: [110/300][100/312]	eta 0:01:41 lr 0.000089	time 0.4710 (0.4757)	loss 12.5152 (12.2674)	grad_norm 5.2067 (inf)	mem 15420MB
[2024-10-24 07:07:15 mlla_tiny] (main.py 296): INFO Train: [110/300][200/312]	eta 0:00:53 lr 0.000089	time 0.4724 (0.4740)	loss 11.6486 (12.2094)	grad_norm 7.1437 (inf)	mem 15420MB
[2024-10-24 07:08:02 mlla_tiny] (main.py 296): INFO Train: [110/300][300/312]	eta 0:00:06 lr 0.000088	time 0.4732 (0.4738)	loss 12.9227 (12.2226)	grad_norm 4.2794 (inf)	mem 15420MB
[2024-10-24 07:08:08 mlla_tiny] (main.py 304): INFO EPOCH 110 training takes 0:02:27
[2024-10-24 07:08:39 mlla_tiny] (main.py 350): INFO  * Acc@1 38.270 Acc@5 63.690
[2024-10-24 07:08:39 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 38.3%
[2024-10-24 07:09:11 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 07:09:11 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 07:09:11 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_110.pth saving......
[2024-10-24 07:09:11 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_110.pth saved !!!
[2024-10-24 07:09:11 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 07:09:12 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 07:09:12 mlla_tiny] (main.py 205): INFO Max accuracy: 38.27%
[2024-10-24 07:09:12 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 07:10:00 mlla_tiny] (main.py 296): INFO Train: [111/300][100/312]	eta 0:01:41 lr 0.000088	time 0.4747 (0.4761)	loss 12.3284 (12.1687)	grad_norm 4.8002 (inf)	mem 15420MB
[2024-10-24 07:10:47 mlla_tiny] (main.py 296): INFO Train: [111/300][200/312]	eta 0:00:53 lr 0.000088	time 0.4735 (0.4745)	loss 12.2490 (12.1746)	grad_norm 4.8282 (inf)	mem 15420MB
[2024-10-24 07:11:35 mlla_tiny] (main.py 296): INFO Train: [111/300][300/312]	eta 0:00:06 lr 0.000088	time 0.4738 (0.4741)	loss 11.5390 (12.1875)	grad_norm 4.8812 (inf)	mem 15420MB
[2024-10-24 07:11:40 mlla_tiny] (main.py 304): INFO EPOCH 111 training takes 0:02:27
[2024-10-24 07:12:12 mlla_tiny] (main.py 350): INFO  * Acc@1 38.450 Acc@5 64.330
[2024-10-24 07:12:12 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 38.5%
[2024-10-24 07:12:43 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 07:12:43 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 07:12:43 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_111.pth saving......
[2024-10-24 07:12:44 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_111.pth saved !!!
[2024-10-24 07:12:44 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 07:12:45 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 07:12:45 mlla_tiny] (main.py 205): INFO Max accuracy: 38.45%
[2024-10-24 07:12:45 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 07:13:33 mlla_tiny] (main.py 296): INFO Train: [112/300][100/312]	eta 0:01:41 lr 0.000088	time 0.4713 (0.4765)	loss 12.7606 (12.1415)	grad_norm 5.6189 (inf)	mem 15420MB
[2024-10-24 07:14:20 mlla_tiny] (main.py 296): INFO Train: [112/300][200/312]	eta 0:00:53 lr 0.000087	time 0.4729 (0.4746)	loss 12.2899 (12.1962)	grad_norm 6.0250 (inf)	mem 15420MB
[2024-10-24 07:15:08 mlla_tiny] (main.py 296): INFO Train: [112/300][300/312]	eta 0:00:06 lr 0.000087	time 0.4737 (0.4742)	loss 11.7125 (12.1856)	grad_norm 6.4984 (inf)	mem 15420MB
[2024-10-24 07:15:13 mlla_tiny] (main.py 304): INFO EPOCH 112 training takes 0:02:27
[2024-10-24 07:15:45 mlla_tiny] (main.py 350): INFO  * Acc@1 38.570 Acc@5 64.050
[2024-10-24 07:15:45 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 38.6%
[2024-10-24 07:16:16 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 07:16:16 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 07:16:16 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_112.pth saving......
[2024-10-24 07:16:19 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_112.pth saved !!!
[2024-10-24 07:16:19 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 07:16:20 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 07:16:20 mlla_tiny] (main.py 205): INFO Max accuracy: 38.57%
[2024-10-24 07:16:20 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 07:17:07 mlla_tiny] (main.py 296): INFO Train: [113/300][100/312]	eta 0:01:41 lr 0.000087	time 0.4711 (0.4759)	loss 12.6480 (12.0612)	grad_norm 5.9003 (inf)	mem 15420MB
[2024-10-24 07:17:54 mlla_tiny] (main.py 296): INFO Train: [113/300][200/312]	eta 0:00:53 lr 0.000087	time 0.4735 (0.4743)	loss 12.4939 (12.1715)	grad_norm 5.1647 (inf)	mem 15420MB
[2024-10-24 07:18:42 mlla_tiny] (main.py 296): INFO Train: [113/300][300/312]	eta 0:00:06 lr 0.000087	time 0.4747 (0.4740)	loss 12.5094 (12.1374)	grad_norm 6.5897 (inf)	mem 15420MB
[2024-10-24 07:18:47 mlla_tiny] (main.py 304): INFO EPOCH 113 training takes 0:02:27
[2024-10-24 07:19:19 mlla_tiny] (main.py 350): INFO  * Acc@1 38.920 Acc@5 64.750
[2024-10-24 07:19:19 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 38.9%
[2024-10-24 07:19:50 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 07:19:50 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 07:19:50 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_113.pth saving......
[2024-10-24 07:19:51 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_113.pth saved !!!
[2024-10-24 07:19:51 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 07:19:52 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 07:19:52 mlla_tiny] (main.py 205): INFO Max accuracy: 38.92%
[2024-10-24 07:19:52 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 07:20:40 mlla_tiny] (main.py 296): INFO Train: [114/300][100/312]	eta 0:01:41 lr 0.000086	time 0.4721 (0.4758)	loss 11.3265 (12.0855)	grad_norm 6.4959 (inf)	mem 15420MB
[2024-10-24 07:21:27 mlla_tiny] (main.py 296): INFO Train: [114/300][200/312]	eta 0:00:53 lr 0.000086	time 0.4723 (0.4743)	loss 12.3381 (12.0948)	grad_norm 7.0442 (inf)	mem 15420MB
[2024-10-24 07:22:15 mlla_tiny] (main.py 296): INFO Train: [114/300][300/312]	eta 0:00:06 lr 0.000086	time 0.4735 (0.4740)	loss 12.6178 (12.1129)	grad_norm 4.0035 (inf)	mem 15420MB
[2024-10-24 07:22:20 mlla_tiny] (main.py 304): INFO EPOCH 114 training takes 0:02:27
[2024-10-24 07:22:52 mlla_tiny] (main.py 350): INFO  * Acc@1 38.580 Acc@5 64.400
[2024-10-24 07:22:52 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 38.6%
[2024-10-24 07:23:23 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.560
[2024-10-24 07:23:23 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 07:23:23 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_114.pth saving......
[2024-10-24 07:23:24 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_114.pth saved !!!
[2024-10-24 07:23:24 mlla_tiny] (main.py 205): INFO Max accuracy: 38.92%
[2024-10-24 07:23:24 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 07:24:12 mlla_tiny] (main.py 296): INFO Train: [115/300][100/312]	eta 0:01:41 lr 0.000086	time 0.4730 (0.4763)	loss 11.9741 (12.1571)	grad_norm 5.8867 (inf)	mem 15420MB
[2024-10-24 07:24:59 mlla_tiny] (main.py 296): INFO Train: [115/300][200/312]	eta 0:00:53 lr 0.000086	time 0.4727 (0.4745)	loss 11.6333 (12.1450)	grad_norm 6.0413 (inf)	mem 15420MB
[2024-10-24 07:25:46 mlla_tiny] (main.py 296): INFO Train: [115/300][300/312]	eta 0:00:06 lr 0.000085	time 0.4734 (0.4741)	loss 11.2121 (12.1187)	grad_norm 6.9437 (inf)	mem 15420MB
[2024-10-24 07:25:52 mlla_tiny] (main.py 304): INFO EPOCH 115 training takes 0:02:27
[2024-10-24 07:26:24 mlla_tiny] (main.py 350): INFO  * Acc@1 39.030 Acc@5 64.640
[2024-10-24 07:26:24 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 39.0%
[2024-10-24 07:26:55 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 07:26:55 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 07:26:55 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_115.pth saving......
[2024-10-24 07:26:56 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_115.pth saved !!!
[2024-10-24 07:26:56 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 07:26:57 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 07:26:57 mlla_tiny] (main.py 205): INFO Max accuracy: 39.03%
[2024-10-24 07:26:57 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 07:27:45 mlla_tiny] (main.py 296): INFO Train: [116/300][100/312]	eta 0:01:41 lr 0.000085	time 0.4727 (0.4763)	loss 12.4930 (12.1781)	grad_norm 4.4281 (inf)	mem 15420MB
[2024-10-24 07:28:32 mlla_tiny] (main.py 296): INFO Train: [116/300][200/312]	eta 0:00:53 lr 0.000085	time 0.4728 (0.4747)	loss 12.6538 (12.1585)	grad_norm 5.1834 (inf)	mem 15420MB
[2024-10-24 07:29:19 mlla_tiny] (main.py 296): INFO Train: [116/300][300/312]	eta 0:00:06 lr 0.000085	time 0.4730 (0.4742)	loss 12.5585 (12.1632)	grad_norm 5.8268 (inf)	mem 15420MB
[2024-10-24 07:29:25 mlla_tiny] (main.py 304): INFO EPOCH 116 training takes 0:02:27
[2024-10-24 07:29:57 mlla_tiny] (main.py 350): INFO  * Acc@1 38.910 Acc@5 65.110
[2024-10-24 07:29:57 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 38.9%
[2024-10-24 07:30:28 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 07:30:28 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 07:30:28 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_116.pth saving......
[2024-10-24 07:30:29 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_116.pth saved !!!
[2024-10-24 07:30:29 mlla_tiny] (main.py 205): INFO Max accuracy: 39.03%
[2024-10-24 07:30:29 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 07:31:17 mlla_tiny] (main.py 296): INFO Train: [117/300][100/312]	eta 0:01:41 lr 0.000085	time 0.4724 (0.4770)	loss 12.1013 (12.0954)	grad_norm 6.1898 (inf)	mem 15420MB
[2024-10-24 07:32:04 mlla_tiny] (main.py 296): INFO Train: [117/300][200/312]	eta 0:00:53 lr 0.000084	time 0.4734 (0.4749)	loss 12.5890 (12.1234)	grad_norm 4.8223 (nan)	mem 15420MB
[2024-10-24 07:32:52 mlla_tiny] (main.py 296): INFO Train: [117/300][300/312]	eta 0:00:06 lr 0.000084	time 0.4728 (0.4744)	loss 12.5764 (12.1586)	grad_norm 3.7155 (nan)	mem 15420MB
[2024-10-24 07:32:57 mlla_tiny] (main.py 304): INFO EPOCH 117 training takes 0:02:28
[2024-10-24 07:33:29 mlla_tiny] (main.py 350): INFO  * Acc@1 39.040 Acc@5 65.100
[2024-10-24 07:33:29 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 39.0%
[2024-10-24 07:34:00 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 07:34:00 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 07:34:00 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_117.pth saving......
[2024-10-24 07:34:01 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_117.pth saved !!!
[2024-10-24 07:34:01 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 07:34:02 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 07:34:02 mlla_tiny] (main.py 205): INFO Max accuracy: 39.04%
[2024-10-24 07:34:02 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 07:34:49 mlla_tiny] (main.py 296): INFO Train: [118/300][100/312]	eta 0:01:41 lr 0.000084	time 0.4716 (0.4756)	loss 11.4397 (11.9966)	grad_norm 6.4393 (inf)	mem 15420MB
[2024-10-24 07:35:37 mlla_tiny] (main.py 296): INFO Train: [118/300][200/312]	eta 0:00:53 lr 0.000084	time 0.4731 (0.4742)	loss 12.7636 (12.0135)	grad_norm 6.7296 (nan)	mem 15420MB
[2024-10-24 07:36:24 mlla_tiny] (main.py 296): INFO Train: [118/300][300/312]	eta 0:00:06 lr 0.000083	time 0.4732 (0.4739)	loss 12.6337 (12.0434)	grad_norm 4.3021 (nan)	mem 15420MB
[2024-10-24 07:36:30 mlla_tiny] (main.py 304): INFO EPOCH 118 training takes 0:02:27
[2024-10-24 07:37:01 mlla_tiny] (main.py 350): INFO  * Acc@1 39.740 Acc@5 65.520
[2024-10-24 07:37:01 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 39.7%
[2024-10-24 07:37:33 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 07:37:33 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 07:37:33 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_118.pth saving......
[2024-10-24 07:37:34 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_118.pth saved !!!
[2024-10-24 07:37:34 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 07:37:35 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 07:37:35 mlla_tiny] (main.py 205): INFO Max accuracy: 39.74%
[2024-10-24 07:37:35 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 07:38:23 mlla_tiny] (main.py 296): INFO Train: [119/300][100/312]	eta 0:01:41 lr 0.000083	time 0.4720 (0.4764)	loss 12.3330 (12.1229)	grad_norm 3.9487 (5.3330)	mem 15420MB
[2024-10-24 07:39:10 mlla_tiny] (main.py 296): INFO Train: [119/300][200/312]	eta 0:00:53 lr 0.000083	time 0.4734 (0.4746)	loss 11.0947 (12.0731)	grad_norm 4.8584 (nan)	mem 15420MB
[2024-10-24 07:39:57 mlla_tiny] (main.py 296): INFO Train: [119/300][300/312]	eta 0:00:06 lr 0.000083	time 0.5085 (0.4744)	loss 11.8039 (12.0783)	grad_norm 5.8630 (nan)	mem 15420MB
[2024-10-24 07:40:03 mlla_tiny] (main.py 304): INFO EPOCH 119 training takes 0:02:28
[2024-10-24 07:40:34 mlla_tiny] (main.py 350): INFO  * Acc@1 40.040 Acc@5 65.510
[2024-10-24 07:40:34 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 40.0%
[2024-10-24 07:41:06 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 07:41:06 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 07:41:06 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_119.pth saving......
[2024-10-24 07:41:07 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_119.pth saved !!!
[2024-10-24 07:41:07 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 07:41:08 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 07:41:08 mlla_tiny] (main.py 205): INFO Max accuracy: 40.04%
[2024-10-24 07:41:08 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 07:41:55 mlla_tiny] (main.py 296): INFO Train: [120/300][100/312]	eta 0:01:41 lr 0.000083	time 0.4729 (0.4765)	loss 11.3319 (11.9727)	grad_norm 4.9558 (inf)	mem 15420MB
[2024-10-24 07:42:43 mlla_tiny] (main.py 296): INFO Train: [120/300][200/312]	eta 0:00:53 lr 0.000082	time 0.4731 (0.4746)	loss 11.0223 (12.0157)	grad_norm 6.2455 (inf)	mem 15420MB
[2024-10-24 07:43:30 mlla_tiny] (main.py 296): INFO Train: [120/300][300/312]	eta 0:00:06 lr 0.000082	time 0.4726 (0.4742)	loss 11.8759 (12.0169)	grad_norm 7.0859 (inf)	mem 15420MB
[2024-10-24 07:43:36 mlla_tiny] (main.py 304): INFO EPOCH 120 training takes 0:02:27
[2024-10-24 07:44:07 mlla_tiny] (main.py 350): INFO  * Acc@1 38.870 Acc@5 64.780
[2024-10-24 07:44:07 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 38.9%
[2024-10-24 07:44:39 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 07:44:39 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 07:44:39 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_120.pth saving......
[2024-10-24 07:44:40 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_120.pth saved !!!
[2024-10-24 07:44:40 mlla_tiny] (main.py 205): INFO Max accuracy: 40.04%
[2024-10-24 07:44:40 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 07:45:28 mlla_tiny] (main.py 296): INFO Train: [121/300][100/312]	eta 0:01:41 lr 0.000082	time 0.4722 (0.4769)	loss 11.4401 (12.0779)	grad_norm 5.3385 (inf)	mem 15420MB
[2024-10-24 07:46:15 mlla_tiny] (main.py 296): INFO Train: [121/300][200/312]	eta 0:00:53 lr 0.000082	time 0.4719 (0.4749)	loss 11.9616 (12.0222)	grad_norm 4.5731 (nan)	mem 15420MB
[2024-10-24 07:47:02 mlla_tiny] (main.py 296): INFO Train: [121/300][300/312]	eta 0:00:06 lr 0.000082	time 0.4729 (0.4743)	loss 12.5723 (12.0428)	grad_norm 4.8602 (nan)	mem 15420MB
[2024-10-24 07:47:08 mlla_tiny] (main.py 304): INFO EPOCH 121 training takes 0:02:27
[2024-10-24 07:47:39 mlla_tiny] (main.py 350): INFO  * Acc@1 39.950 Acc@5 65.680
[2024-10-24 07:47:39 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 40.0%
[2024-10-24 07:48:10 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 07:48:10 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 07:48:10 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_121.pth saving......
[2024-10-24 07:48:12 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_121.pth saved !!!
[2024-10-24 07:48:12 mlla_tiny] (main.py 205): INFO Max accuracy: 40.04%
[2024-10-24 07:48:12 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 07:48:59 mlla_tiny] (main.py 296): INFO Train: [122/300][100/312]	eta 0:01:41 lr 0.000081	time 0.4727 (0.4761)	loss 12.6181 (12.0951)	grad_norm 4.5870 (inf)	mem 15420MB
[2024-10-24 07:49:46 mlla_tiny] (main.py 296): INFO Train: [122/300][200/312]	eta 0:00:53 lr 0.000081	time 0.4734 (0.4744)	loss 12.2197 (12.0586)	grad_norm 4.7820 (inf)	mem 15420MB
[2024-10-24 07:50:34 mlla_tiny] (main.py 296): INFO Train: [122/300][300/312]	eta 0:00:06 lr 0.000081	time 0.4737 (0.4741)	loss 12.8292 (12.0516)	grad_norm 5.6041 (inf)	mem 15420MB
[2024-10-24 07:50:39 mlla_tiny] (main.py 304): INFO EPOCH 122 training takes 0:02:27
[2024-10-24 07:51:11 mlla_tiny] (main.py 350): INFO  * Acc@1 40.370 Acc@5 65.770
[2024-10-24 07:51:11 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 40.4%
[2024-10-24 07:51:42 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 07:51:42 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 07:51:42 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_122.pth saving......
[2024-10-24 07:51:43 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_122.pth saved !!!
[2024-10-24 07:51:43 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 07:51:44 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 07:51:44 mlla_tiny] (main.py 205): INFO Max accuracy: 40.37%
[2024-10-24 07:51:44 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 07:52:32 mlla_tiny] (main.py 296): INFO Train: [123/300][100/312]	eta 0:01:41 lr 0.000081	time 0.4721 (0.4767)	loss 12.1384 (12.0720)	grad_norm 5.1220 (inf)	mem 15420MB
[2024-10-24 07:53:19 mlla_tiny] (main.py 296): INFO Train: [123/300][200/312]	eta 0:00:53 lr 0.000081	time 0.4728 (0.4748)	loss 11.5463 (12.0902)	grad_norm 8.0906 (inf)	mem 15420MB
[2024-10-24 07:54:07 mlla_tiny] (main.py 296): INFO Train: [123/300][300/312]	eta 0:00:06 lr 0.000080	time 0.4734 (0.4744)	loss 12.4785 (12.0631)	grad_norm 3.7623 (inf)	mem 15420MB
[2024-10-24 07:54:12 mlla_tiny] (main.py 304): INFO EPOCH 123 training takes 0:02:28
[2024-10-24 07:54:44 mlla_tiny] (main.py 350): INFO  * Acc@1 40.330 Acc@5 65.870
[2024-10-24 07:54:44 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 40.3%
[2024-10-24 07:55:15 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 07:55:15 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 07:55:15 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_123.pth saving......
[2024-10-24 07:55:16 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_123.pth saved !!!
[2024-10-24 07:55:16 mlla_tiny] (main.py 205): INFO Max accuracy: 40.37%
[2024-10-24 07:55:16 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 07:56:04 mlla_tiny] (main.py 296): INFO Train: [124/300][100/312]	eta 0:01:41 lr 0.000080	time 0.4721 (0.4761)	loss 12.4584 (12.0227)	grad_norm 7.3557 (inf)	mem 15420MB
[2024-10-24 07:56:51 mlla_tiny] (main.py 296): INFO Train: [124/300][200/312]	eta 0:00:53 lr 0.000080	time 0.4737 (0.4747)	loss 11.8427 (12.0535)	grad_norm 4.6944 (inf)	mem 15420MB
[2024-10-24 07:57:38 mlla_tiny] (main.py 296): INFO Train: [124/300][300/312]	eta 0:00:06 lr 0.000080	time 0.4727 (0.4742)	loss 12.0211 (12.0555)	grad_norm 7.1112 (inf)	mem 15420MB
[2024-10-24 07:57:44 mlla_tiny] (main.py 304): INFO EPOCH 124 training takes 0:02:27
[2024-10-24 07:58:15 mlla_tiny] (main.py 350): INFO  * Acc@1 40.700 Acc@5 66.170
[2024-10-24 07:58:15 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 40.7%
[2024-10-24 07:58:46 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 07:58:46 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 07:58:46 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_124.pth saving......
[2024-10-24 07:58:47 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_124.pth saved !!!
[2024-10-24 07:58:47 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 07:58:48 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 07:58:48 mlla_tiny] (main.py 205): INFO Max accuracy: 40.70%
[2024-10-24 07:58:48 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 07:59:36 mlla_tiny] (main.py 296): INFO Train: [125/300][100/312]	eta 0:01:41 lr 0.000080	time 0.4728 (0.4765)	loss 12.6894 (11.9495)	grad_norm 5.3488 (inf)	mem 15420MB
[2024-10-24 08:00:23 mlla_tiny] (main.py 296): INFO Train: [125/300][200/312]	eta 0:00:53 lr 0.000079	time 0.4733 (0.4750)	loss 12.5974 (11.9951)	grad_norm 4.8925 (inf)	mem 15420MB
[2024-10-24 08:01:11 mlla_tiny] (main.py 296): INFO Train: [125/300][300/312]	eta 0:00:06 lr 0.000079	time 0.4730 (0.4745)	loss 12.3044 (12.0211)	grad_norm 4.3963 (inf)	mem 15420MB
[2024-10-24 08:01:16 mlla_tiny] (main.py 304): INFO EPOCH 125 training takes 0:02:28
[2024-10-24 08:01:48 mlla_tiny] (main.py 350): INFO  * Acc@1 40.820 Acc@5 66.270
[2024-10-24 08:01:48 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 40.8%
[2024-10-24 08:02:19 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 08:02:19 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 08:02:19 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_125.pth saving......
[2024-10-24 08:02:20 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_125.pth saved !!!
[2024-10-24 08:02:20 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 08:02:21 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 08:02:21 mlla_tiny] (main.py 205): INFO Max accuracy: 40.82%
[2024-10-24 08:02:21 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 08:03:09 mlla_tiny] (main.py 296): INFO Train: [126/300][100/312]	eta 0:01:41 lr 0.000079	time 0.4731 (0.4765)	loss 12.8176 (11.9658)	grad_norm 5.0600 (inf)	mem 15420MB
[2024-10-24 08:03:56 mlla_tiny] (main.py 296): INFO Train: [126/300][200/312]	eta 0:00:53 lr 0.000079	time 0.4734 (0.4747)	loss 11.0163 (11.9849)	grad_norm 7.1561 (inf)	mem 15420MB
[2024-10-24 08:04:43 mlla_tiny] (main.py 296): INFO Train: [126/300][300/312]	eta 0:00:06 lr 0.000079	time 0.4721 (0.4743)	loss 11.4620 (11.9726)	grad_norm 5.3318 (inf)	mem 15420MB
[2024-10-24 08:04:49 mlla_tiny] (main.py 304): INFO EPOCH 126 training takes 0:02:27
[2024-10-24 08:05:21 mlla_tiny] (main.py 350): INFO  * Acc@1 40.620 Acc@5 66.300
[2024-10-24 08:05:21 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 40.6%
[2024-10-24 08:05:52 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 08:05:52 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 08:05:52 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_126.pth saving......
[2024-10-24 08:05:53 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_126.pth saved !!!
[2024-10-24 08:05:53 mlla_tiny] (main.py 205): INFO Max accuracy: 40.82%
[2024-10-24 08:05:53 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 08:06:41 mlla_tiny] (main.py 296): INFO Train: [127/300][100/312]	eta 0:01:41 lr 0.000078	time 0.4727 (0.4757)	loss 11.9839 (12.0723)	grad_norm 5.3356 (inf)	mem 15420MB
[2024-10-24 08:07:28 mlla_tiny] (main.py 296): INFO Train: [127/300][200/312]	eta 0:00:53 lr 0.000078	time 0.4737 (0.4745)	loss 12.4632 (12.0662)	grad_norm 4.0622 (inf)	mem 15420MB
[2024-10-24 08:08:16 mlla_tiny] (main.py 296): INFO Train: [127/300][300/312]	eta 0:00:06 lr 0.000078	time 0.4733 (0.4740)	loss 12.3909 (12.0127)	grad_norm 4.1460 (inf)	mem 15420MB
[2024-10-24 08:08:21 mlla_tiny] (main.py 304): INFO EPOCH 127 training takes 0:02:27
[2024-10-24 08:08:53 mlla_tiny] (main.py 350): INFO  * Acc@1 41.060 Acc@5 66.240
[2024-10-24 08:08:53 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 41.1%
[2024-10-24 08:09:24 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 08:09:24 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 08:09:24 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_127.pth saving......
[2024-10-24 08:09:27 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_127.pth saved !!!
[2024-10-24 08:09:27 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 08:09:28 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 08:09:28 mlla_tiny] (main.py 205): INFO Max accuracy: 41.06%
[2024-10-24 08:09:28 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 08:10:15 mlla_tiny] (main.py 296): INFO Train: [128/300][100/312]	eta 0:01:41 lr 0.000078	time 0.4723 (0.4767)	loss 12.5117 (11.9833)	grad_norm 5.5590 (inf)	mem 15420MB
[2024-10-24 08:11:03 mlla_tiny] (main.py 296): INFO Train: [128/300][200/312]	eta 0:00:53 lr 0.000077	time 0.4739 (0.4750)	loss 12.1462 (11.9730)	grad_norm 4.5293 (inf)	mem 15420MB
[2024-10-24 08:11:50 mlla_tiny] (main.py 296): INFO Train: [128/300][300/312]	eta 0:00:06 lr 0.000077	time 0.4743 (0.4746)	loss 12.6485 (11.9629)	grad_norm 4.5076 (inf)	mem 15420MB
[2024-10-24 08:11:56 mlla_tiny] (main.py 304): INFO EPOCH 128 training takes 0:02:28
[2024-10-24 08:12:27 mlla_tiny] (main.py 350): INFO  * Acc@1 40.490 Acc@5 66.000
[2024-10-24 08:12:27 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 40.5%
[2024-10-24 08:12:58 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 08:12:58 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 08:12:58 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_128.pth saving......
[2024-10-24 08:12:59 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_128.pth saved !!!
[2024-10-24 08:12:59 mlla_tiny] (main.py 205): INFO Max accuracy: 41.06%
[2024-10-24 08:12:59 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 08:13:47 mlla_tiny] (main.py 296): INFO Train: [129/300][100/312]	eta 0:01:41 lr 0.000077	time 0.4734 (0.4766)	loss 11.0444 (11.9538)	grad_norm 6.9831 (inf)	mem 15420MB
[2024-10-24 08:14:34 mlla_tiny] (main.py 296): INFO Train: [129/300][200/312]	eta 0:00:53 lr 0.000077	time 0.4737 (0.4750)	loss 11.6970 (11.9322)	grad_norm 8.3482 (inf)	mem 15420MB
[2024-10-24 08:15:22 mlla_tiny] (main.py 296): INFO Train: [129/300][300/312]	eta 0:00:06 lr 0.000077	time 0.4736 (0.4745)	loss 11.1644 (11.9665)	grad_norm 6.9243 (inf)	mem 15420MB
[2024-10-24 08:15:27 mlla_tiny] (main.py 304): INFO EPOCH 129 training takes 0:02:28
[2024-10-24 08:15:58 mlla_tiny] (main.py 350): INFO  * Acc@1 41.000 Acc@5 66.350
[2024-10-24 08:15:58 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 41.0%
[2024-10-24 08:16:31 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 08:16:31 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 08:16:31 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_129.pth saving......
[2024-10-24 08:16:31 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_129.pth saved !!!
[2024-10-24 08:16:31 mlla_tiny] (main.py 205): INFO Max accuracy: 41.06%
[2024-10-24 08:16:31 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 08:17:19 mlla_tiny] (main.py 296): INFO Train: [130/300][100/312]	eta 0:01:41 lr 0.000076	time 0.4733 (0.4767)	loss 12.3540 (11.9879)	grad_norm 5.4850 (inf)	mem 15420MB
[2024-10-24 08:18:06 mlla_tiny] (main.py 296): INFO Train: [130/300][200/312]	eta 0:00:53 lr 0.000076	time 0.4731 (0.4750)	loss 12.0992 (11.9919)	grad_norm 5.8079 (inf)	mem 15420MB
[2024-10-24 08:18:54 mlla_tiny] (main.py 296): INFO Train: [130/300][300/312]	eta 0:00:06 lr 0.000076	time 0.4736 (0.4747)	loss 12.6931 (11.9753)	grad_norm 5.2101 (inf)	mem 15420MB
[2024-10-24 08:19:00 mlla_tiny] (main.py 304): INFO EPOCH 130 training takes 0:02:28
[2024-10-24 08:19:31 mlla_tiny] (main.py 350): INFO  * Acc@1 41.220 Acc@5 66.520
[2024-10-24 08:19:31 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 41.2%
[2024-10-24 08:20:03 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 08:20:03 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 08:20:03 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_130.pth saving......
[2024-10-24 08:20:04 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_130.pth saved !!!
[2024-10-24 08:20:04 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 08:20:05 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 08:20:05 mlla_tiny] (main.py 205): INFO Max accuracy: 41.22%
[2024-10-24 08:20:05 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 08:20:52 mlla_tiny] (main.py 296): INFO Train: [131/300][100/312]	eta 0:01:41 lr 0.000076	time 0.4730 (0.4767)	loss 12.7763 (11.9729)	grad_norm 4.5534 (inf)	mem 15420MB
[2024-10-24 08:21:40 mlla_tiny] (main.py 296): INFO Train: [131/300][200/312]	eta 0:00:53 lr 0.000076	time 0.4732 (0.4748)	loss 11.1405 (11.9873)	grad_norm 4.7496 (inf)	mem 15420MB
[2024-10-24 08:22:27 mlla_tiny] (main.py 296): INFO Train: [131/300][300/312]	eta 0:00:06 lr 0.000075	time 0.4727 (0.4744)	loss 12.1746 (11.9951)	grad_norm 5.4254 (inf)	mem 15420MB
[2024-10-24 08:22:33 mlla_tiny] (main.py 304): INFO EPOCH 131 training takes 0:02:28
[2024-10-24 08:23:04 mlla_tiny] (main.py 350): INFO  * Acc@1 41.260 Acc@5 66.710
[2024-10-24 08:23:04 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 41.3%
[2024-10-24 08:23:35 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 08:23:35 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 08:23:35 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_131.pth saving......
[2024-10-24 08:23:36 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_131.pth saved !!!
[2024-10-24 08:23:36 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 08:23:37 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 08:23:37 mlla_tiny] (main.py 205): INFO Max accuracy: 41.26%
[2024-10-24 08:23:37 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 08:24:24 mlla_tiny] (main.py 296): INFO Train: [132/300][100/312]	eta 0:01:41 lr 0.000075	time 0.4723 (0.4759)	loss 12.5180 (12.0124)	grad_norm 5.4971 (inf)	mem 15420MB
[2024-10-24 08:25:12 mlla_tiny] (main.py 296): INFO Train: [132/300][200/312]	eta 0:00:53 lr 0.000075	time 0.4727 (0.4744)	loss 12.3266 (11.9776)	grad_norm 5.8504 (inf)	mem 15420MB
[2024-10-24 08:25:59 mlla_tiny] (main.py 296): INFO Train: [132/300][300/312]	eta 0:00:06 lr 0.000075	time 0.4731 (0.4739)	loss 12.1718 (11.9620)	grad_norm 5.2172 (inf)	mem 15420MB
[2024-10-24 08:26:05 mlla_tiny] (main.py 304): INFO EPOCH 132 training takes 0:02:27
[2024-10-24 08:26:37 mlla_tiny] (main.py 350): INFO  * Acc@1 41.490 Acc@5 66.930
[2024-10-24 08:26:37 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 41.5%
[2024-10-24 08:27:08 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 08:27:08 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 08:27:08 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_132.pth saving......
[2024-10-24 08:27:09 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_132.pth saved !!!
[2024-10-24 08:27:09 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 08:27:10 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 08:27:10 mlla_tiny] (main.py 205): INFO Max accuracy: 41.49%
[2024-10-24 08:27:10 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 08:27:58 mlla_tiny] (main.py 296): INFO Train: [133/300][100/312]	eta 0:01:41 lr 0.000075	time 0.4719 (0.4759)	loss 12.5626 (11.9308)	grad_norm 4.6866 (inf)	mem 15420MB
[2024-10-24 08:28:45 mlla_tiny] (main.py 296): INFO Train: [133/300][200/312]	eta 0:00:53 lr 0.000074	time 0.4746 (0.4742)	loss 11.4236 (11.9372)	grad_norm 7.8763 (inf)	mem 15420MB
[2024-10-24 08:29:33 mlla_tiny] (main.py 296): INFO Train: [133/300][300/312]	eta 0:00:06 lr 0.000074	time 0.4728 (0.4740)	loss 11.3978 (11.9435)	grad_norm 7.1604 (inf)	mem 15420MB
[2024-10-24 08:29:38 mlla_tiny] (main.py 304): INFO EPOCH 133 training takes 0:02:27
[2024-10-24 08:30:10 mlla_tiny] (main.py 350): INFO  * Acc@1 41.480 Acc@5 67.390
[2024-10-24 08:30:10 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 41.5%
[2024-10-24 08:30:42 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 08:30:42 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 08:30:42 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_133.pth saving......
[2024-10-24 08:30:46 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_133.pth saved !!!
[2024-10-24 08:30:46 mlla_tiny] (main.py 205): INFO Max accuracy: 41.49%
[2024-10-24 08:30:46 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 08:31:34 mlla_tiny] (main.py 296): INFO Train: [134/300][100/312]	eta 0:01:41 lr 0.000074	time 0.4742 (0.4760)	loss 10.8222 (12.0303)	grad_norm 6.6135 (inf)	mem 15420MB
[2024-10-24 08:32:21 mlla_tiny] (main.py 296): INFO Train: [134/300][200/312]	eta 0:00:53 lr 0.000074	time 0.4733 (0.4744)	loss 11.6277 (11.9727)	grad_norm 6.5374 (inf)	mem 15420MB
[2024-10-24 08:33:09 mlla_tiny] (main.py 296): INFO Train: [134/300][300/312]	eta 0:00:06 lr 0.000073	time 0.4733 (0.4742)	loss 11.1613 (11.9948)	grad_norm 5.5380 (inf)	mem 15420MB
[2024-10-24 08:33:14 mlla_tiny] (main.py 304): INFO EPOCH 134 training takes 0:02:27
[2024-10-24 08:33:46 mlla_tiny] (main.py 350): INFO  * Acc@1 41.700 Acc@5 67.240
[2024-10-24 08:33:46 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 41.7%
[2024-10-24 08:34:17 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 08:34:17 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 08:34:17 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_134.pth saving......
[2024-10-24 08:34:18 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_134.pth saved !!!
[2024-10-24 08:34:18 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 08:34:19 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 08:34:19 mlla_tiny] (main.py 205): INFO Max accuracy: 41.70%
[2024-10-24 08:34:19 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 08:35:07 mlla_tiny] (main.py 296): INFO Train: [135/300][100/312]	eta 0:01:41 lr 0.000073	time 0.4726 (0.4770)	loss 11.2241 (11.9014)	grad_norm 7.6940 (inf)	mem 15420MB
[2024-10-24 08:35:54 mlla_tiny] (main.py 296): INFO Train: [135/300][200/312]	eta 0:00:53 lr 0.000073	time 0.4732 (0.4751)	loss 11.6114 (11.9013)	grad_norm 8.8544 (inf)	mem 15420MB
[2024-10-24 08:36:42 mlla_tiny] (main.py 296): INFO Train: [135/300][300/312]	eta 0:00:06 lr 0.000073	time 0.4735 (0.4746)	loss 12.4918 (11.8771)	grad_norm 5.4124 (inf)	mem 15420MB
[2024-10-24 08:36:48 mlla_tiny] (main.py 304): INFO EPOCH 135 training takes 0:02:28
[2024-10-24 08:37:19 mlla_tiny] (main.py 350): INFO  * Acc@1 41.570 Acc@5 66.270
[2024-10-24 08:37:19 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 41.6%
[2024-10-24 08:37:50 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 08:37:50 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 08:37:50 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_135.pth saving......
[2024-10-24 08:37:51 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_135.pth saved !!!
[2024-10-24 08:37:51 mlla_tiny] (main.py 205): INFO Max accuracy: 41.70%
[2024-10-24 08:37:51 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 08:38:39 mlla_tiny] (main.py 296): INFO Train: [136/300][100/312]	eta 0:01:41 lr 0.000073	time 0.4721 (0.4763)	loss 12.2025 (11.8263)	grad_norm 5.4140 (inf)	mem 15420MB
[2024-10-24 08:39:26 mlla_tiny] (main.py 296): INFO Train: [136/300][200/312]	eta 0:00:53 lr 0.000072	time 0.4737 (0.4750)	loss 11.7983 (11.9086)	grad_norm 5.7594 (inf)	mem 15420MB
[2024-10-24 08:40:13 mlla_tiny] (main.py 296): INFO Train: [136/300][300/312]	eta 0:00:06 lr 0.000072	time 0.4740 (0.4749)	loss 12.6905 (11.9595)	grad_norm 4.7687 (inf)	mem 15420MB
[2024-10-24 08:40:19 mlla_tiny] (main.py 304): INFO EPOCH 136 training takes 0:02:28
[2024-10-24 08:40:51 mlla_tiny] (main.py 350): INFO  * Acc@1 41.710 Acc@5 66.480
[2024-10-24 08:40:51 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 41.7%
[2024-10-24 08:41:22 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 08:41:22 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 08:41:22 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_136.pth saving......
[2024-10-24 08:41:24 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_136.pth saved !!!
[2024-10-24 08:41:24 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 08:41:25 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 08:41:25 mlla_tiny] (main.py 205): INFO Max accuracy: 41.71%
[2024-10-24 08:41:25 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 08:42:12 mlla_tiny] (main.py 296): INFO Train: [137/300][100/312]	eta 0:01:41 lr 0.000072	time 0.4722 (0.4759)	loss 12.2238 (11.8723)	grad_norm 4.0318 (nan)	mem 15420MB
[2024-10-24 08:43:00 mlla_tiny] (main.py 296): INFO Train: [137/300][200/312]	eta 0:00:53 lr 0.000072	time 0.4737 (0.4746)	loss 11.7831 (11.8926)	grad_norm 4.1474 (nan)	mem 15420MB
[2024-10-24 08:43:47 mlla_tiny] (main.py 296): INFO Train: [137/300][300/312]	eta 0:00:06 lr 0.000072	time 0.4738 (0.4743)	loss 10.9808 (11.8725)	grad_norm 7.3625 (nan)	mem 15420MB
[2024-10-24 08:43:53 mlla_tiny] (main.py 304): INFO EPOCH 137 training takes 0:02:27
[2024-10-24 08:44:24 mlla_tiny] (main.py 350): INFO  * Acc@1 42.010 Acc@5 67.590
[2024-10-24 08:44:24 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 42.0%
[2024-10-24 08:44:55 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 08:44:55 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 08:44:55 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_137.pth saving......
[2024-10-24 08:44:56 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_137.pth saved !!!
[2024-10-24 08:44:56 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 08:44:57 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 08:44:57 mlla_tiny] (main.py 205): INFO Max accuracy: 42.01%
[2024-10-24 08:44:57 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 08:45:45 mlla_tiny] (main.py 296): INFO Train: [138/300][100/312]	eta 0:01:41 lr 0.000071	time 0.4714 (0.4767)	loss 12.4235 (11.8926)	grad_norm 5.3444 (inf)	mem 15420MB
[2024-10-24 08:46:32 mlla_tiny] (main.py 296): INFO Train: [138/300][200/312]	eta 0:00:53 lr 0.000071	time 0.4740 (0.4750)	loss 12.7337 (11.8551)	grad_norm 5.0505 (inf)	mem 15420MB
[2024-10-24 08:47:19 mlla_tiny] (main.py 296): INFO Train: [138/300][300/312]	eta 0:00:06 lr 0.000071	time 0.4741 (0.4746)	loss 10.9935 (11.8453)	grad_norm 11.3026 (inf)	mem 15420MB
[2024-10-24 08:47:25 mlla_tiny] (main.py 304): INFO EPOCH 138 training takes 0:02:28
[2024-10-24 08:47:56 mlla_tiny] (main.py 350): INFO  * Acc@1 42.630 Acc@5 67.400
[2024-10-24 08:47:56 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 42.6%
[2024-10-24 08:48:28 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 08:48:28 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 08:48:28 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_138.pth saving......
[2024-10-24 08:48:29 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_138.pth saved !!!
[2024-10-24 08:48:29 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 08:48:30 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 08:48:30 mlla_tiny] (main.py 205): INFO Max accuracy: 42.63%
[2024-10-24 08:48:30 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 08:49:17 mlla_tiny] (main.py 296): INFO Train: [139/300][100/312]	eta 0:01:41 lr 0.000071	time 0.4730 (0.4763)	loss 12.6211 (11.8646)	grad_norm 5.0568 (inf)	mem 15420MB
[2024-10-24 08:50:05 mlla_tiny] (main.py 296): INFO Train: [139/300][200/312]	eta 0:00:53 lr 0.000070	time 0.4733 (0.4748)	loss 11.3419 (11.8890)	grad_norm 8.8124 (inf)	mem 15420MB
[2024-10-24 08:50:52 mlla_tiny] (main.py 296): INFO Train: [139/300][300/312]	eta 0:00:06 lr 0.000070	time 0.4732 (0.4744)	loss 11.6543 (11.8894)	grad_norm 7.3066 (inf)	mem 15420MB
[2024-10-24 08:50:58 mlla_tiny] (main.py 304): INFO EPOCH 139 training takes 0:02:28
[2024-10-24 08:51:29 mlla_tiny] (main.py 350): INFO  * Acc@1 41.740 Acc@5 66.970
[2024-10-24 08:51:29 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 41.7%
[2024-10-24 08:52:00 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 08:52:00 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 08:52:00 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_139.pth saving......
[2024-10-24 08:52:01 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_139.pth saved !!!
[2024-10-24 08:52:01 mlla_tiny] (main.py 205): INFO Max accuracy: 42.63%
[2024-10-24 08:52:01 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 08:52:49 mlla_tiny] (main.py 296): INFO Train: [140/300][100/312]	eta 0:01:41 lr 0.000070	time 0.4726 (0.4764)	loss 11.6471 (11.9068)	grad_norm 6.1566 (inf)	mem 15420MB
[2024-10-24 08:53:36 mlla_tiny] (main.py 296): INFO Train: [140/300][200/312]	eta 0:00:53 lr 0.000070	time 0.4731 (0.4749)	loss 11.9248 (11.8828)	grad_norm 7.8510 (inf)	mem 15420MB
[2024-10-24 08:54:24 mlla_tiny] (main.py 296): INFO Train: [140/300][300/312]	eta 0:00:06 lr 0.000070	time 0.4737 (0.4744)	loss 12.4319 (11.8864)	grad_norm 5.6656 (inf)	mem 15420MB
[2024-10-24 08:54:29 mlla_tiny] (main.py 304): INFO EPOCH 140 training takes 0:02:28
[2024-10-24 08:55:01 mlla_tiny] (main.py 350): INFO  * Acc@1 42.560 Acc@5 67.410
[2024-10-24 08:55:01 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 42.6%
[2024-10-24 08:55:32 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 08:55:32 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 08:55:32 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_140.pth saving......
[2024-10-24 08:55:33 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_140.pth saved !!!
[2024-10-24 08:55:33 mlla_tiny] (main.py 205): INFO Max accuracy: 42.63%
[2024-10-24 08:55:33 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 08:56:20 mlla_tiny] (main.py 296): INFO Train: [141/300][100/312]	eta 0:01:41 lr 0.000069	time 0.4729 (0.4773)	loss 12.2260 (11.9140)	grad_norm 4.5610 (inf)	mem 15420MB
[2024-10-24 08:57:08 mlla_tiny] (main.py 296): INFO Train: [141/300][200/312]	eta 0:00:53 lr 0.000069	time 0.4737 (0.4753)	loss 10.8807 (11.8450)	grad_norm 5.0642 (inf)	mem 15420MB
[2024-10-24 08:57:55 mlla_tiny] (main.py 296): INFO Train: [141/300][300/312]	eta 0:00:06 lr 0.000069	time 0.4749 (0.4747)	loss 12.1395 (11.8499)	grad_norm 5.2160 (inf)	mem 15420MB
[2024-10-24 08:58:01 mlla_tiny] (main.py 304): INFO EPOCH 141 training takes 0:02:28
[2024-10-24 08:58:32 mlla_tiny] (main.py 350): INFO  * Acc@1 42.140 Acc@5 67.090
[2024-10-24 08:58:32 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 42.1%
[2024-10-24 08:59:03 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 08:59:03 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 08:59:04 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_141.pth saving......
[2024-10-24 08:59:04 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_141.pth saved !!!
[2024-10-24 08:59:04 mlla_tiny] (main.py 205): INFO Max accuracy: 42.63%
[2024-10-24 08:59:04 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 08:59:52 mlla_tiny] (main.py 296): INFO Train: [142/300][100/312]	eta 0:01:41 lr 0.000069	time 0.4713 (0.4764)	loss 11.4712 (11.8464)	grad_norm 6.4373 (inf)	mem 15420MB
[2024-10-24 09:00:39 mlla_tiny] (main.py 296): INFO Train: [142/300][200/312]	eta 0:00:53 lr 0.000069	time 0.4754 (0.4743)	loss 11.4374 (11.8169)	grad_norm 9.0890 (inf)	mem 15420MB
[2024-10-24 09:01:27 mlla_tiny] (main.py 296): INFO Train: [142/300][300/312]	eta 0:00:06 lr 0.000068	time 0.4728 (0.4738)	loss 12.4568 (11.8280)	grad_norm 4.8040 (inf)	mem 15420MB
[2024-10-24 09:01:32 mlla_tiny] (main.py 304): INFO EPOCH 142 training takes 0:02:27
[2024-10-24 09:02:05 mlla_tiny] (main.py 350): INFO  * Acc@1 42.210 Acc@5 67.530
[2024-10-24 09:02:05 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 42.2%
[2024-10-24 09:02:36 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 09:02:36 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 09:02:36 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_142.pth saving......
[2024-10-24 09:02:38 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_142.pth saved !!!
[2024-10-24 09:02:38 mlla_tiny] (main.py 205): INFO Max accuracy: 42.63%
[2024-10-24 09:02:38 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 09:03:25 mlla_tiny] (main.py 296): INFO Train: [143/300][100/312]	eta 0:01:41 lr 0.000068	time 0.5098 (0.4768)	loss 11.9967 (11.8773)	grad_norm 9.9044 (inf)	mem 15420MB
[2024-10-24 09:04:13 mlla_tiny] (main.py 296): INFO Train: [143/300][200/312]	eta 0:00:53 lr 0.000068	time 0.4731 (0.4749)	loss 12.3563 (11.9335)	grad_norm 5.7991 (inf)	mem 15420MB
[2024-10-24 09:05:00 mlla_tiny] (main.py 296): INFO Train: [143/300][300/312]	eta 0:00:06 lr 0.000068	time 0.4737 (0.4745)	loss 12.4755 (11.9247)	grad_norm 6.3653 (inf)	mem 15420MB
[2024-10-24 09:05:06 mlla_tiny] (main.py 304): INFO EPOCH 143 training takes 0:02:28
[2024-10-24 09:05:38 mlla_tiny] (main.py 350): INFO  * Acc@1 42.600 Acc@5 67.000
[2024-10-24 09:05:38 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 42.6%
[2024-10-24 09:06:09 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 09:06:09 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 09:06:09 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_143.pth saving......
[2024-10-24 09:06:10 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_143.pth saved !!!
[2024-10-24 09:06:10 mlla_tiny] (main.py 205): INFO Max accuracy: 42.63%
[2024-10-24 09:06:10 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 09:06:58 mlla_tiny] (main.py 296): INFO Train: [144/300][100/312]	eta 0:01:41 lr 0.000067	time 0.4724 (0.4759)	loss 11.6432 (11.8940)	grad_norm 5.7309 (inf)	mem 15420MB
[2024-10-24 09:07:45 mlla_tiny] (main.py 296): INFO Train: [144/300][200/312]	eta 0:00:53 lr 0.000067	time 0.4730 (0.4746)	loss 12.1197 (11.8473)	grad_norm 7.1256 (inf)	mem 15420MB
[2024-10-24 09:08:32 mlla_tiny] (main.py 296): INFO Train: [144/300][300/312]	eta 0:00:06 lr 0.000067	time 0.4743 (0.4741)	loss 12.6723 (11.8447)	grad_norm 5.0078 (nan)	mem 15420MB
[2024-10-24 09:08:38 mlla_tiny] (main.py 304): INFO EPOCH 144 training takes 0:02:27
[2024-10-24 09:09:09 mlla_tiny] (main.py 350): INFO  * Acc@1 42.490 Acc@5 67.430
[2024-10-24 09:09:09 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 42.5%
[2024-10-24 09:09:41 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 09:09:41 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 09:09:41 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_144.pth saving......
[2024-10-24 09:09:42 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_144.pth saved !!!
[2024-10-24 09:09:42 mlla_tiny] (main.py 205): INFO Max accuracy: 42.63%
[2024-10-24 09:09:42 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 09:10:29 mlla_tiny] (main.py 296): INFO Train: [145/300][100/312]	eta 0:01:41 lr 0.000067	time 0.4713 (0.4761)	loss 11.6662 (11.8275)	grad_norm 4.7433 (inf)	mem 15420MB
[2024-10-24 09:11:17 mlla_tiny] (main.py 296): INFO Train: [145/300][200/312]	eta 0:00:53 lr 0.000067	time 0.4741 (0.4744)	loss 12.1654 (11.8268)	grad_norm 6.5972 (inf)	mem 15420MB
[2024-10-24 09:12:04 mlla_tiny] (main.py 296): INFO Train: [145/300][300/312]	eta 0:00:06 lr 0.000066	time 0.4737 (0.4741)	loss 12.4284 (11.8467)	grad_norm 7.8617 (inf)	mem 15420MB
[2024-10-24 09:12:10 mlla_tiny] (main.py 304): INFO EPOCH 145 training takes 0:02:27
[2024-10-24 09:12:41 mlla_tiny] (main.py 350): INFO  * Acc@1 42.720 Acc@5 67.940
[2024-10-24 09:12:41 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 42.7%
[2024-10-24 09:13:12 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 09:13:12 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 09:13:12 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_145.pth saving......
[2024-10-24 09:13:13 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_145.pth saved !!!
[2024-10-24 09:13:13 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 09:13:14 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 09:13:14 mlla_tiny] (main.py 205): INFO Max accuracy: 42.72%
[2024-10-24 09:13:14 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 09:14:02 mlla_tiny] (main.py 296): INFO Train: [146/300][100/312]	eta 0:01:41 lr 0.000066	time 0.4715 (0.4759)	loss 10.7331 (11.8435)	grad_norm 10.6833 (inf)	mem 15420MB
[2024-10-24 09:14:49 mlla_tiny] (main.py 296): INFO Train: [146/300][200/312]	eta 0:00:53 lr 0.000066	time 0.4737 (0.4742)	loss 10.9094 (11.9080)	grad_norm 10.7514 (inf)	mem 15420MB
[2024-10-24 09:15:37 mlla_tiny] (main.py 296): INFO Train: [146/300][300/312]	eta 0:00:06 lr 0.000066	time 0.4729 (0.4739)	loss 12.3062 (11.9009)	grad_norm 6.5395 (inf)	mem 15420MB
[2024-10-24 09:15:42 mlla_tiny] (main.py 304): INFO EPOCH 146 training takes 0:02:27
[2024-10-24 09:16:14 mlla_tiny] (main.py 350): INFO  * Acc@1 43.030 Acc@5 67.560
[2024-10-24 09:16:14 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 43.0%
[2024-10-24 09:16:45 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 09:16:45 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 09:16:45 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_146.pth saving......
[2024-10-24 09:16:46 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_146.pth saved !!!
[2024-10-24 09:16:46 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 09:16:47 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 09:16:47 mlla_tiny] (main.py 205): INFO Max accuracy: 43.03%
[2024-10-24 09:16:47 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 09:17:34 mlla_tiny] (main.py 296): INFO Train: [147/300][100/312]	eta 0:01:41 lr 0.000066	time 0.4721 (0.4767)	loss 12.2823 (11.8743)	grad_norm 4.3583 (inf)	mem 15420MB
[2024-10-24 09:18:22 mlla_tiny] (main.py 296): INFO Train: [147/300][200/312]	eta 0:00:53 lr 0.000065	time 0.4744 (0.4747)	loss 12.3347 (11.8212)	grad_norm 5.6533 (inf)	mem 15420MB
[2024-10-24 09:19:09 mlla_tiny] (main.py 296): INFO Train: [147/300][300/312]	eta 0:00:06 lr 0.000065	time 0.4732 (0.4745)	loss 11.4115 (11.8057)	grad_norm 8.2447 (inf)	mem 15420MB
[2024-10-24 09:19:15 mlla_tiny] (main.py 304): INFO EPOCH 147 training takes 0:02:28
[2024-10-24 09:19:46 mlla_tiny] (main.py 350): INFO  * Acc@1 42.850 Acc@5 68.020
[2024-10-24 09:19:46 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 42.9%
[2024-10-24 09:20:18 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 09:20:18 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 09:20:18 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_147.pth saving......
[2024-10-24 09:20:19 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_147.pth saved !!!
[2024-10-24 09:20:19 mlla_tiny] (main.py 205): INFO Max accuracy: 43.03%
[2024-10-24 09:20:19 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 09:21:07 mlla_tiny] (main.py 296): INFO Train: [148/300][100/312]	eta 0:01:41 lr 0.000065	time 0.4728 (0.4765)	loss 12.0099 (11.8267)	grad_norm 7.3956 (inf)	mem 15420MB
[2024-10-24 09:21:54 mlla_tiny] (main.py 296): INFO Train: [148/300][200/312]	eta 0:00:53 lr 0.000065	time 0.4732 (0.4749)	loss 11.4556 (11.8392)	grad_norm 7.4037 (inf)	mem 15420MB
[2024-10-24 09:22:42 mlla_tiny] (main.py 296): INFO Train: [148/300][300/312]	eta 0:00:06 lr 0.000064	time 0.4744 (0.4745)	loss 10.9309 (11.8072)	grad_norm 7.0803 (inf)	mem 15420MB
[2024-10-24 09:22:47 mlla_tiny] (main.py 304): INFO EPOCH 148 training takes 0:02:28
[2024-10-24 09:23:19 mlla_tiny] (main.py 350): INFO  * Acc@1 42.570 Acc@5 67.450
[2024-10-24 09:23:19 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 42.6%
[2024-10-24 09:23:50 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 09:23:50 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 09:23:50 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_148.pth saving......
[2024-10-24 09:23:52 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_148.pth saved !!!
[2024-10-24 09:23:52 mlla_tiny] (main.py 205): INFO Max accuracy: 43.03%
[2024-10-24 09:23:52 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 09:24:39 mlla_tiny] (main.py 296): INFO Train: [149/300][100/312]	eta 0:01:41 lr 0.000064	time 0.4725 (0.4776)	loss 11.1406 (11.8290)	grad_norm 8.1121 (inf)	mem 15420MB
[2024-10-24 09:25:27 mlla_tiny] (main.py 296): INFO Train: [149/300][200/312]	eta 0:00:53 lr 0.000064	time 0.4732 (0.4751)	loss 10.5558 (11.8788)	grad_norm 7.6108 (inf)	mem 15420MB
[2024-10-24 09:26:14 mlla_tiny] (main.py 296): INFO Train: [149/300][300/312]	eta 0:00:06 lr 0.000064	time 0.4737 (0.4746)	loss 12.5536 (11.8616)	grad_norm 4.8093 (inf)	mem 15420MB
[2024-10-24 09:26:20 mlla_tiny] (main.py 304): INFO EPOCH 149 training takes 0:02:28
[2024-10-24 09:26:51 mlla_tiny] (main.py 350): INFO  * Acc@1 43.080 Acc@5 67.950
[2024-10-24 09:26:51 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 43.1%
[2024-10-24 09:27:22 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 09:27:22 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 09:27:22 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_149.pth saving......
[2024-10-24 09:27:23 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_149.pth saved !!!
[2024-10-24 09:27:23 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 09:27:24 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 09:27:24 mlla_tiny] (main.py 205): INFO Max accuracy: 43.08%
[2024-10-24 09:27:24 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 09:28:12 mlla_tiny] (main.py 296): INFO Train: [150/300][100/312]	eta 0:01:41 lr 0.000064	time 0.4716 (0.4760)	loss 11.4025 (11.8433)	grad_norm 6.2965 (inf)	mem 15420MB
[2024-10-24 09:28:59 mlla_tiny] (main.py 296): INFO Train: [150/300][200/312]	eta 0:00:53 lr 0.000063	time 0.4733 (0.4744)	loss 10.8321 (11.8233)	grad_norm 6.9308 (inf)	mem 15420MB
[2024-10-24 09:29:47 mlla_tiny] (main.py 296): INFO Train: [150/300][300/312]	eta 0:00:06 lr 0.000063	time 0.4732 (0.4741)	loss 12.3844 (11.7894)	grad_norm 4.5900 (inf)	mem 15420MB
[2024-10-24 09:29:52 mlla_tiny] (main.py 304): INFO EPOCH 150 training takes 0:02:27
[2024-10-24 09:30:24 mlla_tiny] (main.py 350): INFO  * Acc@1 43.030 Acc@5 68.090
[2024-10-24 09:30:24 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 43.0%
[2024-10-24 09:30:55 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 09:30:55 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 09:30:55 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_150.pth saving......
[2024-10-24 09:30:56 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_150.pth saved !!!
[2024-10-24 09:30:56 mlla_tiny] (main.py 205): INFO Max accuracy: 43.08%
[2024-10-24 09:30:56 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 09:31:43 mlla_tiny] (main.py 296): INFO Train: [151/300][100/312]	eta 0:01:41 lr 0.000063	time 0.4727 (0.4762)	loss 11.1379 (11.7310)	grad_norm 6.1209 (inf)	mem 15420MB
[2024-10-24 09:32:31 mlla_tiny] (main.py 296): INFO Train: [151/300][200/312]	eta 0:00:53 lr 0.000063	time 0.4742 (0.4747)	loss 11.1842 (11.8006)	grad_norm 8.0039 (inf)	mem 15420MB
[2024-10-24 09:33:18 mlla_tiny] (main.py 296): INFO Train: [151/300][300/312]	eta 0:00:06 lr 0.000063	time 0.4735 (0.4743)	loss 12.0531 (11.7892)	grad_norm 9.6418 (inf)	mem 15420MB
[2024-10-24 09:33:24 mlla_tiny] (main.py 304): INFO EPOCH 151 training takes 0:02:28
[2024-10-24 09:33:56 mlla_tiny] (main.py 350): INFO  * Acc@1 43.210 Acc@5 68.140
[2024-10-24 09:33:56 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 43.2%
[2024-10-24 09:34:27 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 09:34:27 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 09:34:27 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_151.pth saving......
[2024-10-24 09:34:28 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_151.pth saved !!!
[2024-10-24 09:34:28 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 09:34:29 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 09:34:29 mlla_tiny] (main.py 205): INFO Max accuracy: 43.21%
[2024-10-24 09:34:29 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 09:35:17 mlla_tiny] (main.py 296): INFO Train: [152/300][100/312]	eta 0:01:41 lr 0.000062	time 0.4715 (0.4764)	loss 12.0703 (11.7794)	grad_norm 6.0241 (inf)	mem 15420MB
[2024-10-24 09:36:04 mlla_tiny] (main.py 296): INFO Train: [152/300][200/312]	eta 0:00:53 lr 0.000062	time 0.4733 (0.4746)	loss 12.1726 (11.8019)	grad_norm 4.6331 (inf)	mem 15420MB
[2024-10-24 09:36:51 mlla_tiny] (main.py 296): INFO Train: [152/300][300/312]	eta 0:00:06 lr 0.000062	time 0.4744 (0.4742)	loss 11.6424 (11.8081)	grad_norm 6.1530 (inf)	mem 15420MB
[2024-10-24 09:36:57 mlla_tiny] (main.py 304): INFO EPOCH 152 training takes 0:02:27
[2024-10-24 09:37:29 mlla_tiny] (main.py 350): INFO  * Acc@1 42.740 Acc@5 67.900
[2024-10-24 09:37:29 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 42.7%
[2024-10-24 09:38:00 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 09:38:00 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 09:38:00 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_152.pth saving......
[2024-10-24 09:38:01 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_152.pth saved !!!
[2024-10-24 09:38:01 mlla_tiny] (main.py 205): INFO Max accuracy: 43.21%
[2024-10-24 09:38:01 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 09:38:49 mlla_tiny] (main.py 296): INFO Train: [153/300][100/312]	eta 0:01:41 lr 0.000062	time 0.4740 (0.4769)	loss 12.2484 (11.7651)	grad_norm 5.1444 (inf)	mem 15420MB
[2024-10-24 09:39:36 mlla_tiny] (main.py 296): INFO Train: [153/300][200/312]	eta 0:00:53 lr 0.000061	time 0.4732 (0.4752)	loss 12.0259 (11.8251)	grad_norm 5.6005 (inf)	mem 15420MB
[2024-10-24 09:40:24 mlla_tiny] (main.py 296): INFO Train: [153/300][300/312]	eta 0:00:06 lr 0.000061	time 0.4736 (0.4747)	loss 10.7489 (11.8113)	grad_norm 14.5548 (inf)	mem 15420MB
[2024-10-24 09:40:29 mlla_tiny] (main.py 304): INFO EPOCH 153 training takes 0:02:28
[2024-10-24 09:41:01 mlla_tiny] (main.py 350): INFO  * Acc@1 43.530 Acc@5 68.430
[2024-10-24 09:41:01 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 43.5%
[2024-10-24 09:41:32 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 09:41:32 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 09:41:32 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_153.pth saving......
[2024-10-24 09:41:33 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_153.pth saved !!!
[2024-10-24 09:41:33 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 09:41:34 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 09:41:34 mlla_tiny] (main.py 205): INFO Max accuracy: 43.53%
[2024-10-24 09:41:34 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 09:42:21 mlla_tiny] (main.py 296): INFO Train: [154/300][100/312]	eta 0:01:41 lr 0.000061	time 0.4730 (0.4763)	loss 10.9611 (11.7123)	grad_norm 9.8621 (inf)	mem 15420MB
[2024-10-24 09:43:09 mlla_tiny] (main.py 296): INFO Train: [154/300][200/312]	eta 0:00:53 lr 0.000061	time 0.4740 (0.4747)	loss 11.7652 (11.7442)	grad_norm 5.3266 (inf)	mem 15420MB
[2024-10-24 09:43:56 mlla_tiny] (main.py 296): INFO Train: [154/300][300/312]	eta 0:00:06 lr 0.000061	time 0.4734 (0.4745)	loss 11.1372 (11.7500)	grad_norm 6.4417 (inf)	mem 15420MB
[2024-10-24 09:44:02 mlla_tiny] (main.py 304): INFO EPOCH 154 training takes 0:02:28
[2024-10-24 09:44:33 mlla_tiny] (main.py 350): INFO  * Acc@1 42.760 Acc@5 67.810
[2024-10-24 09:44:33 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 42.8%
[2024-10-24 09:45:05 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 09:45:05 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 09:45:05 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_154.pth saving......
[2024-10-24 09:45:06 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_154.pth saved !!!
[2024-10-24 09:45:06 mlla_tiny] (main.py 205): INFO Max accuracy: 43.53%
[2024-10-24 09:45:06 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 09:45:53 mlla_tiny] (main.py 296): INFO Train: [155/300][100/312]	eta 0:01:41 lr 0.000060	time 0.4728 (0.4770)	loss 10.4431 (11.7798)	grad_norm 9.5732 (inf)	mem 15420MB
[2024-10-24 09:46:41 mlla_tiny] (main.py 296): INFO Train: [155/300][200/312]	eta 0:00:53 lr 0.000060	time 0.4734 (0.4750)	loss 12.1658 (11.7946)	grad_norm 6.6849 (inf)	mem 15420MB
[2024-10-24 09:47:28 mlla_tiny] (main.py 296): INFO Train: [155/300][300/312]	eta 0:00:06 lr 0.000060	time 0.4734 (0.4745)	loss 12.1550 (11.7989)	grad_norm 6.0896 (inf)	mem 15420MB
[2024-10-24 09:47:34 mlla_tiny] (main.py 304): INFO EPOCH 155 training takes 0:02:28
[2024-10-24 09:48:05 mlla_tiny] (main.py 350): INFO  * Acc@1 43.120 Acc@5 68.220
[2024-10-24 09:48:05 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 43.1%
[2024-10-24 09:48:36 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 09:48:36 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 09:48:36 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_155.pth saving......
[2024-10-24 09:48:37 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_155.pth saved !!!
[2024-10-24 09:48:37 mlla_tiny] (main.py 205): INFO Max accuracy: 43.53%
[2024-10-24 09:48:37 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 09:49:25 mlla_tiny] (main.py 296): INFO Train: [156/300][100/312]	eta 0:01:41 lr 0.000060	time 0.4730 (0.4772)	loss 11.6705 (11.6769)	grad_norm 5.4247 (inf)	mem 15420MB
[2024-10-24 09:50:12 mlla_tiny] (main.py 296): INFO Train: [156/300][200/312]	eta 0:00:53 lr 0.000059	time 0.4739 (0.4752)	loss 11.3900 (11.7424)	grad_norm 5.7601 (inf)	mem 15420MB
[2024-10-24 09:50:59 mlla_tiny] (main.py 296): INFO Train: [156/300][300/312]	eta 0:00:06 lr 0.000059	time 0.4744 (0.4747)	loss 12.2138 (11.7625)	grad_norm 5.2900 (inf)	mem 15420MB
[2024-10-24 09:51:05 mlla_tiny] (main.py 304): INFO EPOCH 156 training takes 0:02:28
[2024-10-24 09:51:36 mlla_tiny] (main.py 350): INFO  * Acc@1 43.600 Acc@5 68.480
[2024-10-24 09:51:36 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 43.6%
[2024-10-24 09:52:07 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 09:52:07 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 09:52:07 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_156.pth saving......
[2024-10-24 09:52:08 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_156.pth saved !!!
[2024-10-24 09:52:08 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 09:52:09 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 09:52:09 mlla_tiny] (main.py 205): INFO Max accuracy: 43.60%
[2024-10-24 09:52:09 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 09:52:57 mlla_tiny] (main.py 296): INFO Train: [157/300][100/312]	eta 0:01:41 lr 0.000059	time 0.4726 (0.4766)	loss 12.2974 (11.7528)	grad_norm 5.3875 (inf)	mem 15420MB
[2024-10-24 09:53:44 mlla_tiny] (main.py 296): INFO Train: [157/300][200/312]	eta 0:00:53 lr 0.000059	time 0.4736 (0.4749)	loss 10.7953 (11.7706)	grad_norm 5.4703 (inf)	mem 15420MB
[2024-10-24 09:54:32 mlla_tiny] (main.py 296): INFO Train: [157/300][300/312]	eta 0:00:06 lr 0.000059	time 0.4737 (0.4747)	loss 12.2647 (11.7869)	grad_norm 5.7303 (inf)	mem 15420MB
[2024-10-24 09:54:37 mlla_tiny] (main.py 304): INFO EPOCH 157 training takes 0:02:28
[2024-10-24 09:55:09 mlla_tiny] (main.py 350): INFO  * Acc@1 43.690 Acc@5 68.540
[2024-10-24 09:55:09 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 43.7%
[2024-10-24 09:55:41 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 09:55:41 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 09:55:41 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_157.pth saving......
[2024-10-24 09:55:42 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_157.pth saved !!!
[2024-10-24 09:55:42 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 09:55:43 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 09:55:43 mlla_tiny] (main.py 205): INFO Max accuracy: 43.69%
[2024-10-24 09:55:43 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 09:56:30 mlla_tiny] (main.py 296): INFO Train: [158/300][100/312]	eta 0:01:41 lr 0.000058	time 0.4714 (0.4764)	loss 11.4522 (11.8466)	grad_norm 7.4500 (inf)	mem 15420MB
[2024-10-24 09:57:18 mlla_tiny] (main.py 296): INFO Train: [158/300][200/312]	eta 0:00:53 lr 0.000058	time 0.4738 (0.4747)	loss 12.0364 (11.8139)	grad_norm 4.9889 (inf)	mem 15420MB
[2024-10-24 09:58:05 mlla_tiny] (main.py 296): INFO Train: [158/300][300/312]	eta 0:00:06 lr 0.000058	time 0.5107 (0.4746)	loss 11.7142 (11.8026)	grad_norm 7.1899 (inf)	mem 15420MB
[2024-10-24 09:58:11 mlla_tiny] (main.py 304): INFO EPOCH 158 training takes 0:02:28
[2024-10-24 09:58:43 mlla_tiny] (main.py 350): INFO  * Acc@1 43.700 Acc@5 68.690
[2024-10-24 09:58:43 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 43.7%
[2024-10-24 09:59:14 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 09:59:14 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 09:59:14 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_158.pth saving......
[2024-10-24 09:59:15 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_158.pth saved !!!
[2024-10-24 09:59:15 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 09:59:16 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 09:59:16 mlla_tiny] (main.py 205): INFO Max accuracy: 43.70%
[2024-10-24 09:59:16 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 10:00:03 mlla_tiny] (main.py 296): INFO Train: [159/300][100/312]	eta 0:01:41 lr 0.000058	time 0.4722 (0.4768)	loss 10.6013 (11.6274)	grad_norm 9.1141 (inf)	mem 15420MB
[2024-10-24 10:00:51 mlla_tiny] (main.py 296): INFO Train: [159/300][200/312]	eta 0:00:53 lr 0.000058	time 0.4741 (0.4748)	loss 12.3771 (11.7315)	grad_norm 4.9123 (inf)	mem 15420MB
[2024-10-24 10:01:38 mlla_tiny] (main.py 296): INFO Train: [159/300][300/312]	eta 0:00:06 lr 0.000057	time 0.4738 (0.4744)	loss 12.1236 (11.7356)	grad_norm 5.1267 (inf)	mem 15420MB
[2024-10-24 10:01:44 mlla_tiny] (main.py 304): INFO EPOCH 159 training takes 0:02:28
[2024-10-24 10:02:15 mlla_tiny] (main.py 350): INFO  * Acc@1 43.840 Acc@5 68.730
[2024-10-24 10:02:15 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 43.8%
[2024-10-24 10:02:47 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 10:02:47 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 10:02:47 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_159.pth saving......
[2024-10-24 10:02:48 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_159.pth saved !!!
[2024-10-24 10:02:48 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 10:02:49 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 10:02:49 mlla_tiny] (main.py 205): INFO Max accuracy: 43.84%
[2024-10-24 10:02:49 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 10:03:37 mlla_tiny] (main.py 296): INFO Train: [160/300][100/312]	eta 0:01:41 lr 0.000057	time 0.4724 (0.4762)	loss 11.6089 (11.8514)	grad_norm 5.8387 (inf)	mem 15420MB
[2024-10-24 10:04:24 mlla_tiny] (main.py 296): INFO Train: [160/300][200/312]	eta 0:00:53 lr 0.000057	time 0.4730 (0.4744)	loss 12.6433 (11.7861)	grad_norm 5.3086 (inf)	mem 15420MB
[2024-10-24 10:05:11 mlla_tiny] (main.py 296): INFO Train: [160/300][300/312]	eta 0:00:06 lr 0.000057	time 0.4743 (0.4740)	loss 12.5819 (11.7687)	grad_norm 5.2222 (inf)	mem 15420MB
[2024-10-24 10:05:17 mlla_tiny] (main.py 304): INFO EPOCH 160 training takes 0:02:27
[2024-10-24 10:05:48 mlla_tiny] (main.py 350): INFO  * Acc@1 43.790 Acc@5 68.350
[2024-10-24 10:05:48 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 43.8%
[2024-10-24 10:06:20 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 10:06:20 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 10:06:20 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_160.pth saving......
[2024-10-24 10:06:21 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_160.pth saved !!!
[2024-10-24 10:06:21 mlla_tiny] (main.py 205): INFO Max accuracy: 43.84%
[2024-10-24 10:06:21 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 10:07:08 mlla_tiny] (main.py 296): INFO Train: [161/300][100/312]	eta 0:01:41 lr 0.000056	time 0.4751 (0.4766)	loss 12.2010 (11.7308)	grad_norm 4.3174 (inf)	mem 15420MB
[2024-10-24 10:07:56 mlla_tiny] (main.py 296): INFO Train: [161/300][200/312]	eta 0:00:53 lr 0.000056	time 0.4736 (0.4748)	loss 11.1935 (11.6998)	grad_norm 7.9353 (inf)	mem 15420MB
[2024-10-24 10:08:43 mlla_tiny] (main.py 296): INFO Train: [161/300][300/312]	eta 0:00:06 lr 0.000056	time 0.4750 (0.4745)	loss 10.8923 (11.7538)	grad_norm 10.3821 (inf)	mem 15420MB
[2024-10-24 10:08:49 mlla_tiny] (main.py 304): INFO EPOCH 161 training takes 0:02:28
[2024-10-24 10:09:20 mlla_tiny] (main.py 350): INFO  * Acc@1 43.360 Acc@5 68.240
[2024-10-24 10:09:20 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 43.4%
[2024-10-24 10:09:52 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 10:09:52 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 10:09:52 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_161.pth saving......
[2024-10-24 10:09:53 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_161.pth saved !!!
[2024-10-24 10:09:53 mlla_tiny] (main.py 205): INFO Max accuracy: 43.84%
[2024-10-24 10:09:53 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 10:10:41 mlla_tiny] (main.py 296): INFO Train: [162/300][100/312]	eta 0:01:41 lr 0.000056	time 0.4721 (0.4763)	loss 10.8563 (11.6857)	grad_norm 5.8837 (inf)	mem 15420MB
[2024-10-24 10:11:28 mlla_tiny] (main.py 296): INFO Train: [162/300][200/312]	eta 0:00:53 lr 0.000056	time 0.4737 (0.4745)	loss 11.1843 (11.7318)	grad_norm 8.4965 (inf)	mem 15420MB
[2024-10-24 10:12:15 mlla_tiny] (main.py 296): INFO Train: [162/300][300/312]	eta 0:00:06 lr 0.000055	time 0.4735 (0.4743)	loss 10.5678 (11.7506)	grad_norm 6.7333 (inf)	mem 15420MB
[2024-10-24 10:12:21 mlla_tiny] (main.py 304): INFO EPOCH 162 training takes 0:02:27
[2024-10-24 10:12:52 mlla_tiny] (main.py 350): INFO  * Acc@1 44.020 Acc@5 68.560
[2024-10-24 10:12:52 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.0%
[2024-10-24 10:13:24 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 10:13:24 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 10:13:24 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_162.pth saving......
[2024-10-24 10:13:25 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_162.pth saved !!!
[2024-10-24 10:13:25 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 10:13:26 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 10:13:26 mlla_tiny] (main.py 205): INFO Max accuracy: 44.02%
[2024-10-24 10:13:26 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 10:14:13 mlla_tiny] (main.py 296): INFO Train: [163/300][100/312]	eta 0:01:41 lr 0.000055	time 0.4720 (0.4763)	loss 12.2329 (11.8300)	grad_norm 4.8610 (inf)	mem 15420MB
[2024-10-24 10:15:00 mlla_tiny] (main.py 296): INFO Train: [163/300][200/312]	eta 0:00:53 lr 0.000055	time 0.4744 (0.4746)	loss 11.2278 (11.7503)	grad_norm 7.6095 (inf)	mem 15420MB
[2024-10-24 10:15:48 mlla_tiny] (main.py 296): INFO Train: [163/300][300/312]	eta 0:00:06 lr 0.000055	time 0.4733 (0.4743)	loss 12.2872 (11.7348)	grad_norm 6.0702 (inf)	mem 15420MB
[2024-10-24 10:15:54 mlla_tiny] (main.py 304): INFO EPOCH 163 training takes 0:02:28
[2024-10-24 10:16:25 mlla_tiny] (main.py 350): INFO  * Acc@1 43.410 Acc@5 68.370
[2024-10-24 10:16:25 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 43.4%
[2024-10-24 10:16:56 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 10:16:56 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 10:16:57 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_163.pth saving......
[2024-10-24 10:16:58 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_163.pth saved !!!
[2024-10-24 10:16:58 mlla_tiny] (main.py 205): INFO Max accuracy: 44.02%
[2024-10-24 10:16:58 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 10:17:46 mlla_tiny] (main.py 296): INFO Train: [164/300][100/312]	eta 0:01:41 lr 0.000055	time 0.4728 (0.4776)	loss 11.0160 (11.6640)	grad_norm 7.6994 (inf)	mem 15420MB
[2024-10-24 10:18:33 mlla_tiny] (main.py 296): INFO Train: [164/300][200/312]	eta 0:00:53 lr 0.000054	time 0.4736 (0.4752)	loss 12.3573 (11.6611)	grad_norm 7.9629 (inf)	mem 15420MB
[2024-10-24 10:19:20 mlla_tiny] (main.py 296): INFO Train: [164/300][300/312]	eta 0:00:06 lr 0.000054	time 0.4745 (0.4747)	loss 11.8694 (11.7170)	grad_norm 6.7249 (inf)	mem 15420MB
[2024-10-24 10:19:26 mlla_tiny] (main.py 304): INFO EPOCH 164 training takes 0:02:28
[2024-10-24 10:19:57 mlla_tiny] (main.py 350): INFO  * Acc@1 43.800 Acc@5 68.560
[2024-10-24 10:19:57 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 43.8%
[2024-10-24 10:20:29 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 10:20:29 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 10:20:29 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_164.pth saving......
[2024-10-24 10:20:30 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_164.pth saved !!!
[2024-10-24 10:20:30 mlla_tiny] (main.py 205): INFO Max accuracy: 44.02%
[2024-10-24 10:20:30 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 10:21:17 mlla_tiny] (main.py 296): INFO Train: [165/300][100/312]	eta 0:01:41 lr 0.000054	time 0.4717 (0.4763)	loss 11.5796 (11.7233)	grad_norm 6.3097 (inf)	mem 15420MB
[2024-10-24 10:22:04 mlla_tiny] (main.py 296): INFO Train: [165/300][200/312]	eta 0:00:53 lr 0.000054	time 0.4737 (0.4746)	loss 11.6770 (11.7034)	grad_norm 6.8086 (inf)	mem 15420MB
[2024-10-24 10:22:52 mlla_tiny] (main.py 296): INFO Train: [165/300][300/312]	eta 0:00:06 lr 0.000053	time 0.4737 (0.4743)	loss 11.7737 (11.6900)	grad_norm 6.1392 (inf)	mem 15420MB
[2024-10-24 10:22:58 mlla_tiny] (main.py 304): INFO EPOCH 165 training takes 0:02:27
[2024-10-24 10:23:29 mlla_tiny] (main.py 350): INFO  * Acc@1 44.390 Acc@5 68.960
[2024-10-24 10:23:29 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.4%
[2024-10-24 10:24:00 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 10:24:00 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 10:24:00 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_165.pth saving......
[2024-10-24 10:24:01 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_165.pth saved !!!
[2024-10-24 10:24:01 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 10:24:02 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 10:24:02 mlla_tiny] (main.py 205): INFO Max accuracy: 44.39%
[2024-10-24 10:24:02 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 10:24:49 mlla_tiny] (main.py 296): INFO Train: [166/300][100/312]	eta 0:01:41 lr 0.000053	time 0.4726 (0.4763)	loss 12.2056 (11.6905)	grad_norm 5.4907 (inf)	mem 15420MB
[2024-10-24 10:25:37 mlla_tiny] (main.py 296): INFO Train: [166/300][200/312]	eta 0:00:53 lr 0.000053	time 0.4719 (0.4746)	loss 12.1116 (11.7771)	grad_norm 6.0028 (inf)	mem 15420MB
[2024-10-24 10:26:24 mlla_tiny] (main.py 296): INFO Train: [166/300][300/312]	eta 0:00:06 lr 0.000053	time 0.4730 (0.4741)	loss 12.0449 (11.7750)	grad_norm 4.3498 (inf)	mem 15420MB
[2024-10-24 10:26:30 mlla_tiny] (main.py 304): INFO EPOCH 166 training takes 0:02:27
[2024-10-24 10:27:01 mlla_tiny] (main.py 350): INFO  * Acc@1 43.040 Acc@5 68.220
[2024-10-24 10:27:01 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 43.0%
[2024-10-24 10:27:33 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 10:27:33 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 10:27:33 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_166.pth saving......
[2024-10-24 10:27:34 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_166.pth saved !!!
[2024-10-24 10:27:34 mlla_tiny] (main.py 205): INFO Max accuracy: 44.39%
[2024-10-24 10:27:34 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 10:28:22 mlla_tiny] (main.py 296): INFO Train: [167/300][100/312]	eta 0:01:41 lr 0.000053	time 0.4731 (0.4762)	loss 12.6515 (11.6573)	grad_norm 4.6958 (inf)	mem 15420MB
[2024-10-24 10:29:09 mlla_tiny] (main.py 296): INFO Train: [167/300][200/312]	eta 0:00:53 lr 0.000052	time 0.4735 (0.4748)	loss 11.6884 (11.7185)	grad_norm 7.9312 (inf)	mem 15420MB
[2024-10-24 10:29:56 mlla_tiny] (main.py 296): INFO Train: [167/300][300/312]	eta 0:00:06 lr 0.000052	time 0.4734 (0.4745)	loss 12.3444 (11.6839)	grad_norm 4.3247 (inf)	mem 15420MB
[2024-10-24 10:30:02 mlla_tiny] (main.py 304): INFO EPOCH 167 training takes 0:02:28
[2024-10-24 10:30:33 mlla_tiny] (main.py 350): INFO  * Acc@1 44.220 Acc@5 69.010
[2024-10-24 10:30:33 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.2%
[2024-10-24 10:31:05 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 10:31:05 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 10:31:05 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_167.pth saving......
[2024-10-24 10:31:06 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_167.pth saved !!!
[2024-10-24 10:31:06 mlla_tiny] (main.py 205): INFO Max accuracy: 44.39%
[2024-10-24 10:31:06 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 10:31:53 mlla_tiny] (main.py 296): INFO Train: [168/300][100/312]	eta 0:01:41 lr 0.000052	time 0.4719 (0.4766)	loss 11.5391 (11.8285)	grad_norm 5.7583 (inf)	mem 15420MB
[2024-10-24 10:32:41 mlla_tiny] (main.py 296): INFO Train: [168/300][200/312]	eta 0:00:53 lr 0.000052	time 0.4725 (0.4745)	loss 12.3920 (11.7535)	grad_norm 6.4650 (inf)	mem 15420MB
[2024-10-24 10:33:28 mlla_tiny] (main.py 296): INFO Train: [168/300][300/312]	eta 0:00:06 lr 0.000052	time 0.4730 (0.4742)	loss 12.3398 (11.7306)	grad_norm 4.7123 (inf)	mem 15420MB
[2024-10-24 10:33:34 mlla_tiny] (main.py 304): INFO EPOCH 168 training takes 0:02:27
[2024-10-24 10:34:06 mlla_tiny] (main.py 350): INFO  * Acc@1 44.290 Acc@5 68.470
[2024-10-24 10:34:06 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.3%
[2024-10-24 10:34:37 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 10:34:37 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 10:34:37 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_168.pth saving......
[2024-10-24 10:34:38 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_168.pth saved !!!
[2024-10-24 10:34:38 mlla_tiny] (main.py 205): INFO Max accuracy: 44.39%
[2024-10-24 10:34:38 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 10:35:26 mlla_tiny] (main.py 296): INFO Train: [169/300][100/312]	eta 0:01:41 lr 0.000051	time 0.4715 (0.4760)	loss 12.1777 (11.5029)	grad_norm 4.7929 (inf)	mem 15420MB
[2024-10-24 10:36:13 mlla_tiny] (main.py 296): INFO Train: [169/300][200/312]	eta 0:00:53 lr 0.000051	time 0.4741 (0.4743)	loss 11.4240 (11.5936)	grad_norm 6.3251 (inf)	mem 15420MB
[2024-10-24 10:37:00 mlla_tiny] (main.py 296): INFO Train: [169/300][300/312]	eta 0:00:06 lr 0.000051	time 0.4724 (0.4739)	loss 11.5461 (11.6526)	grad_norm 5.7521 (inf)	mem 15420MB
[2024-10-24 10:37:06 mlla_tiny] (main.py 304): INFO EPOCH 169 training takes 0:02:27
[2024-10-24 10:37:38 mlla_tiny] (main.py 350): INFO  * Acc@1 44.090 Acc@5 68.850
[2024-10-24 10:37:38 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.1%
[2024-10-24 10:38:09 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 10:38:09 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 10:38:09 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_169.pth saving......
[2024-10-24 10:38:10 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_169.pth saved !!!
[2024-10-24 10:38:10 mlla_tiny] (main.py 205): INFO Max accuracy: 44.39%
[2024-10-24 10:38:10 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 10:38:57 mlla_tiny] (main.py 296): INFO Train: [170/300][100/312]	eta 0:01:41 lr 0.000051	time 0.4720 (0.4765)	loss 11.2156 (11.6787)	grad_norm 5.4618 (inf)	mem 15420MB
[2024-10-24 10:39:45 mlla_tiny] (main.py 296): INFO Train: [170/300][200/312]	eta 0:00:53 lr 0.000050	time 0.4739 (0.4746)	loss 12.1932 (11.7180)	grad_norm 4.9629 (inf)	mem 15420MB
[2024-10-24 10:40:32 mlla_tiny] (main.py 296): INFO Train: [170/300][300/312]	eta 0:00:06 lr 0.000050	time 0.4736 (0.4742)	loss 10.8589 (11.6745)	grad_norm 6.0554 (inf)	mem 15420MB
[2024-10-24 10:40:38 mlla_tiny] (main.py 304): INFO EPOCH 170 training takes 0:02:27
[2024-10-24 10:41:09 mlla_tiny] (main.py 350): INFO  * Acc@1 44.070 Acc@5 68.530
[2024-10-24 10:41:09 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.1%
[2024-10-24 10:41:40 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 10:41:40 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 10:41:40 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_170.pth saving......
[2024-10-24 10:41:41 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_170.pth saved !!!
[2024-10-24 10:41:41 mlla_tiny] (main.py 205): INFO Max accuracy: 44.39%
[2024-10-24 10:41:41 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 10:42:29 mlla_tiny] (main.py 296): INFO Train: [171/300][100/312]	eta 0:01:41 lr 0.000050	time 0.4709 (0.4767)	loss 12.2721 (11.6592)	grad_norm 4.8494 (inf)	mem 15420MB
[2024-10-24 10:43:16 mlla_tiny] (main.py 296): INFO Train: [171/300][200/312]	eta 0:00:53 lr 0.000050	time 0.4723 (0.4747)	loss 11.3561 (11.7105)	grad_norm 9.1272 (inf)	mem 15420MB
[2024-10-24 10:44:04 mlla_tiny] (main.py 296): INFO Train: [171/300][300/312]	eta 0:00:06 lr 0.000050	time 0.4727 (0.4742)	loss 10.5032 (11.6902)	grad_norm 16.9811 (inf)	mem 15420MB
[2024-10-24 10:44:09 mlla_tiny] (main.py 304): INFO EPOCH 171 training takes 0:02:27
[2024-10-24 10:44:41 mlla_tiny] (main.py 350): INFO  * Acc@1 44.320 Acc@5 68.880
[2024-10-24 10:44:41 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.3%
[2024-10-24 10:45:12 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 10:45:12 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 10:45:12 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_171.pth saving......
[2024-10-24 10:45:13 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_171.pth saved !!!
[2024-10-24 10:45:13 mlla_tiny] (main.py 205): INFO Max accuracy: 44.39%
[2024-10-24 10:45:13 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 10:46:01 mlla_tiny] (main.py 296): INFO Train: [172/300][100/312]	eta 0:01:41 lr 0.000049	time 0.5093 (0.4767)	loss 10.6902 (11.7731)	grad_norm 6.8384 (inf)	mem 15420MB
[2024-10-24 10:46:48 mlla_tiny] (main.py 296): INFO Train: [172/300][200/312]	eta 0:00:53 lr 0.000049	time 0.4727 (0.4749)	loss 11.6675 (11.7439)	grad_norm 5.5549 (inf)	mem 15420MB
[2024-10-24 10:47:36 mlla_tiny] (main.py 296): INFO Train: [172/300][300/312]	eta 0:00:06 lr 0.000049	time 0.4734 (0.4744)	loss 12.0855 (11.7292)	grad_norm 7.3312 (inf)	mem 15420MB
[2024-10-24 10:47:41 mlla_tiny] (main.py 304): INFO EPOCH 172 training takes 0:02:28
[2024-10-24 10:48:13 mlla_tiny] (main.py 350): INFO  * Acc@1 44.580 Acc@5 68.990
[2024-10-24 10:48:13 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.6%
[2024-10-24 10:48:44 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 10:48:44 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 10:48:45 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_172.pth saving......
[2024-10-24 10:48:46 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_172.pth saved !!!
[2024-10-24 10:48:46 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 10:48:47 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 10:48:47 mlla_tiny] (main.py 205): INFO Max accuracy: 44.58%
[2024-10-24 10:48:47 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 10:49:34 mlla_tiny] (main.py 296): INFO Train: [173/300][100/312]	eta 0:01:41 lr 0.000049	time 0.4724 (0.4766)	loss 11.5101 (11.6239)	grad_norm 7.3623 (inf)	mem 15420MB
[2024-10-24 10:50:21 mlla_tiny] (main.py 296): INFO Train: [173/300][200/312]	eta 0:00:53 lr 0.000049	time 0.4733 (0.4747)	loss 11.2720 (11.6949)	grad_norm 8.5174 (inf)	mem 15420MB
[2024-10-24 10:51:09 mlla_tiny] (main.py 296): INFO Train: [173/300][300/312]	eta 0:00:06 lr 0.000048	time 0.4737 (0.4743)	loss 12.1669 (11.6520)	grad_norm 5.5813 (inf)	mem 15420MB
[2024-10-24 10:51:15 mlla_tiny] (main.py 304): INFO EPOCH 173 training takes 0:02:28
[2024-10-24 10:51:45 mlla_tiny] (main.py 350): INFO  * Acc@1 44.630 Acc@5 68.740
[2024-10-24 10:51:45 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.6%
[2024-10-24 10:52:17 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 10:52:17 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 10:52:17 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_173.pth saving......
[2024-10-24 10:52:18 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_173.pth saved !!!
[2024-10-24 10:52:18 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 10:52:19 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 10:52:19 mlla_tiny] (main.py 205): INFO Max accuracy: 44.63%
[2024-10-24 10:52:19 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 10:53:07 mlla_tiny] (main.py 296): INFO Train: [174/300][100/312]	eta 0:01:41 lr 0.000048	time 0.4723 (0.4766)	loss 11.2105 (11.5659)	grad_norm 8.6708 (inf)	mem 15420MB
[2024-10-24 10:53:54 mlla_tiny] (main.py 296): INFO Train: [174/300][200/312]	eta 0:00:53 lr 0.000048	time 0.4737 (0.4747)	loss 11.9775 (11.5833)	grad_norm 4.8302 (inf)	mem 15420MB
[2024-10-24 10:54:42 mlla_tiny] (main.py 296): INFO Train: [174/300][300/312]	eta 0:00:06 lr 0.000048	time 0.4733 (0.4744)	loss 12.1099 (11.6210)	grad_norm 4.7109 (inf)	mem 15420MB
[2024-10-24 10:54:47 mlla_tiny] (main.py 304): INFO EPOCH 174 training takes 0:02:28
[2024-10-24 10:55:19 mlla_tiny] (main.py 350): INFO  * Acc@1 44.290 Acc@5 69.110
[2024-10-24 10:55:19 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.3%
[2024-10-24 10:55:50 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 10:55:50 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 10:55:50 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_174.pth saving......
[2024-10-24 10:55:51 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_174.pth saved !!!
[2024-10-24 10:55:51 mlla_tiny] (main.py 205): INFO Max accuracy: 44.63%
[2024-10-24 10:55:51 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 10:56:38 mlla_tiny] (main.py 296): INFO Train: [175/300][100/312]	eta 0:01:41 lr 0.000048	time 0.4714 (0.4762)	loss 11.9322 (11.6304)	grad_norm 10.6829 (inf)	mem 15420MB
[2024-10-24 10:57:26 mlla_tiny] (main.py 296): INFO Train: [175/300][200/312]	eta 0:00:53 lr 0.000047	time 0.4736 (0.4747)	loss 11.9382 (11.6145)	grad_norm 10.1184 (inf)	mem 15420MB
[2024-10-24 10:58:13 mlla_tiny] (main.py 296): INFO Train: [175/300][300/312]	eta 0:00:06 lr 0.000047	time 0.4743 (0.4744)	loss 12.4845 (11.6129)	grad_norm 5.1456 (inf)	mem 15420MB
[2024-10-24 10:58:19 mlla_tiny] (main.py 304): INFO EPOCH 175 training takes 0:02:28
[2024-10-24 10:58:50 mlla_tiny] (main.py 350): INFO  * Acc@1 44.370 Acc@5 69.110
[2024-10-24 10:58:50 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.4%
[2024-10-24 10:59:21 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 10:59:21 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 10:59:21 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_175.pth saving......
[2024-10-24 10:59:22 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_175.pth saved !!!
[2024-10-24 10:59:22 mlla_tiny] (main.py 205): INFO Max accuracy: 44.63%
[2024-10-24 10:59:22 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 11:00:10 mlla_tiny] (main.py 296): INFO Train: [176/300][100/312]	eta 0:01:41 lr 0.000047	time 0.4723 (0.4766)	loss 12.4208 (11.6007)	grad_norm 6.8156 (nan)	mem 15420MB
[2024-10-24 11:00:57 mlla_tiny] (main.py 296): INFO Train: [176/300][200/312]	eta 0:00:53 lr 0.000047	time 0.4733 (0.4748)	loss 11.9445 (11.6196)	grad_norm 8.0284 (nan)	mem 15420MB
[2024-10-24 11:01:45 mlla_tiny] (main.py 296): INFO Train: [176/300][300/312]	eta 0:00:06 lr 0.000047	time 0.4734 (0.4743)	loss 12.0143 (11.6255)	grad_norm 4.2813 (nan)	mem 15420MB
[2024-10-24 11:01:50 mlla_tiny] (main.py 304): INFO EPOCH 176 training takes 0:02:27
[2024-10-24 11:02:22 mlla_tiny] (main.py 350): INFO  * Acc@1 44.410 Acc@5 69.080
[2024-10-24 11:02:22 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.4%
[2024-10-24 11:02:53 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 11:02:53 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 11:02:53 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_176.pth saving......
[2024-10-24 11:02:54 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_176.pth saved !!!
[2024-10-24 11:02:54 mlla_tiny] (main.py 205): INFO Max accuracy: 44.63%
[2024-10-24 11:02:54 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 11:03:42 mlla_tiny] (main.py 296): INFO Train: [177/300][100/312]	eta 0:01:41 lr 0.000046	time 0.4725 (0.4763)	loss 12.5092 (11.6610)	grad_norm 5.7382 (inf)	mem 15420MB
[2024-10-24 11:04:29 mlla_tiny] (main.py 296): INFO Train: [177/300][200/312]	eta 0:00:53 lr 0.000046	time 0.4736 (0.4747)	loss 11.1053 (11.6544)	grad_norm 6.4905 (inf)	mem 15420MB
[2024-10-24 11:05:17 mlla_tiny] (main.py 296): INFO Train: [177/300][300/312]	eta 0:00:06 lr 0.000046	time 0.4741 (0.4745)	loss 11.2942 (11.6633)	grad_norm 8.6426 (inf)	mem 15420MB
[2024-10-24 11:05:22 mlla_tiny] (main.py 304): INFO EPOCH 177 training takes 0:02:28
[2024-10-24 11:05:54 mlla_tiny] (main.py 350): INFO  * Acc@1 44.980 Acc@5 69.360
[2024-10-24 11:05:54 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.0%
[2024-10-24 11:06:25 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 11:06:25 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 11:06:25 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_177.pth saving......
[2024-10-24 11:06:26 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_177.pth saved !!!
[2024-10-24 11:06:26 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 11:06:27 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 11:06:27 mlla_tiny] (main.py 205): INFO Max accuracy: 44.98%
[2024-10-24 11:06:27 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 11:07:15 mlla_tiny] (main.py 296): INFO Train: [178/300][100/312]	eta 0:01:41 lr 0.000046	time 0.4742 (0.4758)	loss 12.1735 (11.6640)	grad_norm 6.8368 (inf)	mem 15420MB
[2024-10-24 11:08:02 mlla_tiny] (main.py 296): INFO Train: [178/300][200/312]	eta 0:00:53 lr 0.000045	time 0.4746 (0.4747)	loss 12.2645 (11.6154)	grad_norm 7.0729 (inf)	mem 15420MB
[2024-10-24 11:08:50 mlla_tiny] (main.py 296): INFO Train: [178/300][300/312]	eta 0:00:06 lr 0.000045	time 0.4745 (0.4743)	loss 12.5572 (11.6474)	grad_norm 8.8281 (inf)	mem 15420MB
[2024-10-24 11:08:55 mlla_tiny] (main.py 304): INFO EPOCH 178 training takes 0:02:27
[2024-10-24 11:09:27 mlla_tiny] (main.py 350): INFO  * Acc@1 44.190 Acc@5 69.090
[2024-10-24 11:09:27 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.2%
[2024-10-24 11:09:58 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 11:09:58 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 11:09:58 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_178.pth saving......
[2024-10-24 11:09:59 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_178.pth saved !!!
[2024-10-24 11:09:59 mlla_tiny] (main.py 205): INFO Max accuracy: 44.98%
[2024-10-24 11:09:59 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 11:10:47 mlla_tiny] (main.py 296): INFO Train: [179/300][100/312]	eta 0:01:41 lr 0.000045	time 0.4725 (0.4765)	loss 12.2954 (11.5474)	grad_norm 5.3948 (inf)	mem 15420MB
[2024-10-24 11:11:34 mlla_tiny] (main.py 296): INFO Train: [179/300][200/312]	eta 0:00:53 lr 0.000045	time 0.4724 (0.4748)	loss 11.1402 (11.5356)	grad_norm 7.4939 (inf)	mem 15420MB
[2024-10-24 11:12:21 mlla_tiny] (main.py 296): INFO Train: [179/300][300/312]	eta 0:00:06 lr 0.000045	time 0.4737 (0.4744)	loss 11.1138 (11.5905)	grad_norm 8.3836 (inf)	mem 15420MB
[2024-10-24 11:12:27 mlla_tiny] (main.py 304): INFO EPOCH 179 training takes 0:02:28
[2024-10-24 11:12:59 mlla_tiny] (main.py 350): INFO  * Acc@1 44.460 Acc@5 68.980
[2024-10-24 11:12:59 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.5%
[2024-10-24 11:13:31 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 11:13:31 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 11:13:31 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_179.pth saving......
[2024-10-24 11:13:31 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_179.pth saved !!!
[2024-10-24 11:13:31 mlla_tiny] (main.py 205): INFO Max accuracy: 44.98%
[2024-10-24 11:13:31 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 11:14:19 mlla_tiny] (main.py 296): INFO Train: [180/300][100/312]	eta 0:01:41 lr 0.000044	time 0.4723 (0.4775)	loss 12.0139 (11.5043)	grad_norm 6.6457 (inf)	mem 15420MB
[2024-10-24 11:15:07 mlla_tiny] (main.py 296): INFO Train: [180/300][200/312]	eta 0:00:53 lr 0.000044	time 0.4730 (0.4751)	loss 11.8812 (11.5009)	grad_norm 5.8280 (inf)	mem 15420MB
[2024-10-24 11:15:54 mlla_tiny] (main.py 296): INFO Train: [180/300][300/312]	eta 0:00:06 lr 0.000044	time 0.4726 (0.4747)	loss 11.7108 (11.5568)	grad_norm 8.6193 (inf)	mem 15420MB
[2024-10-24 11:16:00 mlla_tiny] (main.py 304): INFO EPOCH 180 training takes 0:02:28
[2024-10-24 11:16:31 mlla_tiny] (main.py 350): INFO  * Acc@1 44.950 Acc@5 69.640
[2024-10-24 11:16:31 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.0%
[2024-10-24 11:17:03 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 11:17:03 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 11:17:03 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_180.pth saving......
[2024-10-24 11:17:04 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_180.pth saved !!!
[2024-10-24 11:17:04 mlla_tiny] (main.py 205): INFO Max accuracy: 44.98%
[2024-10-24 11:17:04 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 11:17:51 mlla_tiny] (main.py 296): INFO Train: [181/300][100/312]	eta 0:01:41 lr 0.000044	time 0.4721 (0.4770)	loss 10.9384 (11.5517)	grad_norm 7.6903 (inf)	mem 15420MB
[2024-10-24 11:18:39 mlla_tiny] (main.py 296): INFO Train: [181/300][200/312]	eta 0:00:53 lr 0.000044	time 0.4756 (0.4753)	loss 12.1936 (11.5793)	grad_norm 5.1800 (inf)	mem 15420MB
[2024-10-24 11:19:26 mlla_tiny] (main.py 296): INFO Train: [181/300][300/312]	eta 0:00:06 lr 0.000043	time 0.4739 (0.4748)	loss 11.6268 (11.5974)	grad_norm 10.6803 (inf)	mem 15420MB
[2024-10-24 11:19:32 mlla_tiny] (main.py 304): INFO EPOCH 181 training takes 0:02:28
[2024-10-24 11:20:03 mlla_tiny] (main.py 350): INFO  * Acc@1 44.590 Acc@5 69.310
[2024-10-24 11:20:03 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.6%
[2024-10-24 11:20:35 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 11:20:35 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 11:20:35 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_181.pth saving......
[2024-10-24 11:20:36 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_181.pth saved !!!
[2024-10-24 11:20:36 mlla_tiny] (main.py 205): INFO Max accuracy: 44.98%
[2024-10-24 11:20:36 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 11:21:23 mlla_tiny] (main.py 296): INFO Train: [182/300][100/312]	eta 0:01:41 lr 0.000043	time 0.4716 (0.4764)	loss 12.0450 (11.5532)	grad_norm 5.3362 (inf)	mem 15420MB
[2024-10-24 11:22:11 mlla_tiny] (main.py 296): INFO Train: [182/300][200/312]	eta 0:00:53 lr 0.000043	time 0.4740 (0.4747)	loss 11.0328 (11.6217)	grad_norm 6.2065 (inf)	mem 15420MB
[2024-10-24 11:22:58 mlla_tiny] (main.py 296): INFO Train: [182/300][300/312]	eta 0:00:06 lr 0.000043	time 0.4736 (0.4743)	loss 12.3373 (11.6397)	grad_norm 6.6549 (inf)	mem 15420MB
[2024-10-24 11:23:04 mlla_tiny] (main.py 304): INFO EPOCH 182 training takes 0:02:28
[2024-10-24 11:23:35 mlla_tiny] (main.py 350): INFO  * Acc@1 44.280 Acc@5 68.960
[2024-10-24 11:23:35 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.3%
[2024-10-24 11:24:07 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 11:24:07 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 11:24:07 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_182.pth saving......
[2024-10-24 11:24:08 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_182.pth saved !!!
[2024-10-24 11:24:08 mlla_tiny] (main.py 205): INFO Max accuracy: 44.98%
[2024-10-24 11:24:08 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 11:24:55 mlla_tiny] (main.py 296): INFO Train: [183/300][100/312]	eta 0:01:41 lr 0.000043	time 0.4729 (0.4769)	loss 10.9288 (11.6309)	grad_norm 8.7503 (inf)	mem 15420MB
[2024-10-24 11:25:43 mlla_tiny] (main.py 296): INFO Train: [183/300][200/312]	eta 0:00:53 lr 0.000042	time 0.4734 (0.4752)	loss 12.0938 (11.5661)	grad_norm 5.6499 (inf)	mem 15420MB
[2024-10-24 11:26:30 mlla_tiny] (main.py 296): INFO Train: [183/300][300/312]	eta 0:00:06 lr 0.000042	time 0.4729 (0.4746)	loss 11.0756 (11.5573)	grad_norm 6.0667 (inf)	mem 15420MB
[2024-10-24 11:26:36 mlla_tiny] (main.py 304): INFO EPOCH 183 training takes 0:02:28
[2024-10-24 11:27:07 mlla_tiny] (main.py 350): INFO  * Acc@1 44.890 Acc@5 69.060
[2024-10-24 11:27:07 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.9%
[2024-10-24 11:27:39 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 11:27:39 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 11:27:39 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_183.pth saving......
[2024-10-24 11:27:40 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_183.pth saved !!!
[2024-10-24 11:27:40 mlla_tiny] (main.py 205): INFO Max accuracy: 44.98%
[2024-10-24 11:27:40 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 11:28:27 mlla_tiny] (main.py 296): INFO Train: [184/300][100/312]	eta 0:01:41 lr 0.000042	time 0.4725 (0.4772)	loss 11.9140 (11.6291)	grad_norm 6.0052 (inf)	mem 15420MB
[2024-10-24 11:29:15 mlla_tiny] (main.py 296): INFO Train: [184/300][200/312]	eta 0:00:53 lr 0.000042	time 0.4744 (0.4753)	loss 11.7132 (11.6416)	grad_norm 7.4851 (inf)	mem 15420MB
[2024-10-24 11:30:02 mlla_tiny] (main.py 296): INFO Train: [184/300][300/312]	eta 0:00:06 lr 0.000042	time 0.4739 (0.4749)	loss 10.4125 (11.6022)	grad_norm 7.2350 (inf)	mem 15420MB
[2024-10-24 11:30:08 mlla_tiny] (main.py 304): INFO EPOCH 184 training takes 0:02:28
[2024-10-24 11:30:39 mlla_tiny] (main.py 350): INFO  * Acc@1 44.910 Acc@5 69.100
[2024-10-24 11:30:39 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.9%
[2024-10-24 11:31:11 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.550
[2024-10-24 11:31:11 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 11:31:11 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_184.pth saving......
[2024-10-24 11:31:12 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_184.pth saved !!!
[2024-10-24 11:31:12 mlla_tiny] (main.py 205): INFO Max accuracy: 44.98%
[2024-10-24 11:31:12 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 11:31:59 mlla_tiny] (main.py 296): INFO Train: [185/300][100/312]	eta 0:01:41 lr 0.000041	time 0.4716 (0.4758)	loss 11.9041 (11.6040)	grad_norm 5.8582 (inf)	mem 15420MB
[2024-10-24 11:32:47 mlla_tiny] (main.py 296): INFO Train: [185/300][200/312]	eta 0:00:53 lr 0.000041	time 0.4730 (0.4741)	loss 12.0322 (11.6391)	grad_norm 6.0095 (inf)	mem 15420MB
[2024-10-24 11:33:34 mlla_tiny] (main.py 296): INFO Train: [185/300][300/312]	eta 0:00:06 lr 0.000041	time 0.4744 (0.4740)	loss 11.7154 (11.6477)	grad_norm 6.2950 (inf)	mem 15420MB
[2024-10-24 11:33:40 mlla_tiny] (main.py 304): INFO EPOCH 185 training takes 0:02:27
[2024-10-24 11:34:11 mlla_tiny] (main.py 350): INFO  * Acc@1 44.910 Acc@5 69.090
[2024-10-24 11:34:11 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.9%
[2024-10-24 11:34:43 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 11:34:43 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 11:34:43 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_185.pth saving......
[2024-10-24 11:34:44 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_185.pth saved !!!
[2024-10-24 11:34:44 mlla_tiny] (main.py 205): INFO Max accuracy: 44.98%
[2024-10-24 11:34:44 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 11:35:31 mlla_tiny] (main.py 296): INFO Train: [186/300][100/312]	eta 0:01:41 lr 0.000041	time 0.4721 (0.4767)	loss 11.7958 (11.5761)	grad_norm 5.6488 (inf)	mem 15420MB
[2024-10-24 11:36:18 mlla_tiny] (main.py 296): INFO Train: [186/300][200/312]	eta 0:00:53 lr 0.000041	time 0.4730 (0.4746)	loss 12.3091 (11.5916)	grad_norm 7.2000 (inf)	mem 15420MB
[2024-10-24 11:37:06 mlla_tiny] (main.py 296): INFO Train: [186/300][300/312]	eta 0:00:06 lr 0.000040	time 0.4733 (0.4742)	loss 11.8143 (11.5866)	grad_norm 5.7323 (inf)	mem 15420MB
[2024-10-24 11:37:12 mlla_tiny] (main.py 304): INFO EPOCH 186 training takes 0:02:27
[2024-10-24 11:37:43 mlla_tiny] (main.py 350): INFO  * Acc@1 44.600 Acc@5 69.330
[2024-10-24 11:37:43 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.6%
[2024-10-24 11:38:14 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 11:38:14 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 11:38:14 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_186.pth saving......
[2024-10-24 11:38:15 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_186.pth saved !!!
[2024-10-24 11:38:15 mlla_tiny] (main.py 205): INFO Max accuracy: 44.98%
[2024-10-24 11:38:15 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 11:39:03 mlla_tiny] (main.py 296): INFO Train: [187/300][100/312]	eta 0:01:41 lr 0.000040	time 0.4720 (0.4766)	loss 11.6451 (11.5956)	grad_norm 7.1989 (inf)	mem 15420MB
[2024-10-24 11:39:50 mlla_tiny] (main.py 296): INFO Train: [187/300][200/312]	eta 0:00:53 lr 0.000040	time 0.4732 (0.4751)	loss 12.0940 (11.5954)	grad_norm 5.9270 (inf)	mem 15420MB
[2024-10-24 11:40:38 mlla_tiny] (main.py 296): INFO Train: [187/300][300/312]	eta 0:00:06 lr 0.000040	time 0.4743 (0.4745)	loss 10.6032 (11.5762)	grad_norm 6.4641 (inf)	mem 15420MB
[2024-10-24 11:40:43 mlla_tiny] (main.py 304): INFO EPOCH 187 training takes 0:02:28
[2024-10-24 11:41:15 mlla_tiny] (main.py 350): INFO  * Acc@1 44.250 Acc@5 68.840
[2024-10-24 11:41:15 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.2%
[2024-10-24 11:41:46 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 11:41:46 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 11:41:46 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_187.pth saving......
[2024-10-24 11:41:47 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_187.pth saved !!!
[2024-10-24 11:41:47 mlla_tiny] (main.py 205): INFO Max accuracy: 44.98%
[2024-10-24 11:41:47 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 11:42:34 mlla_tiny] (main.py 296): INFO Train: [188/300][100/312]	eta 0:01:41 lr 0.000040	time 0.4712 (0.4767)	loss 11.1254 (11.5319)	grad_norm 8.7484 (inf)	mem 15420MB
[2024-10-24 11:43:22 mlla_tiny] (main.py 296): INFO Train: [188/300][200/312]	eta 0:00:53 lr 0.000039	time 0.4736 (0.4747)	loss 12.0563 (11.5132)	grad_norm 4.3168 (inf)	mem 15420MB
[2024-10-24 11:44:09 mlla_tiny] (main.py 296): INFO Train: [188/300][300/312]	eta 0:00:06 lr 0.000039	time 0.4740 (0.4743)	loss 10.4902 (11.5401)	grad_norm 7.1013 (inf)	mem 15420MB
[2024-10-24 11:44:15 mlla_tiny] (main.py 304): INFO EPOCH 188 training takes 0:02:28
[2024-10-24 11:44:46 mlla_tiny] (main.py 350): INFO  * Acc@1 45.280 Acc@5 69.350
[2024-10-24 11:44:46 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.3%
[2024-10-24 11:45:17 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 11:45:17 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 11:45:17 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_188.pth saving......
[2024-10-24 11:45:18 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_188.pth saved !!!
[2024-10-24 11:45:18 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 11:45:19 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 11:45:19 mlla_tiny] (main.py 205): INFO Max accuracy: 45.28%
[2024-10-24 11:45:19 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 11:46:07 mlla_tiny] (main.py 296): INFO Train: [189/300][100/312]	eta 0:01:41 lr 0.000039	time 0.4717 (0.4761)	loss 11.1723 (11.4750)	grad_norm 7.3871 (inf)	mem 15420MB
[2024-10-24 11:46:54 mlla_tiny] (main.py 296): INFO Train: [189/300][200/312]	eta 0:00:53 lr 0.000039	time 0.4737 (0.4746)	loss 12.1673 (11.5659)	grad_norm 4.8915 (inf)	mem 15420MB
[2024-10-24 11:47:42 mlla_tiny] (main.py 296): INFO Train: [189/300][300/312]	eta 0:00:06 lr 0.000039	time 0.4729 (0.4743)	loss 11.1562 (11.5888)	grad_norm 9.8474 (inf)	mem 15420MB
[2024-10-24 11:47:47 mlla_tiny] (main.py 304): INFO EPOCH 189 training takes 0:02:28
[2024-10-24 11:48:18 mlla_tiny] (main.py 350): INFO  * Acc@1 45.280 Acc@5 69.920
[2024-10-24 11:48:18 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.3%
[2024-10-24 11:48:49 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 11:48:49 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 11:48:49 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_189.pth saving......
[2024-10-24 11:48:50 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_189.pth saved !!!
[2024-10-24 11:48:50 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 11:48:51 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 11:48:51 mlla_tiny] (main.py 205): INFO Max accuracy: 45.28%
[2024-10-24 11:48:51 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 11:49:39 mlla_tiny] (main.py 296): INFO Train: [190/300][100/312]	eta 0:01:41 lr 0.000038	time 0.4729 (0.4764)	loss 11.3029 (11.5507)	grad_norm 7.2160 (inf)	mem 15420MB
[2024-10-24 11:50:26 mlla_tiny] (main.py 296): INFO Train: [190/300][200/312]	eta 0:00:53 lr 0.000038	time 0.4751 (0.4748)	loss 11.9622 (11.4995)	grad_norm 6.9749 (inf)	mem 15420MB
[2024-10-24 11:51:14 mlla_tiny] (main.py 296): INFO Train: [190/300][300/312]	eta 0:00:06 lr 0.000038	time 0.4730 (0.4746)	loss 10.8196 (11.5205)	grad_norm 12.8370 (inf)	mem 15420MB
[2024-10-24 11:51:19 mlla_tiny] (main.py 304): INFO EPOCH 190 training takes 0:02:28
[2024-10-24 11:51:51 mlla_tiny] (main.py 350): INFO  * Acc@1 45.440 Acc@5 69.120
[2024-10-24 11:51:51 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.4%
[2024-10-24 11:52:22 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 11:52:22 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 11:52:22 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_190.pth saving......
[2024-10-24 11:52:23 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_190.pth saved !!!
[2024-10-24 11:52:23 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 11:52:24 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 11:52:24 mlla_tiny] (main.py 205): INFO Max accuracy: 45.44%
[2024-10-24 11:52:24 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 11:53:12 mlla_tiny] (main.py 296): INFO Train: [191/300][100/312]	eta 0:01:41 lr 0.000038	time 0.4733 (0.4772)	loss 11.9938 (11.6865)	grad_norm 5.0149 (inf)	mem 15420MB
[2024-10-24 11:53:59 mlla_tiny] (main.py 296): INFO Train: [191/300][200/312]	eta 0:00:53 lr 0.000038	time 0.4731 (0.4752)	loss 10.4157 (11.5768)	grad_norm 7.4001 (inf)	mem 15420MB
[2024-10-24 11:54:47 mlla_tiny] (main.py 296): INFO Train: [191/300][300/312]	eta 0:00:06 lr 0.000037	time 0.4739 (0.4748)	loss 11.3195 (11.5777)	grad_norm 5.3268 (inf)	mem 15420MB
[2024-10-24 11:54:52 mlla_tiny] (main.py 304): INFO EPOCH 191 training takes 0:02:28
[2024-10-24 11:55:24 mlla_tiny] (main.py 350): INFO  * Acc@1 44.990 Acc@5 69.200
[2024-10-24 11:55:24 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.0%
[2024-10-24 11:55:55 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 11:55:55 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 11:55:55 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_191.pth saving......
[2024-10-24 11:55:56 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_191.pth saved !!!
[2024-10-24 11:55:56 mlla_tiny] (main.py 205): INFO Max accuracy: 45.44%
[2024-10-24 11:55:56 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 11:56:44 mlla_tiny] (main.py 296): INFO Train: [192/300][100/312]	eta 0:01:41 lr 0.000037	time 0.4717 (0.4764)	loss 11.2145 (11.4835)	grad_norm 5.5853 (inf)	mem 15420MB
[2024-10-24 11:57:31 mlla_tiny] (main.py 296): INFO Train: [192/300][200/312]	eta 0:00:53 lr 0.000037	time 0.4729 (0.4748)	loss 12.2340 (11.5234)	grad_norm 6.8898 (inf)	mem 15420MB
[2024-10-24 11:58:18 mlla_tiny] (main.py 296): INFO Train: [192/300][300/312]	eta 0:00:06 lr 0.000037	time 0.4734 (0.4744)	loss 12.1791 (11.4890)	grad_norm 7.3630 (inf)	mem 15420MB
[2024-10-24 11:58:24 mlla_tiny] (main.py 304): INFO EPOCH 192 training takes 0:02:28
[2024-10-24 11:58:55 mlla_tiny] (main.py 350): INFO  * Acc@1 45.270 Acc@5 69.620
[2024-10-24 11:58:55 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.3%
[2024-10-24 11:59:27 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 11:59:27 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 11:59:27 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_192.pth saving......
[2024-10-24 11:59:28 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_192.pth saved !!!
[2024-10-24 11:59:28 mlla_tiny] (main.py 205): INFO Max accuracy: 45.44%
[2024-10-24 11:59:28 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 12:00:16 mlla_tiny] (main.py 296): INFO Train: [193/300][100/312]	eta 0:01:41 lr 0.000037	time 0.4716 (0.4759)	loss 10.3199 (11.5961)	grad_norm 6.5964 (inf)	mem 15420MB
[2024-10-24 12:01:03 mlla_tiny] (main.py 296): INFO Train: [193/300][200/312]	eta 0:00:53 lr 0.000036	time 0.4732 (0.4743)	loss 11.4923 (11.5795)	grad_norm 10.2571 (inf)	mem 15420MB
[2024-10-24 12:01:50 mlla_tiny] (main.py 296): INFO Train: [193/300][300/312]	eta 0:00:06 lr 0.000036	time 0.4727 (0.4741)	loss 12.1180 (11.5721)	grad_norm 6.0690 (inf)	mem 15420MB
[2024-10-24 12:01:56 mlla_tiny] (main.py 304): INFO EPOCH 193 training takes 0:02:27
[2024-10-24 12:02:27 mlla_tiny] (main.py 350): INFO  * Acc@1 45.030 Acc@5 69.210
[2024-10-24 12:02:27 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.0%
[2024-10-24 12:02:58 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 12:02:58 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 12:02:58 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_193.pth saving......
[2024-10-24 12:03:00 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_193.pth saved !!!
[2024-10-24 12:03:00 mlla_tiny] (main.py 205): INFO Max accuracy: 45.44%
[2024-10-24 12:03:00 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 12:03:48 mlla_tiny] (main.py 296): INFO Train: [194/300][100/312]	eta 0:01:41 lr 0.000036	time 0.4722 (0.4769)	loss 11.7216 (11.4764)	grad_norm 5.4861 (inf)	mem 15420MB
[2024-10-24 12:04:35 mlla_tiny] (main.py 296): INFO Train: [194/300][200/312]	eta 0:00:53 lr 0.000036	time 0.4728 (0.4749)	loss 11.2335 (11.5281)	grad_norm 7.0962 (inf)	mem 15420MB
[2024-10-24 12:05:22 mlla_tiny] (main.py 296): INFO Train: [194/300][300/312]	eta 0:00:06 lr 0.000036	time 0.4758 (0.4746)	loss 11.3991 (11.5487)	grad_norm 5.2434 (inf)	mem 15420MB
[2024-10-24 12:05:28 mlla_tiny] (main.py 304): INFO EPOCH 194 training takes 0:02:28
[2024-10-24 12:05:59 mlla_tiny] (main.py 350): INFO  * Acc@1 45.850 Acc@5 69.670
[2024-10-24 12:05:59 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.9%
[2024-10-24 12:06:31 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 12:06:31 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 12:06:31 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_194.pth saving......
[2024-10-24 12:06:32 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_194.pth saved !!!
[2024-10-24 12:06:32 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 12:06:33 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 12:06:33 mlla_tiny] (main.py 205): INFO Max accuracy: 45.85%
[2024-10-24 12:06:33 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 12:07:20 mlla_tiny] (main.py 296): INFO Train: [195/300][100/312]	eta 0:01:41 lr 0.000035	time 0.4719 (0.4764)	loss 10.4257 (11.6059)	grad_norm 9.9396 (inf)	mem 15420MB
[2024-10-24 12:08:08 mlla_tiny] (main.py 296): INFO Train: [195/300][200/312]	eta 0:00:53 lr 0.000035	time 0.4725 (0.4745)	loss 10.7752 (11.5667)	grad_norm 6.8785 (inf)	mem 15420MB
[2024-10-24 12:08:55 mlla_tiny] (main.py 296): INFO Train: [195/300][300/312]	eta 0:00:06 lr 0.000035	time 0.4733 (0.4742)	loss 11.4045 (11.5896)	grad_norm 5.6947 (inf)	mem 15420MB
[2024-10-24 12:09:01 mlla_tiny] (main.py 304): INFO EPOCH 195 training takes 0:02:27
[2024-10-24 12:09:32 mlla_tiny] (main.py 350): INFO  * Acc@1 45.320 Acc@5 69.580
[2024-10-24 12:09:32 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.3%
[2024-10-24 12:10:04 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 12:10:04 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 12:10:04 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_195.pth saving......
[2024-10-24 12:10:05 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_195.pth saved !!!
[2024-10-24 12:10:05 mlla_tiny] (main.py 205): INFO Max accuracy: 45.85%
[2024-10-24 12:10:05 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 12:10:52 mlla_tiny] (main.py 296): INFO Train: [196/300][100/312]	eta 0:01:41 lr 0.000035	time 0.4723 (0.4762)	loss 10.3441 (11.4217)	grad_norm 8.6390 (inf)	mem 15420MB
[2024-10-24 12:11:40 mlla_tiny] (main.py 296): INFO Train: [196/300][200/312]	eta 0:00:53 lr 0.000035	time 0.4730 (0.4746)	loss 12.0295 (11.4409)	grad_norm 5.3219 (inf)	mem 15420MB
[2024-10-24 12:12:27 mlla_tiny] (main.py 296): INFO Train: [196/300][300/312]	eta 0:00:06 lr 0.000034	time 0.4742 (0.4743)	loss 12.1440 (11.4820)	grad_norm 5.6907 (inf)	mem 15420MB
[2024-10-24 12:12:33 mlla_tiny] (main.py 304): INFO EPOCH 196 training takes 0:02:28
[2024-10-24 12:13:04 mlla_tiny] (main.py 350): INFO  * Acc@1 45.240 Acc@5 69.430
[2024-10-24 12:13:04 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.2%
[2024-10-24 12:13:35 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 12:13:35 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 12:13:35 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_196.pth saving......
[2024-10-24 12:13:37 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_196.pth saved !!!
[2024-10-24 12:13:37 mlla_tiny] (main.py 205): INFO Max accuracy: 45.85%
[2024-10-24 12:13:37 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 12:14:24 mlla_tiny] (main.py 296): INFO Train: [197/300][100/312]	eta 0:01:41 lr 0.000034	time 0.4725 (0.4770)	loss 12.0225 (11.5552)	grad_norm 5.8406 (inf)	mem 15420MB
[2024-10-24 12:15:12 mlla_tiny] (main.py 296): INFO Train: [197/300][200/312]	eta 0:00:53 lr 0.000034	time 0.4735 (0.4749)	loss 11.7912 (11.5528)	grad_norm 5.9920 (inf)	mem 15420MB
[2024-10-24 12:15:59 mlla_tiny] (main.py 296): INFO Train: [197/300][300/312]	eta 0:00:06 lr 0.000034	time 0.4729 (0.4746)	loss 11.8346 (11.5592)	grad_norm 4.3155 (nan)	mem 15420MB
[2024-10-24 12:16:05 mlla_tiny] (main.py 304): INFO EPOCH 197 training takes 0:02:28
[2024-10-24 12:16:36 mlla_tiny] (main.py 350): INFO  * Acc@1 44.860 Acc@5 69.110
[2024-10-24 12:16:36 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 44.9%
[2024-10-24 12:17:07 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 12:17:07 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 12:17:07 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_197.pth saving......
[2024-10-24 12:17:08 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_197.pth saved !!!
[2024-10-24 12:17:08 mlla_tiny] (main.py 205): INFO Max accuracy: 45.85%
[2024-10-24 12:17:08 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 12:17:56 mlla_tiny] (main.py 296): INFO Train: [198/300][100/312]	eta 0:01:41 lr 0.000034	time 0.5108 (0.4766)	loss 11.3302 (11.4607)	grad_norm 8.7767 (inf)	mem 15420MB
[2024-10-24 12:18:43 mlla_tiny] (main.py 296): INFO Train: [198/300][200/312]	eta 0:00:53 lr 0.000034	time 0.4731 (0.4751)	loss 11.4063 (11.4795)	grad_norm 5.5816 (inf)	mem 15420MB
[2024-10-24 12:19:31 mlla_tiny] (main.py 296): INFO Train: [198/300][300/312]	eta 0:00:06 lr 0.000033	time 0.4739 (0.4747)	loss 10.7282 (11.4976)	grad_norm 7.3276 (inf)	mem 15420MB
[2024-10-24 12:19:36 mlla_tiny] (main.py 304): INFO EPOCH 198 training takes 0:02:28
[2024-10-24 12:20:08 mlla_tiny] (main.py 350): INFO  * Acc@1 45.370 Acc@5 69.380
[2024-10-24 12:20:08 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.4%
[2024-10-24 12:20:39 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 12:20:39 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 12:20:39 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_198.pth saving......
[2024-10-24 12:20:40 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_198.pth saved !!!
[2024-10-24 12:20:40 mlla_tiny] (main.py 205): INFO Max accuracy: 45.85%
[2024-10-24 12:20:40 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 12:21:27 mlla_tiny] (main.py 296): INFO Train: [199/300][100/312]	eta 0:01:41 lr 0.000033	time 0.4721 (0.4761)	loss 11.0261 (11.5872)	grad_norm 11.7720 (inf)	mem 15420MB
[2024-10-24 12:22:14 mlla_tiny] (main.py 296): INFO Train: [199/300][200/312]	eta 0:00:53 lr 0.000033	time 0.4737 (0.4747)	loss 12.0622 (11.5791)	grad_norm 6.0988 (inf)	mem 15420MB
[2024-10-24 12:23:02 mlla_tiny] (main.py 296): INFO Train: [199/300][300/312]	eta 0:00:06 lr 0.000033	time 0.4740 (0.4743)	loss 10.6748 (11.5821)	grad_norm 7.2459 (inf)	mem 15420MB
[2024-10-24 12:23:08 mlla_tiny] (main.py 304): INFO EPOCH 199 training takes 0:02:28
[2024-10-24 12:23:39 mlla_tiny] (main.py 350): INFO  * Acc@1 45.500 Acc@5 69.300
[2024-10-24 12:23:39 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.5%
[2024-10-24 12:24:11 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 12:24:11 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 12:24:11 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_199.pth saving......
[2024-10-24 12:24:12 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_199.pth saved !!!
[2024-10-24 12:24:12 mlla_tiny] (main.py 205): INFO Max accuracy: 45.85%
[2024-10-24 12:24:12 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 12:25:00 mlla_tiny] (main.py 296): INFO Train: [200/300][100/312]	eta 0:01:41 lr 0.000033	time 0.4726 (0.4771)	loss 12.2108 (11.4647)	grad_norm 6.5089 (inf)	mem 15420MB
[2024-10-24 12:25:47 mlla_tiny] (main.py 296): INFO Train: [200/300][200/312]	eta 0:00:53 lr 0.000032	time 0.4734 (0.4751)	loss 12.0094 (11.5116)	grad_norm 6.4148 (inf)	mem 15420MB
[2024-10-24 12:26:34 mlla_tiny] (main.py 296): INFO Train: [200/300][300/312]	eta 0:00:06 lr 0.000032	time 0.4735 (0.4745)	loss 12.1972 (11.4907)	grad_norm 4.6100 (inf)	mem 15420MB
[2024-10-24 12:26:40 mlla_tiny] (main.py 304): INFO EPOCH 200 training takes 0:02:28
[2024-10-24 12:27:11 mlla_tiny] (main.py 350): INFO  * Acc@1 45.500 Acc@5 69.710
[2024-10-24 12:27:11 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.5%
[2024-10-24 12:27:43 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 12:27:43 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 12:27:43 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_200.pth saving......
[2024-10-24 12:27:44 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_200.pth saved !!!
[2024-10-24 12:27:44 mlla_tiny] (main.py 205): INFO Max accuracy: 45.85%
[2024-10-24 12:27:44 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 12:28:31 mlla_tiny] (main.py 296): INFO Train: [201/300][100/312]	eta 0:01:41 lr 0.000032	time 0.4723 (0.4766)	loss 12.1647 (11.4514)	grad_norm 5.1872 (inf)	mem 15420MB
[2024-10-24 12:29:19 mlla_tiny] (main.py 296): INFO Train: [201/300][200/312]	eta 0:00:53 lr 0.000032	time 0.4731 (0.4747)	loss 12.0864 (11.4869)	grad_norm 6.0743 (inf)	mem 15420MB
[2024-10-24 12:30:06 mlla_tiny] (main.py 296): INFO Train: [201/300][300/312]	eta 0:00:06 lr 0.000032	time 0.4730 (0.4742)	loss 10.4294 (11.4699)	grad_norm 5.9611 (inf)	mem 15420MB
[2024-10-24 12:30:12 mlla_tiny] (main.py 304): INFO EPOCH 201 training takes 0:02:27
[2024-10-24 12:30:43 mlla_tiny] (main.py 350): INFO  * Acc@1 45.680 Acc@5 69.320
[2024-10-24 12:30:43 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.7%
[2024-10-24 12:31:14 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 12:31:14 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 12:31:15 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_201.pth saving......
[2024-10-24 12:31:15 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_201.pth saved !!!
[2024-10-24 12:31:15 mlla_tiny] (main.py 205): INFO Max accuracy: 45.85%
[2024-10-24 12:31:15 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 12:32:03 mlla_tiny] (main.py 296): INFO Train: [202/300][100/312]	eta 0:01:41 lr 0.000031	time 0.4717 (0.4757)	loss 12.1295 (11.4299)	grad_norm 9.0237 (inf)	mem 15420MB
[2024-10-24 12:32:50 mlla_tiny] (main.py 296): INFO Train: [202/300][200/312]	eta 0:00:53 lr 0.000031	time 0.4732 (0.4741)	loss 11.0610 (11.4601)	grad_norm 6.4962 (inf)	mem 15420MB
[2024-10-24 12:33:38 mlla_tiny] (main.py 296): INFO Train: [202/300][300/312]	eta 0:00:06 lr 0.000031	time 0.4746 (0.4740)	loss 12.2672 (11.5007)	grad_norm 6.4124 (inf)	mem 15420MB
[2024-10-24 12:33:43 mlla_tiny] (main.py 304): INFO EPOCH 202 training takes 0:02:27
[2024-10-24 12:34:14 mlla_tiny] (main.py 350): INFO  * Acc@1 45.450 Acc@5 69.480
[2024-10-24 12:34:14 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.5%
[2024-10-24 12:34:46 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 12:34:46 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 12:34:46 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_202.pth saving......
[2024-10-24 12:34:47 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_202.pth saved !!!
[2024-10-24 12:34:47 mlla_tiny] (main.py 205): INFO Max accuracy: 45.85%
[2024-10-24 12:34:47 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 12:35:35 mlla_tiny] (main.py 296): INFO Train: [203/300][100/312]	eta 0:01:41 lr 0.000031	time 0.4716 (0.4772)	loss 12.0815 (11.5048)	grad_norm 7.3181 (inf)	mem 15420MB
[2024-10-24 12:36:22 mlla_tiny] (main.py 296): INFO Train: [203/300][200/312]	eta 0:00:53 lr 0.000031	time 0.4735 (0.4752)	loss 11.7329 (11.5579)	grad_norm 7.9079 (inf)	mem 15420MB
[2024-10-24 12:37:09 mlla_tiny] (main.py 296): INFO Train: [203/300][300/312]	eta 0:00:06 lr 0.000031	time 0.4735 (0.4747)	loss 12.1423 (11.5463)	grad_norm 6.8650 (inf)	mem 15420MB
[2024-10-24 12:37:15 mlla_tiny] (main.py 304): INFO EPOCH 203 training takes 0:02:28
[2024-10-24 12:37:48 mlla_tiny] (main.py 350): INFO  * Acc@1 45.940 Acc@5 69.540
[2024-10-24 12:37:48 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.9%
[2024-10-24 12:38:19 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 12:38:19 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 12:38:19 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_203.pth saving......
[2024-10-24 12:38:20 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_203.pth saved !!!
[2024-10-24 12:38:20 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 12:38:21 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 12:38:21 mlla_tiny] (main.py 205): INFO Max accuracy: 45.94%
[2024-10-24 12:38:21 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 12:39:08 mlla_tiny] (main.py 296): INFO Train: [204/300][100/312]	eta 0:01:41 lr 0.000030	time 0.4722 (0.4765)	loss 12.0832 (11.4604)	grad_norm 7.9918 (inf)	mem 15420MB
[2024-10-24 12:39:56 mlla_tiny] (main.py 296): INFO Train: [204/300][200/312]	eta 0:00:53 lr 0.000030	time 0.4743 (0.4748)	loss 12.4194 (11.4318)	grad_norm 6.2143 (inf)	mem 15420MB
[2024-10-24 12:40:43 mlla_tiny] (main.py 296): INFO Train: [204/300][300/312]	eta 0:00:06 lr 0.000030	time 0.4743 (0.4744)	loss 12.0870 (11.4614)	grad_norm 11.8866 (inf)	mem 15420MB
[2024-10-24 12:40:49 mlla_tiny] (main.py 304): INFO EPOCH 204 training takes 0:02:28
[2024-10-24 12:41:21 mlla_tiny] (main.py 350): INFO  * Acc@1 45.830 Acc@5 69.570
[2024-10-24 12:41:21 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.8%
[2024-10-24 12:41:52 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 12:41:52 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 12:41:52 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_204.pth saving......
[2024-10-24 12:41:53 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_204.pth saved !!!
[2024-10-24 12:41:53 mlla_tiny] (main.py 205): INFO Max accuracy: 45.94%
[2024-10-24 12:41:53 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 12:42:41 mlla_tiny] (main.py 296): INFO Train: [205/300][100/312]	eta 0:01:41 lr 0.000030	time 0.4717 (0.4766)	loss 12.3569 (11.4919)	grad_norm 5.9370 (inf)	mem 15420MB
[2024-10-24 12:43:28 mlla_tiny] (main.py 296): INFO Train: [205/300][200/312]	eta 0:00:53 lr 0.000030	time 0.4729 (0.4746)	loss 10.5679 (11.4676)	grad_norm 10.0144 (inf)	mem 15420MB
[2024-10-24 12:44:15 mlla_tiny] (main.py 296): INFO Train: [205/300][300/312]	eta 0:00:06 lr 0.000029	time 0.4730 (0.4742)	loss 11.2375 (11.5009)	grad_norm 5.3450 (inf)	mem 15420MB
[2024-10-24 12:44:21 mlla_tiny] (main.py 304): INFO EPOCH 205 training takes 0:02:27
[2024-10-24 12:44:53 mlla_tiny] (main.py 350): INFO  * Acc@1 45.770 Acc@5 69.560
[2024-10-24 12:44:53 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.8%
[2024-10-24 12:45:24 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 12:45:24 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 12:45:24 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_205.pth saving......
[2024-10-24 12:45:25 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_205.pth saved !!!
[2024-10-24 12:45:25 mlla_tiny] (main.py 205): INFO Max accuracy: 45.94%
[2024-10-24 12:45:25 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 12:46:13 mlla_tiny] (main.py 296): INFO Train: [206/300][100/312]	eta 0:01:41 lr 0.000029	time 0.4718 (0.4762)	loss 10.2380 (11.4811)	grad_norm 7.5567 (inf)	mem 15420MB
[2024-10-24 12:47:00 mlla_tiny] (main.py 296): INFO Train: [206/300][200/312]	eta 0:00:53 lr 0.000029	time 0.4729 (0.4745)	loss 11.8724 (11.5463)	grad_norm 6.3504 (inf)	mem 15420MB
[2024-10-24 12:47:48 mlla_tiny] (main.py 296): INFO Train: [206/300][300/312]	eta 0:00:06 lr 0.000029	time 0.4745 (0.4742)	loss 12.2229 (11.5411)	grad_norm 5.6313 (inf)	mem 15420MB
[2024-10-24 12:47:53 mlla_tiny] (main.py 304): INFO EPOCH 206 training takes 0:02:27
[2024-10-24 12:48:25 mlla_tiny] (main.py 350): INFO  * Acc@1 45.530 Acc@5 70.020
[2024-10-24 12:48:25 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.5%
[2024-10-24 12:48:56 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 12:48:56 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 12:48:56 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_206.pth saving......
[2024-10-24 12:48:57 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_206.pth saved !!!
[2024-10-24 12:48:57 mlla_tiny] (main.py 205): INFO Max accuracy: 45.94%
[2024-10-24 12:48:57 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 12:49:45 mlla_tiny] (main.py 296): INFO Train: [207/300][100/312]	eta 0:01:41 lr 0.000029	time 0.4722 (0.4774)	loss 12.3235 (11.5617)	grad_norm 6.0479 (inf)	mem 15420MB
[2024-10-24 12:50:32 mlla_tiny] (main.py 296): INFO Train: [207/300][200/312]	eta 0:00:53 lr 0.000029	time 0.4737 (0.4748)	loss 11.0746 (11.4912)	grad_norm 8.0669 (inf)	mem 15420MB
[2024-10-24 12:51:19 mlla_tiny] (main.py 296): INFO Train: [207/300][300/312]	eta 0:00:06 lr 0.000028	time 0.4734 (0.4743)	loss 11.0988 (11.5041)	grad_norm 9.8467 (inf)	mem 15420MB
[2024-10-24 12:51:25 mlla_tiny] (main.py 304): INFO EPOCH 207 training takes 0:02:27
[2024-10-24 12:51:57 mlla_tiny] (main.py 350): INFO  * Acc@1 45.390 Acc@5 69.730
[2024-10-24 12:51:57 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.4%
[2024-10-24 12:52:28 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 12:52:28 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 12:52:28 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_207.pth saving......
[2024-10-24 12:52:29 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_207.pth saved !!!
[2024-10-24 12:52:29 mlla_tiny] (main.py 205): INFO Max accuracy: 45.94%
[2024-10-24 12:52:29 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 12:53:17 mlla_tiny] (main.py 296): INFO Train: [208/300][100/312]	eta 0:01:41 lr 0.000028	time 0.4747 (0.4769)	loss 11.7138 (11.5539)	grad_norm 5.1172 (inf)	mem 15420MB
[2024-10-24 12:54:04 mlla_tiny] (main.py 296): INFO Train: [208/300][200/312]	eta 0:00:53 lr 0.000028	time 0.4726 (0.4747)	loss 11.5285 (11.5244)	grad_norm 5.6028 (inf)	mem 15420MB
[2024-10-24 12:54:51 mlla_tiny] (main.py 296): INFO Train: [208/300][300/312]	eta 0:00:06 lr 0.000028	time 0.5169 (0.4744)	loss 12.0329 (11.5030)	grad_norm 4.9648 (inf)	mem 15420MB
[2024-10-24 12:54:57 mlla_tiny] (main.py 304): INFO EPOCH 208 training takes 0:02:28
[2024-10-24 12:55:28 mlla_tiny] (main.py 350): INFO  * Acc@1 45.930 Acc@5 69.730
[2024-10-24 12:55:28 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.9%
[2024-10-24 12:55:59 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 12:55:59 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 12:55:59 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_208.pth saving......
[2024-10-24 12:56:01 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_208.pth saved !!!
[2024-10-24 12:56:01 mlla_tiny] (main.py 205): INFO Max accuracy: 45.94%
[2024-10-24 12:56:01 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 12:56:48 mlla_tiny] (main.py 296): INFO Train: [209/300][100/312]	eta 0:01:41 lr 0.000028	time 0.4721 (0.4769)	loss 12.1273 (11.5558)	grad_norm 5.4882 (inf)	mem 15420MB
[2024-10-24 12:57:36 mlla_tiny] (main.py 296): INFO Train: [209/300][200/312]	eta 0:00:53 lr 0.000027	time 0.4727 (0.4748)	loss 11.6538 (11.5616)	grad_norm 7.7460 (inf)	mem 15420MB
[2024-10-24 12:58:23 mlla_tiny] (main.py 296): INFO Train: [209/300][300/312]	eta 0:00:06 lr 0.000027	time 0.4740 (0.4745)	loss 10.4277 (11.5545)	grad_norm 11.9369 (inf)	mem 15420MB
[2024-10-24 12:58:29 mlla_tiny] (main.py 304): INFO EPOCH 209 training takes 0:02:28
[2024-10-24 12:59:00 mlla_tiny] (main.py 350): INFO  * Acc@1 45.670 Acc@5 69.640
[2024-10-24 12:59:00 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.7%
[2024-10-24 12:59:32 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 12:59:32 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 12:59:32 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_209.pth saving......
[2024-10-24 12:59:33 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_209.pth saved !!!
[2024-10-24 12:59:33 mlla_tiny] (main.py 205): INFO Max accuracy: 45.94%
[2024-10-24 12:59:33 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 13:00:20 mlla_tiny] (main.py 296): INFO Train: [210/300][100/312]	eta 0:01:41 lr 0.000027	time 0.4719 (0.4768)	loss 11.8617 (11.4816)	grad_norm 7.4868 (inf)	mem 15420MB
[2024-10-24 13:01:08 mlla_tiny] (main.py 296): INFO Train: [210/300][200/312]	eta 0:00:53 lr 0.000027	time 0.4733 (0.4749)	loss 11.3249 (11.4586)	grad_norm 9.6546 (inf)	mem 15420MB
[2024-10-24 13:01:55 mlla_tiny] (main.py 296): INFO Train: [210/300][300/312]	eta 0:00:06 lr 0.000027	time 0.4742 (0.4745)	loss 10.9267 (11.4673)	grad_norm 8.2534 (inf)	mem 15420MB
[2024-10-24 13:02:01 mlla_tiny] (main.py 304): INFO EPOCH 210 training takes 0:02:28
[2024-10-24 13:02:32 mlla_tiny] (main.py 350): INFO  * Acc@1 45.790 Acc@5 70.300
[2024-10-24 13:02:32 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.8%
[2024-10-24 13:03:04 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 13:03:04 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 13:03:04 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_210.pth saving......
[2024-10-24 13:03:05 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_210.pth saved !!!
[2024-10-24 13:03:05 mlla_tiny] (main.py 205): INFO Max accuracy: 45.94%
[2024-10-24 13:03:05 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 13:03:53 mlla_tiny] (main.py 296): INFO Train: [211/300][100/312]	eta 0:01:41 lr 0.000027	time 0.4721 (0.4766)	loss 11.3948 (11.5134)	grad_norm 7.5895 (inf)	mem 15420MB
[2024-10-24 13:04:40 mlla_tiny] (main.py 296): INFO Train: [211/300][200/312]	eta 0:00:53 lr 0.000026	time 0.4742 (0.4750)	loss 11.4940 (11.5117)	grad_norm 7.2521 (inf)	mem 15420MB
[2024-10-24 13:05:27 mlla_tiny] (main.py 296): INFO Train: [211/300][300/312]	eta 0:00:06 lr 0.000026	time 0.4729 (0.4745)	loss 12.2098 (11.4770)	grad_norm 6.9637 (inf)	mem 15420MB
[2024-10-24 13:05:33 mlla_tiny] (main.py 304): INFO EPOCH 211 training takes 0:02:28
[2024-10-24 13:06:04 mlla_tiny] (main.py 350): INFO  * Acc@1 46.200 Acc@5 70.300
[2024-10-24 13:06:04 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.2%
[2024-10-24 13:06:36 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 13:06:36 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 13:06:36 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_211.pth saving......
[2024-10-24 13:06:37 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_211.pth saved !!!
[2024-10-24 13:06:37 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 13:06:39 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 13:06:39 mlla_tiny] (main.py 205): INFO Max accuracy: 46.20%
[2024-10-24 13:06:39 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 13:07:26 mlla_tiny] (main.py 296): INFO Train: [212/300][100/312]	eta 0:01:41 lr 0.000026	time 0.4716 (0.4765)	loss 11.8724 (11.4715)	grad_norm 5.7821 (inf)	mem 15420MB
[2024-10-24 13:08:14 mlla_tiny] (main.py 296): INFO Train: [212/300][200/312]	eta 0:00:53 lr 0.000026	time 0.4742 (0.4748)	loss 12.5031 (11.4534)	grad_norm 5.5881 (inf)	mem 15420MB
[2024-10-24 13:09:01 mlla_tiny] (main.py 296): INFO Train: [212/300][300/312]	eta 0:00:06 lr 0.000026	time 0.4735 (0.4745)	loss 10.8342 (11.4414)	grad_norm 9.3897 (inf)	mem 15420MB
[2024-10-24 13:09:07 mlla_tiny] (main.py 304): INFO EPOCH 212 training takes 0:02:28
[2024-10-24 13:09:38 mlla_tiny] (main.py 350): INFO  * Acc@1 45.770 Acc@5 69.710
[2024-10-24 13:09:38 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.8%
[2024-10-24 13:10:10 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 13:10:10 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 13:10:10 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_212.pth saving......
[2024-10-24 13:10:11 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_212.pth saved !!!
[2024-10-24 13:10:11 mlla_tiny] (main.py 205): INFO Max accuracy: 46.20%
[2024-10-24 13:10:11 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 13:10:58 mlla_tiny] (main.py 296): INFO Train: [213/300][100/312]	eta 0:01:41 lr 0.000026	time 0.4723 (0.4759)	loss 11.3396 (11.5026)	grad_norm 5.8466 (inf)	mem 15420MB
[2024-10-24 13:11:45 mlla_tiny] (main.py 296): INFO Train: [213/300][200/312]	eta 0:00:53 lr 0.000025	time 0.4735 (0.4744)	loss 10.2872 (11.4797)	grad_norm 8.0696 (inf)	mem 15420MB
[2024-10-24 13:12:33 mlla_tiny] (main.py 296): INFO Train: [213/300][300/312]	eta 0:00:06 lr 0.000025	time 0.4732 (0.4740)	loss 11.2241 (11.4997)	grad_norm 6.6744 (inf)	mem 15420MB
[2024-10-24 13:12:38 mlla_tiny] (main.py 304): INFO EPOCH 213 training takes 0:02:27
[2024-10-24 13:13:10 mlla_tiny] (main.py 350): INFO  * Acc@1 45.830 Acc@5 69.730
[2024-10-24 13:13:10 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.8%
[2024-10-24 13:13:41 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 13:13:41 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 13:13:41 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_213.pth saving......
[2024-10-24 13:13:42 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_213.pth saved !!!
[2024-10-24 13:13:42 mlla_tiny] (main.py 205): INFO Max accuracy: 46.20%
[2024-10-24 13:13:42 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 13:14:30 mlla_tiny] (main.py 296): INFO Train: [214/300][100/312]	eta 0:01:41 lr 0.000025	time 0.4720 (0.4762)	loss 12.3421 (11.5041)	grad_norm 6.5306 (inf)	mem 15420MB
[2024-10-24 13:15:17 mlla_tiny] (main.py 296): INFO Train: [214/300][200/312]	eta 0:00:53 lr 0.000025	time 0.4729 (0.4746)	loss 11.6517 (11.4920)	grad_norm 8.2339 (inf)	mem 15420MB
[2024-10-24 13:16:04 mlla_tiny] (main.py 296): INFO Train: [214/300][300/312]	eta 0:00:06 lr 0.000025	time 0.4737 (0.4743)	loss 11.5837 (11.5433)	grad_norm 7.2208 (inf)	mem 15420MB
[2024-10-24 13:16:10 mlla_tiny] (main.py 304): INFO EPOCH 214 training takes 0:02:27
[2024-10-24 13:16:42 mlla_tiny] (main.py 350): INFO  * Acc@1 45.620 Acc@5 70.280
[2024-10-24 13:16:42 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.6%
[2024-10-24 13:17:13 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 13:17:13 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 13:17:13 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_214.pth saving......
[2024-10-24 13:17:14 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_214.pth saved !!!
[2024-10-24 13:17:14 mlla_tiny] (main.py 205): INFO Max accuracy: 46.20%
[2024-10-24 13:17:14 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 13:18:02 mlla_tiny] (main.py 296): INFO Train: [215/300][100/312]	eta 0:01:41 lr 0.000025	time 0.4724 (0.4765)	loss 11.8709 (11.4984)	grad_norm 7.4099 (inf)	mem 15420MB
[2024-10-24 13:18:49 mlla_tiny] (main.py 296): INFO Train: [215/300][200/312]	eta 0:00:53 lr 0.000024	time 0.4730 (0.4748)	loss 11.9799 (11.4471)	grad_norm 7.0203 (inf)	mem 15420MB
[2024-10-24 13:19:37 mlla_tiny] (main.py 296): INFO Train: [215/300][300/312]	eta 0:00:06 lr 0.000024	time 0.4735 (0.4745)	loss 11.5848 (11.4509)	grad_norm 6.2692 (inf)	mem 15420MB
[2024-10-24 13:19:43 mlla_tiny] (main.py 304): INFO EPOCH 215 training takes 0:02:28
[2024-10-24 13:20:14 mlla_tiny] (main.py 350): INFO  * Acc@1 46.350 Acc@5 70.030
[2024-10-24 13:20:14 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.4%
[2024-10-24 13:20:45 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 13:20:45 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 13:20:45 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_215.pth saving......
[2024-10-24 13:20:46 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_215.pth saved !!!
[2024-10-24 13:20:46 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 13:20:47 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 13:20:47 mlla_tiny] (main.py 205): INFO Max accuracy: 46.35%
[2024-10-24 13:20:47 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 13:21:35 mlla_tiny] (main.py 296): INFO Train: [216/300][100/312]	eta 0:01:41 lr 0.000024	time 0.4723 (0.4771)	loss 12.2656 (11.5355)	grad_norm 7.8087 (inf)	mem 15420MB
[2024-10-24 13:22:22 mlla_tiny] (main.py 296): INFO Train: [216/300][200/312]	eta 0:00:53 lr 0.000024	time 0.4733 (0.4751)	loss 11.6882 (11.4966)	grad_norm 5.7525 (inf)	mem 15420MB
[2024-10-24 13:23:09 mlla_tiny] (main.py 296): INFO Train: [216/300][300/312]	eta 0:00:06 lr 0.000024	time 0.4736 (0.4748)	loss 11.7605 (11.5100)	grad_norm 6.3438 (inf)	mem 15420MB
[2024-10-24 13:23:15 mlla_tiny] (main.py 304): INFO EPOCH 216 training takes 0:02:28
[2024-10-24 13:23:46 mlla_tiny] (main.py 350): INFO  * Acc@1 45.820 Acc@5 70.050
[2024-10-24 13:23:46 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.8%
[2024-10-24 13:24:17 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.540
[2024-10-24 13:24:17 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 13:24:17 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_216.pth saving......
[2024-10-24 13:24:18 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_216.pth saved !!!
[2024-10-24 13:24:18 mlla_tiny] (main.py 205): INFO Max accuracy: 46.35%
[2024-10-24 13:24:18 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 13:25:06 mlla_tiny] (main.py 296): INFO Train: [217/300][100/312]	eta 0:01:41 lr 0.000024	time 0.4725 (0.4771)	loss 10.8517 (11.5264)	grad_norm 7.5344 (inf)	mem 15420MB
[2024-10-24 13:25:54 mlla_tiny] (main.py 296): INFO Train: [217/300][200/312]	eta 0:00:53 lr 0.000023	time 0.4759 (0.4753)	loss 12.0782 (11.4308)	grad_norm 4.9632 (inf)	mem 15420MB
[2024-10-24 13:26:41 mlla_tiny] (main.py 296): INFO Train: [217/300][300/312]	eta 0:00:06 lr 0.000023	time 0.4740 (0.4748)	loss 10.0494 (11.4643)	grad_norm 7.3946 (inf)	mem 15420MB
[2024-10-24 13:26:47 mlla_tiny] (main.py 304): INFO EPOCH 217 training takes 0:02:28
[2024-10-24 13:27:18 mlla_tiny] (main.py 350): INFO  * Acc@1 45.640 Acc@5 69.430
[2024-10-24 13:27:18 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.6%
[2024-10-24 13:27:49 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.520
[2024-10-24 13:27:49 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 13:27:49 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_217.pth saving......
[2024-10-24 13:27:51 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_217.pth saved !!!
[2024-10-24 13:27:51 mlla_tiny] (main.py 205): INFO Max accuracy: 46.35%
[2024-10-24 13:27:51 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 13:28:39 mlla_tiny] (main.py 296): INFO Train: [218/300][100/312]	eta 0:01:41 lr 0.000023	time 0.4729 (0.4775)	loss 12.3257 (11.4402)	grad_norm 8.5783 (inf)	mem 15420MB
[2024-10-24 13:29:26 mlla_tiny] (main.py 296): INFO Train: [218/300][200/312]	eta 0:00:53 lr 0.000023	time 0.4738 (0.4753)	loss 12.1456 (11.4393)	grad_norm 6.8489 (inf)	mem 15420MB
[2024-10-24 13:30:14 mlla_tiny] (main.py 296): INFO Train: [218/300][300/312]	eta 0:00:06 lr 0.000023	time 0.4740 (0.4749)	loss 10.7027 (11.4620)	grad_norm 7.3001 (inf)	mem 15420MB
[2024-10-24 13:30:20 mlla_tiny] (main.py 304): INFO EPOCH 218 training takes 0:02:28
[2024-10-24 13:30:51 mlla_tiny] (main.py 350): INFO  * Acc@1 45.620 Acc@5 69.970
[2024-10-24 13:30:51 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.6%
[2024-10-24 13:31:22 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 13:31:22 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 13:31:22 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_218.pth saving......
[2024-10-24 13:31:23 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_218.pth saved !!!
[2024-10-24 13:31:23 mlla_tiny] (main.py 205): INFO Max accuracy: 46.35%
[2024-10-24 13:31:23 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 13:32:11 mlla_tiny] (main.py 296): INFO Train: [219/300][100/312]	eta 0:01:41 lr 0.000023	time 0.4719 (0.4765)	loss 12.0521 (11.5880)	grad_norm 6.9663 (inf)	mem 15420MB
[2024-10-24 13:32:58 mlla_tiny] (main.py 296): INFO Train: [219/300][200/312]	eta 0:00:53 lr 0.000022	time 0.4739 (0.4751)	loss 11.9567 (11.5156)	grad_norm 5.9015 (inf)	mem 15420MB
[2024-10-24 13:33:46 mlla_tiny] (main.py 296): INFO Train: [219/300][300/312]	eta 0:00:06 lr 0.000022	time 0.4738 (0.4746)	loss 12.0862 (11.4819)	grad_norm 6.0387 (inf)	mem 15420MB
[2024-10-24 13:33:51 mlla_tiny] (main.py 304): INFO EPOCH 219 training takes 0:02:28
[2024-10-24 13:34:22 mlla_tiny] (main.py 350): INFO  * Acc@1 46.060 Acc@5 70.200
[2024-10-24 13:34:22 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.1%
[2024-10-24 13:34:54 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 13:34:54 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 13:34:54 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_219.pth saving......
[2024-10-24 13:34:55 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_219.pth saved !!!
[2024-10-24 13:34:55 mlla_tiny] (main.py 205): INFO Max accuracy: 46.35%
[2024-10-24 13:34:55 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 13:35:43 mlla_tiny] (main.py 296): INFO Train: [220/300][100/312]	eta 0:01:41 lr 0.000022	time 0.4736 (0.4761)	loss 11.4712 (11.3740)	grad_norm 9.9630 (inf)	mem 15420MB
[2024-10-24 13:36:30 mlla_tiny] (main.py 296): INFO Train: [220/300][200/312]	eta 0:00:53 lr 0.000022	time 0.4758 (0.4747)	loss 11.3754 (11.3861)	grad_norm 5.1244 (inf)	mem 15420MB
[2024-10-24 13:37:18 mlla_tiny] (main.py 296): INFO Train: [220/300][300/312]	eta 0:00:06 lr 0.000022	time 0.4740 (0.4746)	loss 10.4064 (11.4064)	grad_norm 6.4919 (inf)	mem 15420MB
[2024-10-24 13:37:24 mlla_tiny] (main.py 304): INFO EPOCH 220 training takes 0:02:28
[2024-10-24 13:37:55 mlla_tiny] (main.py 350): INFO  * Acc@1 45.830 Acc@5 69.760
[2024-10-24 13:37:55 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.8%
[2024-10-24 13:38:26 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 13:38:26 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 13:38:26 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_220.pth saving......
[2024-10-24 13:38:28 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_220.pth saved !!!
[2024-10-24 13:38:28 mlla_tiny] (main.py 205): INFO Max accuracy: 46.35%
[2024-10-24 13:38:28 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 13:39:15 mlla_tiny] (main.py 296): INFO Train: [221/300][100/312]	eta 0:01:41 lr 0.000022	time 0.4746 (0.4771)	loss 11.2584 (11.3832)	grad_norm 6.1779 (inf)	mem 15420MB
[2024-10-24 13:40:03 mlla_tiny] (main.py 296): INFO Train: [221/300][200/312]	eta 0:00:53 lr 0.000021	time 0.4727 (0.4750)	loss 10.9748 (11.4074)	grad_norm 6.6212 (inf)	mem 15420MB
[2024-10-24 13:40:50 mlla_tiny] (main.py 296): INFO Train: [221/300][300/312]	eta 0:00:06 lr 0.000021	time 0.4733 (0.4745)	loss 10.3863 (11.4491)	grad_norm 8.6809 (inf)	mem 15420MB
[2024-10-24 13:40:56 mlla_tiny] (main.py 304): INFO EPOCH 221 training takes 0:02:28
[2024-10-24 13:41:28 mlla_tiny] (main.py 350): INFO  * Acc@1 46.360 Acc@5 70.200
[2024-10-24 13:41:28 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.4%
[2024-10-24 13:41:59 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 13:41:59 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 13:41:59 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_221.pth saving......
[2024-10-24 13:42:00 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_221.pth saved !!!
[2024-10-24 13:42:00 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 13:42:02 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 13:42:02 mlla_tiny] (main.py 205): INFO Max accuracy: 46.36%
[2024-10-24 13:42:02 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 13:42:49 mlla_tiny] (main.py 296): INFO Train: [222/300][100/312]	eta 0:01:41 lr 0.000021	time 0.4723 (0.4760)	loss 12.0134 (11.4338)	grad_norm 7.3775 (inf)	mem 15420MB
[2024-10-24 13:43:36 mlla_tiny] (main.py 296): INFO Train: [222/300][200/312]	eta 0:00:53 lr 0.000021	time 0.4737 (0.4744)	loss 11.1862 (11.4211)	grad_norm 6.5846 (inf)	mem 15420MB
[2024-10-24 13:44:24 mlla_tiny] (main.py 296): INFO Train: [222/300][300/312]	eta 0:00:06 lr 0.000021	time 0.4731 (0.4743)	loss 10.9588 (11.4154)	grad_norm 8.4796 (inf)	mem 15420MB
[2024-10-24 13:44:30 mlla_tiny] (main.py 304): INFO EPOCH 222 training takes 0:02:27
[2024-10-24 13:45:01 mlla_tiny] (main.py 350): INFO  * Acc@1 46.200 Acc@5 70.120
[2024-10-24 13:45:01 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.2%
[2024-10-24 13:45:33 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 13:45:33 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 13:45:33 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_222.pth saving......
[2024-10-24 13:45:34 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_222.pth saved !!!
[2024-10-24 13:45:34 mlla_tiny] (main.py 205): INFO Max accuracy: 46.36%
[2024-10-24 13:45:34 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 13:46:21 mlla_tiny] (main.py 296): INFO Train: [223/300][100/312]	eta 0:01:41 lr 0.000021	time 0.4726 (0.4766)	loss 12.0105 (11.4297)	grad_norm 7.0878 (inf)	mem 15420MB
[2024-10-24 13:47:09 mlla_tiny] (main.py 296): INFO Train: [223/300][200/312]	eta 0:00:53 lr 0.000020	time 0.4738 (0.4749)	loss 11.1287 (11.4590)	grad_norm 6.6129 (inf)	mem 15420MB
[2024-10-24 13:47:56 mlla_tiny] (main.py 296): INFO Train: [223/300][300/312]	eta 0:00:06 lr 0.000020	time 0.4730 (0.4744)	loss 11.6008 (11.4827)	grad_norm 5.3733 (inf)	mem 15420MB
[2024-10-24 13:48:02 mlla_tiny] (main.py 304): INFO EPOCH 223 training takes 0:02:28
[2024-10-24 13:48:33 mlla_tiny] (main.py 350): INFO  * Acc@1 45.640 Acc@5 69.960
[2024-10-24 13:48:33 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.6%
[2024-10-24 13:49:05 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 13:49:05 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 13:49:05 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_223.pth saving......
[2024-10-24 13:49:06 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_223.pth saved !!!
[2024-10-24 13:49:06 mlla_tiny] (main.py 205): INFO Max accuracy: 46.36%
[2024-10-24 13:49:06 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 13:49:53 mlla_tiny] (main.py 296): INFO Train: [224/300][100/312]	eta 0:01:41 lr 0.000020	time 0.4724 (0.4773)	loss 11.3989 (11.5703)	grad_norm 9.8890 (inf)	mem 15420MB
[2024-10-24 13:50:41 mlla_tiny] (main.py 296): INFO Train: [224/300][200/312]	eta 0:00:53 lr 0.000020	time 0.4739 (0.4753)	loss 11.1741 (11.5368)	grad_norm 5.4812 (inf)	mem 15420MB
[2024-10-24 13:51:28 mlla_tiny] (main.py 296): INFO Train: [224/300][300/312]	eta 0:00:06 lr 0.000020	time 0.4748 (0.4748)	loss 11.8365 (11.5342)	grad_norm 7.8379 (inf)	mem 15420MB
[2024-10-24 13:51:34 mlla_tiny] (main.py 304): INFO EPOCH 224 training takes 0:02:28
[2024-10-24 13:52:05 mlla_tiny] (main.py 350): INFO  * Acc@1 46.130 Acc@5 70.110
[2024-10-24 13:52:05 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.1%
[2024-10-24 13:52:37 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 13:52:37 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 13:52:37 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_224.pth saving......
[2024-10-24 13:52:38 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_224.pth saved !!!
[2024-10-24 13:52:38 mlla_tiny] (main.py 205): INFO Max accuracy: 46.36%
[2024-10-24 13:52:38 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 13:53:25 mlla_tiny] (main.py 296): INFO Train: [225/300][100/312]	eta 0:01:41 lr 0.000020	time 0.5104 (0.4775)	loss 11.0334 (11.4983)	grad_norm 5.6931 (inf)	mem 15420MB
[2024-10-24 13:54:13 mlla_tiny] (main.py 296): INFO Train: [225/300][200/312]	eta 0:00:53 lr 0.000020	time 0.4736 (0.4755)	loss 11.7302 (11.4706)	grad_norm 6.4980 (inf)	mem 15420MB
[2024-10-24 13:55:00 mlla_tiny] (main.py 296): INFO Train: [225/300][300/312]	eta 0:00:06 lr 0.000019	time 0.4743 (0.4749)	loss 11.8890 (11.4670)	grad_norm 6.7239 (inf)	mem 15420MB
[2024-10-24 13:55:06 mlla_tiny] (main.py 304): INFO EPOCH 225 training takes 0:02:28
[2024-10-24 13:55:37 mlla_tiny] (main.py 350): INFO  * Acc@1 46.130 Acc@5 70.500
[2024-10-24 13:55:37 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.1%
[2024-10-24 13:56:08 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 13:56:08 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 13:56:08 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_225.pth saving......
[2024-10-24 13:56:09 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_225.pth saved !!!
[2024-10-24 13:56:09 mlla_tiny] (main.py 205): INFO Max accuracy: 46.36%
[2024-10-24 13:56:09 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 13:56:57 mlla_tiny] (main.py 296): INFO Train: [226/300][100/312]	eta 0:01:41 lr 0.000019	time 0.4724 (0.4763)	loss 11.1379 (11.4588)	grad_norm 6.2134 (inf)	mem 15420MB
[2024-10-24 13:57:44 mlla_tiny] (main.py 296): INFO Train: [226/300][200/312]	eta 0:00:53 lr 0.000019	time 0.4737 (0.4751)	loss 10.8622 (11.4116)	grad_norm 7.3197 (inf)	mem 15420MB
[2024-10-24 13:58:32 mlla_tiny] (main.py 296): INFO Train: [226/300][300/312]	eta 0:00:06 lr 0.000019	time 0.4743 (0.4746)	loss 11.6359 (11.4139)	grad_norm 5.8265 (inf)	mem 15420MB
[2024-10-24 13:58:38 mlla_tiny] (main.py 304): INFO EPOCH 226 training takes 0:02:28
[2024-10-24 13:59:09 mlla_tiny] (main.py 350): INFO  * Acc@1 46.170 Acc@5 70.120
[2024-10-24 13:59:09 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.2%
[2024-10-24 13:59:41 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 13:59:41 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 13:59:41 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_226.pth saving......
[2024-10-24 13:59:42 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_226.pth saved !!!
[2024-10-24 13:59:42 mlla_tiny] (main.py 205): INFO Max accuracy: 46.36%
[2024-10-24 13:59:42 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 14:00:29 mlla_tiny] (main.py 296): INFO Train: [227/300][100/312]	eta 0:01:41 lr 0.000019	time 0.4729 (0.4774)	loss 11.9591 (11.4915)	grad_norm 7.1028 (inf)	mem 15420MB
[2024-10-24 14:01:17 mlla_tiny] (main.py 296): INFO Train: [227/300][200/312]	eta 0:00:53 lr 0.000019	time 0.4732 (0.4754)	loss 11.7720 (11.5059)	grad_norm 10.5001 (inf)	mem 15420MB
[2024-10-24 14:02:04 mlla_tiny] (main.py 296): INFO Train: [227/300][300/312]	eta 0:00:06 lr 0.000018	time 0.4741 (0.4749)	loss 12.4262 (11.4580)	grad_norm 6.1457 (inf)	mem 15420MB
[2024-10-24 14:02:10 mlla_tiny] (main.py 304): INFO EPOCH 227 training takes 0:02:28
[2024-10-24 14:02:41 mlla_tiny] (main.py 350): INFO  * Acc@1 46.120 Acc@5 70.380
[2024-10-24 14:02:41 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.1%
[2024-10-24 14:03:12 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 14:03:12 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 14:03:12 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_227.pth saving......
[2024-10-24 14:03:13 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_227.pth saved !!!
[2024-10-24 14:03:13 mlla_tiny] (main.py 205): INFO Max accuracy: 46.36%
[2024-10-24 14:03:13 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 14:04:01 mlla_tiny] (main.py 296): INFO Train: [228/300][100/312]	eta 0:01:41 lr 0.000018	time 0.4717 (0.4765)	loss 10.5681 (11.3091)	grad_norm 6.7140 (inf)	mem 15420MB
[2024-10-24 14:04:48 mlla_tiny] (main.py 296): INFO Train: [228/300][200/312]	eta 0:00:53 lr 0.000018	time 0.4730 (0.4748)	loss 10.7443 (11.4291)	grad_norm 8.1170 (inf)	mem 15420MB
[2024-10-24 14:05:35 mlla_tiny] (main.py 296): INFO Train: [228/300][300/312]	eta 0:00:06 lr 0.000018	time 0.4737 (0.4744)	loss 10.4098 (11.4056)	grad_norm 8.6442 (inf)	mem 15420MB
[2024-10-24 14:05:41 mlla_tiny] (main.py 304): INFO EPOCH 228 training takes 0:02:28
[2024-10-24 14:06:12 mlla_tiny] (main.py 350): INFO  * Acc@1 46.060 Acc@5 70.280
[2024-10-24 14:06:12 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.1%
[2024-10-24 14:06:44 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 14:06:44 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 14:06:44 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_228.pth saving......
[2024-10-24 14:06:45 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_228.pth saved !!!
[2024-10-24 14:06:45 mlla_tiny] (main.py 205): INFO Max accuracy: 46.36%
[2024-10-24 14:06:45 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 14:07:32 mlla_tiny] (main.py 296): INFO Train: [229/300][100/312]	eta 0:01:41 lr 0.000018	time 0.4720 (0.4761)	loss 11.1498 (11.4162)	grad_norm 9.1837 (inf)	mem 15420MB
[2024-10-24 14:08:20 mlla_tiny] (main.py 296): INFO Train: [229/300][200/312]	eta 0:00:53 lr 0.000018	time 0.4736 (0.4743)	loss 12.2162 (11.3948)	grad_norm 7.0414 (inf)	mem 15420MB
[2024-10-24 14:09:07 mlla_tiny] (main.py 296): INFO Train: [229/300][300/312]	eta 0:00:06 lr 0.000018	time 0.4728 (0.4738)	loss 10.7910 (11.3824)	grad_norm 5.8321 (inf)	mem 15420MB
[2024-10-24 14:09:13 mlla_tiny] (main.py 304): INFO EPOCH 229 training takes 0:02:27
[2024-10-24 14:09:44 mlla_tiny] (main.py 350): INFO  * Acc@1 46.190 Acc@5 70.400
[2024-10-24 14:09:44 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.2%
[2024-10-24 14:10:15 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 14:10:15 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 14:10:15 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_229.pth saving......
[2024-10-24 14:10:16 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_229.pth saved !!!
[2024-10-24 14:10:16 mlla_tiny] (main.py 205): INFO Max accuracy: 46.36%
[2024-10-24 14:10:16 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 14:11:04 mlla_tiny] (main.py 296): INFO Train: [230/300][100/312]	eta 0:01:41 lr 0.000017	time 0.4726 (0.4765)	loss 12.1447 (11.4063)	grad_norm 6.2977 (inf)	mem 15420MB
[2024-10-24 14:11:51 mlla_tiny] (main.py 296): INFO Train: [230/300][200/312]	eta 0:00:53 lr 0.000017	time 0.4732 (0.4748)	loss 11.7723 (11.4488)	grad_norm 6.6953 (inf)	mem 15420MB
[2024-10-24 14:12:39 mlla_tiny] (main.py 296): INFO Train: [230/300][300/312]	eta 0:00:06 lr 0.000017	time 0.4744 (0.4743)	loss 11.5903 (11.4456)	grad_norm 8.0573 (inf)	mem 15420MB
[2024-10-24 14:12:44 mlla_tiny] (main.py 304): INFO EPOCH 230 training takes 0:02:28
[2024-10-24 14:13:16 mlla_tiny] (main.py 350): INFO  * Acc@1 46.420 Acc@5 70.410
[2024-10-24 14:13:16 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.4%
[2024-10-24 14:13:47 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 14:13:47 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 14:13:47 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_230.pth saving......
[2024-10-24 14:13:48 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_230.pth saved !!!
[2024-10-24 14:13:48 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 14:13:49 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 14:13:49 mlla_tiny] (main.py 205): INFO Max accuracy: 46.42%
[2024-10-24 14:13:49 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 14:14:37 mlla_tiny] (main.py 296): INFO Train: [231/300][100/312]	eta 0:01:41 lr 0.000017	time 0.4720 (0.4777)	loss 11.9326 (11.5122)	grad_norm 6.1851 (inf)	mem 15420MB
[2024-10-24 14:15:25 mlla_tiny] (main.py 296): INFO Train: [231/300][200/312]	eta 0:00:53 lr 0.000017	time 0.4744 (0.4757)	loss 10.4919 (11.5283)	grad_norm 14.9729 (inf)	mem 15420MB
[2024-10-24 14:16:12 mlla_tiny] (main.py 296): INFO Train: [231/300][300/312]	eta 0:00:06 lr 0.000017	time 0.4740 (0.4751)	loss 11.6382 (11.4675)	grad_norm 5.6969 (inf)	mem 15420MB
[2024-10-24 14:16:18 mlla_tiny] (main.py 304): INFO EPOCH 231 training takes 0:02:28
[2024-10-24 14:16:49 mlla_tiny] (main.py 350): INFO  * Acc@1 46.260 Acc@5 70.240
[2024-10-24 14:16:49 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.3%
[2024-10-24 14:17:21 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 14:17:21 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 14:17:21 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_231.pth saving......
[2024-10-24 14:17:22 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_231.pth saved !!!
[2024-10-24 14:17:22 mlla_tiny] (main.py 205): INFO Max accuracy: 46.42%
[2024-10-24 14:17:22 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 14:18:09 mlla_tiny] (main.py 296): INFO Train: [232/300][100/312]	eta 0:01:41 lr 0.000017	time 0.4722 (0.4764)	loss 12.2217 (11.4268)	grad_norm 5.7808 (inf)	mem 15420MB
[2024-10-24 14:18:57 mlla_tiny] (main.py 296): INFO Train: [232/300][200/312]	eta 0:00:53 lr 0.000016	time 0.4737 (0.4748)	loss 11.5918 (11.4677)	grad_norm 5.3769 (inf)	mem 15420MB
[2024-10-24 14:19:44 mlla_tiny] (main.py 296): INFO Train: [232/300][300/312]	eta 0:00:06 lr 0.000016	time 0.4751 (0.4745)	loss 11.0693 (11.4458)	grad_norm 7.2126 (inf)	mem 15420MB
[2024-10-24 14:19:50 mlla_tiny] (main.py 304): INFO EPOCH 232 training takes 0:02:28
[2024-10-24 14:20:21 mlla_tiny] (main.py 350): INFO  * Acc@1 45.950 Acc@5 69.920
[2024-10-24 14:20:21 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.0%
[2024-10-24 14:20:52 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 14:20:52 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 14:20:52 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_232.pth saving......
[2024-10-24 14:20:53 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_232.pth saved !!!
[2024-10-24 14:20:53 mlla_tiny] (main.py 205): INFO Max accuracy: 46.42%
[2024-10-24 14:20:53 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 14:21:41 mlla_tiny] (main.py 296): INFO Train: [233/300][100/312]	eta 0:01:41 lr 0.000016	time 0.4722 (0.4767)	loss 11.9578 (11.3723)	grad_norm 11.1810 (inf)	mem 15420MB
[2024-10-24 14:22:28 mlla_tiny] (main.py 296): INFO Train: [233/300][200/312]	eta 0:00:53 lr 0.000016	time 0.4735 (0.4752)	loss 10.4878 (11.3963)	grad_norm 7.6172 (inf)	mem 15420MB
[2024-10-24 14:23:16 mlla_tiny] (main.py 296): INFO Train: [233/300][300/312]	eta 0:00:06 lr 0.000016	time 0.4731 (0.4746)	loss 11.5961 (11.3911)	grad_norm 9.2716 (inf)	mem 15420MB
[2024-10-24 14:23:22 mlla_tiny] (main.py 304): INFO EPOCH 233 training takes 0:02:28
[2024-10-24 14:23:53 mlla_tiny] (main.py 350): INFO  * Acc@1 46.090 Acc@5 70.110
[2024-10-24 14:23:53 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.1%
[2024-10-24 14:24:24 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 14:24:24 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 14:24:24 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_233.pth saving......
[2024-10-24 14:24:25 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_233.pth saved !!!
[2024-10-24 14:24:25 mlla_tiny] (main.py 205): INFO Max accuracy: 46.42%
[2024-10-24 14:24:25 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 14:25:13 mlla_tiny] (main.py 296): INFO Train: [234/300][100/312]	eta 0:01:41 lr 0.000016	time 0.4724 (0.4771)	loss 12.1201 (11.4009)	grad_norm 5.6945 (inf)	mem 15420MB
[2024-10-24 14:26:00 mlla_tiny] (main.py 296): INFO Train: [234/300][200/312]	eta 0:00:53 lr 0.000016	time 0.4746 (0.4754)	loss 10.6193 (11.4029)	grad_norm 13.1248 (inf)	mem 15420MB
[2024-10-24 14:26:48 mlla_tiny] (main.py 296): INFO Train: [234/300][300/312]	eta 0:00:06 lr 0.000015	time 0.4744 (0.4749)	loss 11.6743 (11.4333)	grad_norm 6.6542 (inf)	mem 15420MB
[2024-10-24 14:26:53 mlla_tiny] (main.py 304): INFO EPOCH 234 training takes 0:02:28
[2024-10-24 14:27:25 mlla_tiny] (main.py 350): INFO  * Acc@1 45.850 Acc@5 70.660
[2024-10-24 14:27:25 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 45.9%
[2024-10-24 14:27:56 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 14:27:56 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 14:27:56 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_234.pth saving......
[2024-10-24 14:27:57 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_234.pth saved !!!
[2024-10-24 14:27:57 mlla_tiny] (main.py 205): INFO Max accuracy: 46.42%
[2024-10-24 14:27:57 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 14:28:45 mlla_tiny] (main.py 296): INFO Train: [235/300][100/312]	eta 0:01:41 lr 0.000015	time 0.4721 (0.4767)	loss 12.2169 (11.3850)	grad_norm 6.4840 (inf)	mem 15420MB
[2024-10-24 14:29:32 mlla_tiny] (main.py 296): INFO Train: [235/300][200/312]	eta 0:00:53 lr 0.000015	time 0.4762 (0.4749)	loss 10.6910 (11.3431)	grad_norm 9.8774 (inf)	mem 15420MB
[2024-10-24 14:30:19 mlla_tiny] (main.py 296): INFO Train: [235/300][300/312]	eta 0:00:06 lr 0.000015	time 0.4740 (0.4745)	loss 10.8162 (11.3764)	grad_norm 7.3878 (inf)	mem 15420MB
[2024-10-24 14:30:25 mlla_tiny] (main.py 304): INFO EPOCH 235 training takes 0:02:28
[2024-10-24 14:30:56 mlla_tiny] (main.py 350): INFO  * Acc@1 46.490 Acc@5 70.330
[2024-10-24 14:30:56 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.5%
[2024-10-24 14:31:27 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 14:31:27 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 14:31:27 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_235.pth saving......
[2024-10-24 14:31:29 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_235.pth saved !!!
[2024-10-24 14:31:29 mlla_tiny] (utils.py 259): INFO work_dir/mlla_tiny/default/max_acc.pth saving......
[2024-10-24 14:31:30 mlla_tiny] (utils.py 261): INFO work_dir/mlla_tiny/default/max_acc.pth saved !!!
[2024-10-24 14:31:30 mlla_tiny] (main.py 205): INFO Max accuracy: 46.49%
[2024-10-24 14:31:30 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 14:32:18 mlla_tiny] (main.py 296): INFO Train: [236/300][100/312]	eta 0:01:41 lr 0.000015	time 0.4709 (0.4760)	loss 10.3511 (11.4260)	grad_norm 10.7094 (inf)	mem 15420MB
[2024-10-24 14:33:05 mlla_tiny] (main.py 296): INFO Train: [236/300][200/312]	eta 0:00:53 lr 0.000015	time 0.4732 (0.4744)	loss 11.8613 (11.4293)	grad_norm 8.9719 (inf)	mem 15420MB
[2024-10-24 14:33:52 mlla_tiny] (main.py 296): INFO Train: [236/300][300/312]	eta 0:00:06 lr 0.000015	time 0.4737 (0.4742)	loss 11.0891 (11.4165)	grad_norm 7.1589 (inf)	mem 15420MB
[2024-10-24 14:33:58 mlla_tiny] (main.py 304): INFO EPOCH 236 training takes 0:02:27
[2024-10-24 14:34:29 mlla_tiny] (main.py 350): INFO  * Acc@1 46.170 Acc@5 70.380
[2024-10-24 14:34:29 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.2%
[2024-10-24 14:35:01 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 14:35:01 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 14:35:01 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_236.pth saving......
[2024-10-24 14:35:02 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_236.pth saved !!!
[2024-10-24 14:35:02 mlla_tiny] (main.py 205): INFO Max accuracy: 46.49%
[2024-10-24 14:35:02 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 14:35:49 mlla_tiny] (main.py 296): INFO Train: [237/300][100/312]	eta 0:01:41 lr 0.000015	time 0.4726 (0.4758)	loss 10.5548 (11.3602)	grad_norm 9.4917 (inf)	mem 15420MB
[2024-10-24 14:36:37 mlla_tiny] (main.py 296): INFO Train: [237/300][200/312]	eta 0:00:53 lr 0.000014	time 0.4735 (0.4747)	loss 12.0435 (11.3098)	grad_norm 6.7644 (inf)	mem 15420MB
[2024-10-24 14:37:24 mlla_tiny] (main.py 296): INFO Train: [237/300][300/312]	eta 0:00:06 lr 0.000014	time 0.4727 (0.4744)	loss 11.2022 (11.3296)	grad_norm 7.2583 (inf)	mem 15420MB
[2024-10-24 14:37:30 mlla_tiny] (main.py 304): INFO EPOCH 237 training takes 0:02:28
[2024-10-24 14:38:02 mlla_tiny] (main.py 350): INFO  * Acc@1 46.190 Acc@5 70.420
[2024-10-24 14:38:02 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.2%
[2024-10-24 14:38:33 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 14:38:33 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 14:38:33 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_237.pth saving......
[2024-10-24 14:38:34 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_237.pth saved !!!
[2024-10-24 14:38:34 mlla_tiny] (main.py 205): INFO Max accuracy: 46.49%
[2024-10-24 14:38:34 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 14:39:22 mlla_tiny] (main.py 296): INFO Train: [238/300][100/312]	eta 0:01:41 lr 0.000014	time 0.4725 (0.4764)	loss 12.3419 (11.4432)	grad_norm 5.5859 (inf)	mem 15420MB
[2024-10-24 14:40:09 mlla_tiny] (main.py 296): INFO Train: [238/300][200/312]	eta 0:00:53 lr 0.000014	time 0.4754 (0.4747)	loss 12.3053 (11.4644)	grad_norm 7.5709 (inf)	mem 15420MB
[2024-10-24 14:40:56 mlla_tiny] (main.py 296): INFO Train: [238/300][300/312]	eta 0:00:06 lr 0.000014	time 0.4737 (0.4743)	loss 11.1210 (11.4758)	grad_norm 6.6497 (inf)	mem 15420MB
[2024-10-24 14:41:02 mlla_tiny] (main.py 304): INFO EPOCH 238 training takes 0:02:28
[2024-10-24 14:41:34 mlla_tiny] (main.py 350): INFO  * Acc@1 46.160 Acc@5 70.080
[2024-10-24 14:41:34 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.2%
[2024-10-24 14:42:05 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 14:42:05 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 14:42:05 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_238.pth saving......
[2024-10-24 14:42:07 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_238.pth saved !!!
[2024-10-24 14:42:07 mlla_tiny] (main.py 205): INFO Max accuracy: 46.49%
[2024-10-24 14:42:07 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 14:42:54 mlla_tiny] (main.py 296): INFO Train: [239/300][100/312]	eta 0:01:41 lr 0.000014	time 0.4720 (0.4766)	loss 11.4382 (11.4364)	grad_norm 6.8628 (inf)	mem 15420MB
[2024-10-24 14:43:42 mlla_tiny] (main.py 296): INFO Train: [239/300][200/312]	eta 0:00:53 lr 0.000014	time 0.4739 (0.4749)	loss 12.0111 (11.4890)	grad_norm 9.2565 (inf)	mem 15420MB
[2024-10-24 14:44:29 mlla_tiny] (main.py 296): INFO Train: [239/300][300/312]	eta 0:00:06 lr 0.000013	time 0.4743 (0.4745)	loss 11.8765 (11.4699)	grad_norm 6.3899 (inf)	mem 15420MB
[2024-10-24 14:44:35 mlla_tiny] (main.py 304): INFO EPOCH 239 training takes 0:02:28
[2024-10-24 14:45:06 mlla_tiny] (main.py 350): INFO  * Acc@1 46.360 Acc@5 70.280
[2024-10-24 14:45:06 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.4%
[2024-10-24 14:45:38 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 14:45:38 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 14:45:38 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_239.pth saving......
[2024-10-24 14:45:39 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_239.pth saved !!!
[2024-10-24 14:45:39 mlla_tiny] (main.py 205): INFO Max accuracy: 46.49%
[2024-10-24 14:45:39 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 14:46:26 mlla_tiny] (main.py 296): INFO Train: [240/300][100/312]	eta 0:01:41 lr 0.000013	time 0.4715 (0.4761)	loss 12.1387 (11.4209)	grad_norm 9.7746 (inf)	mem 15420MB
[2024-10-24 14:47:14 mlla_tiny] (main.py 296): INFO Train: [240/300][200/312]	eta 0:00:53 lr 0.000013	time 0.4736 (0.4744)	loss 11.8660 (11.4153)	grad_norm 7.6428 (nan)	mem 15420MB
[2024-10-24 14:48:01 mlla_tiny] (main.py 296): INFO Train: [240/300][300/312]	eta 0:00:06 lr 0.000013	time 0.4728 (0.4742)	loss 10.8884 (11.4028)	grad_norm 10.7728 (nan)	mem 15420MB
[2024-10-24 14:48:07 mlla_tiny] (main.py 304): INFO EPOCH 240 training takes 0:02:27
[2024-10-24 14:48:38 mlla_tiny] (main.py 350): INFO  * Acc@1 46.440 Acc@5 70.650
[2024-10-24 14:48:38 mlla_tiny] (main.py 192): INFO Accuracy of the network on the 10000 test images: 46.4%
[2024-10-24 14:49:10 mlla_tiny] (main.py 350): INFO  * Acc@1 0.100 Acc@5 0.500
[2024-10-24 14:49:10 mlla_tiny] (main.py 195): INFO Accuracy of the ema network on the 10000 test images: 0.1%
[2024-10-24 14:49:10 mlla_tiny] (utils.py 264): INFO work_dir/mlla_tiny/default/ckpt_epoch_240.pth saving......
[2024-10-24 14:49:11 mlla_tiny] (utils.py 266): INFO work_dir/mlla_tiny/default/ckpt_epoch_240.pth saved !!!
[2024-10-24 14:49:11 mlla_tiny] (main.py 205): INFO Max accuracy: 46.49%
[2024-10-24 14:49:11 mlla_tiny] (main.py 211): INFO Max ema accuracy: 0.11%
[2024-10-24 14:49:58 mlla_tiny] (main.py 296): INFO Train: [241/300][100/312]	eta 0:01:41 lr 0.000013	time 0.4724 (0.4768)	loss 12.0632 (11.2935)	grad_norm 7.7124 (inf)	mem 15420MB
[2024-10-24 14:50:46 mlla_tiny] (main.py 296): INFO Train: [241/300][200/312]	eta 0:00:53 lr 0.000013	time 0.4744 (0.4750)	loss 10.3177 (11.3383)	grad_norm 9.4398 (inf)	mem 15420MB
